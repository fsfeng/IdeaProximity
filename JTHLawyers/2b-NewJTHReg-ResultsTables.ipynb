{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/homedir/eco/sfeng/bigdata/python/miniconda3/lib/python3.6/site-packages/statsmodels/compat/pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.\n",
      "  from pandas.core import datetools\n"
     ]
    }
   ],
   "source": [
    "import scipy as sp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import timeit\n",
    "import re\n",
    "import json\n",
    "import pickle\n",
    "import fastparquet\n",
    "import os\n",
    "os.chdir('/mnt/t48/bighomes-active/sfeng/patentdiffusion/')\n",
    "seed = 3\n",
    "import seaborn as sns\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "import datetime\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "import statsmodels.iolib.summary2 as summary2\n",
    "import logging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. JTH summary tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsl = pickle.load(open(\"DataStore/2018-11/jth_rep_control_long_dict_1112.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "rt = pd.DataFrame()\n",
    "for k in [\"PC\", \"Sim\", \"Lawyer\"]:\n",
    "    v = tsl[k]\n",
    "    v2 = v[[\"perc_match_10\", \"year_group\", \"inv_msa_match\"]].groupby([\"year_group\", \"inv_msa_match\"]).mean().reset_index()\n",
    "    \n",
    "    t_pct = {n:g[\"perc_match_10\"].values for n,g in v.loc[v[\"inv_msa_match\"] == True, [\"year_group\", \"perc_match_10\"]].groupby(\"year_group\")}\n",
    "    c_pct = {n:g[\"perc_match_10\"].values for n,g in v.loc[v[\"inv_msa_match\"] == False, [\"year_group\", \"perc_match_10\"]].groupby(\"year_group\")}\n",
    "    \n",
    "    tc = v2.loc[v2[\"inv_msa_match\"] == True, \"perc_match_10\"].values\n",
    "    cc = v2.loc[v2[\"inv_msa_match\"] == False, \"perc_match_10\"].values\n",
    "    yg = v2.loc[v2[\"inv_msa_match\"] == True, \"year_group\"].values\n",
    "    p = [sp.stats.ttest_ind(t_pct[k], c_pct[k], equal_var=False, nan_policy=\"omit\")[1] for k in t_pct.keys()] \n",
    "    n = v[[\"perc_match_10\", \"year_group\"]].groupby([\"year_group\"]).size().values\n",
    "    ind = [\"Type\", \"Target, Pct Cite in Target MSA\", \"Control, Pct Cite in Target MSA\", \"Ratio\", \"$p$-value\", \"$N$\"]\n",
    "    \n",
    "    r = pd.DataFrame({\"Year Group\": yg,\n",
    "                      \"Target, Pct Cite in Target MSA\": tc, \n",
    "                      \"Control, Pct Cite in Target MSA\": cc, \n",
    "                      \"$p$-value\": p, \"$N$\": n})\n",
    "    \n",
    "    r = r.loc[r[\"Year Group\"] != \"2005-15\"].set_index(\"Year Group\")\n",
    "    \n",
    "    r[\"Ratio\"] = r[\"Target, Pct Cite in Target MSA\"]/r[\"Control, Pct Cite in Target MSA\"]\n",
    "    r = r.round(3)\n",
    "    r[\"Type\"] = k\n",
    "    \n",
    "    r = r[ind].T\n",
    "    r.loc[\"$N$\"] = r.loc[\"$N$\"].astype(int).astype(str)\n",
    "    rt = rt.append(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lcccc}\n",
      "\\toprule\n",
      "Year Group & 1975-85 & 1985-95 & 1995-05 \\\\\n",
      "\\midrule\n",
      "Type                            &      PC &      PC &      PC \\\\\n",
      "Target, Pct Cite in Target MSA  &   0.091 &   0.097 &    0.11 \\\\\n",
      "Control, Pct Cite in Target MSA &   0.038 &   0.035 &   0.045 \\\\\n",
      "Ratio                           &   2.411 &   2.792 &   2.429 \\\\\n",
      "$p$-value                       &       0 &       0 &       0 \\\\\n",
      "Obs.                            &   58647 &  107358 &  185154 \\\\\n",
      "Type                            &     Sim &     Sim &     Sim \\\\\n",
      "Target, Pct Cite in Target MSA  &   0.092 &   0.097 &    0.11 \\\\\n",
      "Control, Pct Cite in Target MSA &   0.048 &   0.041 &   0.054 \\\\\n",
      "Ratio                           &   1.923 &   2.397 &   2.047 \\\\\n",
      "$p$-value                       &       0 &       0 &       0 \\\\\n",
      "Obs.                            &   36917 &   67332 &  117137 \\\\\n",
      "Type                            &  Lawyer &  Lawyer &  Lawyer \\\\\n",
      "Target, Pct Cite in Target MSA  &   0.094 &     0.1 &   0.115 \\\\\n",
      "Control, Pct Cite in Target MSA &   0.075 &   0.079 &   0.089 \\\\\n",
      "Ratio                           &    1.25 &   1.272 &   1.287 \\\\\n",
      "$p$-value                       &       0 &       0 &       0 \\\\\n",
      "Obs.                            &   22914 &   51837 &   85855 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(rt.to_latex(index=True, escape=False, column_format = \"lcccc\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. JTH Regression tables\n",
    "\n",
    "Code based on: https://sfengc7.stern.nyu.edu:8888/notebooks/patentdiffusion/201808Results/Reg1016/4a-CombinedResults-1026.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "regs = pickle.load(open(\"DataStore/2018-10/Reg1016/reg_model_1016.pkl\", \"rb\"))\n",
    "\n",
    "jr = pd.read_csv(\"DataStore/2018-11/JTHReg1112/jth_rep_reg_1112.csv\", index_col=0)\n",
    "\n",
    "# Other regressions\n",
    "rr = pd.read_csv(\"DataStore/2018-10/Reg1016/reg_pairs_out_HC1_1016.csv\",index_col=0)\n",
    "\n",
    "# Change samp\n",
    "rr[\"samp\"] = rr[\"samp\"].apply(lambda x: eval(x)[1]+\"-\"+eval(x)[0])\n",
    "\n",
    "rr = pd.concat([jr,rr],axis=0)\n",
    "# Reset index\n",
    "rr = rr.reset_index(drop=True)\n",
    "\n",
    "# Equation id\n",
    "rr[\"id\"] = [\"({0}, {1}, {2})\".format(i,j,k) for i,j,k in zip(rr[\"samp\"], rr[\"LKS\"], rr[\"Model\"])]\n",
    "rr[\"id\"] = rr[\"id\"].astype(str)\n",
    "\n",
    "# Add S.E.\n",
    "# S.E. index\n",
    "se_ind = rr.loc[rr[\"index\"].isnull()].index.tolist()\n",
    "\n",
    "for ind in se_ind:\n",
    "    rr.loc[ind, \"index\"] = \"SE {0}\".format(rr.loc[ind-1, \"index\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "j_ind_pc = [\n",
    "    '(JTH Rep-PC, norm_perc_match_10, N PC FE-Year FE)',\n",
    "    '(JTH Rep-Sim, norm_perc_match_10, N PC FE-Year FE)',\n",
    "    '(JTH Rep-Lawyer, norm_perc_match_10, N PC FE-Year FE)'\n",
    "]\n",
    "j_ind_ex = [\n",
    "    '(JTH Rep-PC, norm_perc_match_10, N Examiner FE-Year FE)',\n",
    "    '(JTH Rep-Sim, norm_perc_match_10, N Examiner FE-Year FE)',\n",
    "    '(JTH Rep-Lawyer, norm_perc_match_10, N Examiner FE-Year FE)'\n",
    "]\n",
    "mod_n =  [\"Control Selection: Standard JTH\", \"Control Selection: Similarity\", \"Control Selection: Lawyer\"]\n",
    "mod_dict = dict(zip(j_ind_pc, mod_n))\n",
    "mod_dict.update(dict(zip(j_ind_ex, mod_n)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Localization estimates\n",
    "t = {}\n",
    "for l in [(\"PC\", j_ind_pc), (\"Examiner\", j_ind_ex)]:\n",
    "    rc = rr.loc[rr[\"id\"].isin(l[1]) & rr[\"index\"].isin([\"C(inv_msa_match)[T.True]\",\\\n",
    "            \"SE C(inv_msa_match)[T.True]\", \"$N$\", \"Adjusted $R^2$\"])].copy()\n",
    "    rc[\"id\"] = rc[\"id\"].map(mod_dict)\n",
    "    rc.loc[rc[\"index\"].isin([\"$N$\", \"Adjusted $R^2$\"]), \"id\"] =\\\n",
    "    rc.loc[rc[\"index\"].isin([\"$N$\", \"Adjusted $R^2$\"]), \"index\"]\n",
    "    # Fixed effects columns\n",
    "    rc[\"Year \\& PC FE\"] = \"\"\n",
    "    rc[\"Other Controls\"] = \"\"\n",
    "    rc.loc[(rc[\"index\"] == \"SE C(inv_msa_match)[T.True]\"), ['id']] = \"\"\n",
    "    rc.loc[(rc[\"index\"] == \"C(inv_msa_match)[T.True]\"), [\"Year \\& PC FE\"]] = True\n",
    "    rc.loc[(rc[\"index\"] == \"C(inv_msa_match)[T.True]\"), [\"Other Controls\"]] = False\n",
    "    # cols = ['id', '1975-85', '1985-95', '1995-05', '2005-15', \"Year \\& PC FE\", \"Other Controls\"]\n",
    "    cols = ['id', '1975-85', '1985-95', '1995-05']\n",
    "    rc = rc[cols]\n",
    "    rc = rc.rename(columns={\"id\": \"\"})\n",
    "    t[l[0]] = rc\n",
    "t1 = t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PC\n",
      "\\begin{tabular}{lccc}\n",
      "\\toprule\n",
      "                                 &    1975-85 &    1985-95 &    1995-05 \\\\\n",
      "\\midrule\n",
      " Control Selection: Standard JTH &  0.2422*** &  0.2849*** &  0.2968*** \\\\\n",
      "                                 &   (0.0074) &   (0.0051) &   (0.0041) \\\\\n",
      "                             $N$ &      58647 &     107358 &     185154 \\\\\n",
      "                  Adjusted $R^2$ &       0.03 &       0.05 &       0.05 \\\\\n",
      "   Control Selection: Similarity &  0.2029*** &  0.2681*** &  0.2621*** \\\\\n",
      "                                 &   (0.0100) &   (0.0067) &   (0.0054) \\\\\n",
      "                             $N$ &      36917 &      67332 &     117137 \\\\\n",
      "                  Adjusted $R^2$ &       0.02 &       0.03 &       0.04 \\\\\n",
      "       Control Selection: Lawyer &  0.0806*** &  0.0935*** &  0.1150*** \\\\\n",
      "                                 &   (0.0136) &   (0.0086) &   (0.0069) \\\\\n",
      "                             $N$ &      22914 &      51837 &      85855 \\\\\n",
      "                  Adjusted $R^2$ &       0.02 &       0.03 &       0.03 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n",
      "Examiner\n",
      "\\begin{tabular}{lccc}\n",
      "\\toprule\n",
      "                                 &    1975-85 &    1985-95 &    1995-05 \\\\\n",
      "\\midrule\n",
      " Control Selection: Standard JTH &  0.2340*** &  0.2783*** &  0.2864*** \\\\\n",
      "                                 &   (0.0073) &   (0.0050) &   (0.0040) \\\\\n",
      "                             $N$ &      58647 &     107358 &     185154 \\\\\n",
      "                  Adjusted $R^2$ &       0.04 &       0.06 &       0.08 \\\\\n",
      "   Control Selection: Similarity &  0.1983*** &  0.2656*** &  0.2633*** \\\\\n",
      "                                 &   (0.0100) &   (0.0067) &   (0.0053) \\\\\n",
      "                             $N$ &      36917 &      67332 &     117137 \\\\\n",
      "                  Adjusted $R^2$ &       0.04 &       0.06 &       0.08 \\\\\n",
      "       Control Selection: Lawyer &  0.0842*** &  0.0916*** &  0.1119*** \\\\\n",
      "                                 &   (0.0136) &   (0.0086) &   (0.0068) \\\\\n",
      "                             $N$ &      22914 &      51837 &      85855 \\\\\n",
      "                  Adjusted $R^2$ &       0.05 &       0.06 &       0.08 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for k,v in t1.items():\n",
    "    print(k)\n",
    "    print(v.to_latex(index=False, escape=False, column_format=\"lccc\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NAICS and PC Samples\n",
    "\n",
    "### 1. Summary of average similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "rt = pd.DataFrame()\n",
    "y = \"sim_docvecs\"\n",
    "for k in [\"naics_name\", \"primclass\"]:\n",
    "    v = fastparquet.ParquetFile(\"DataStore/2018-10/Reg1016/{0}_all_1016.parq\".format(k)).to_pandas()\n",
    "    v2 = v[[y, \"year_group\", \"inv_msa_match\"]].groupby([\"year_group\", \"inv_msa_match\"]).mean().reset_index()\n",
    "    \n",
    "    t_pct = {n:g[y].values for n,g in v.loc[v[\"inv_msa_match\"] == True, [\"year_group\", y]].groupby(\"year_group\")}\n",
    "    c_pct = {n:g[y].values for n,g in v.loc[v[\"inv_msa_match\"] == False, [\"year_group\", y]].groupby(\"year_group\")}\n",
    "    \n",
    "    tc = v2.loc[v2[\"inv_msa_match\"] == True, y].values\n",
    "    cc = v2.loc[v2[\"inv_msa_match\"] == False, y].values\n",
    "    yg = v2.loc[v2[\"inv_msa_match\"] == True, \"year_group\"].values\n",
    "    p = [sp.stats.ttest_ind(t_pct[k], c_pct[k], equal_var=False, nan_policy=\"omit\")[1] for k in t_pct.keys()] \n",
    "    n = v[[y, \"year_group\"]].groupby([\"year_group\"]).size().values\n",
    "    ind = [\"Type\", \"Within Cluster, $I(MSA\\,Match)=1$\", \"Across Cluster, $I(MSA\\,Match)=0$\", \"Ratio\", \"$p$-value\", \"$N$\"]\n",
    "    \n",
    "    r = pd.DataFrame({\"Year Group\": yg,\n",
    "                      \"Within Cluster, $I(MSA\\,Match)=1$\": tc, \n",
    "                      \"Across Cluster, $I(MSA\\,Match)=0$\": cc, \n",
    "                      \"$p$-value\": p, \"$N$\": n})\n",
    "    \n",
    "#     r = r.loc[r[\"Year Group\"] != \"2005-15\"].set_index(\"Year Group\")\n",
    "    r = r.set_index(\"Year Group\")\n",
    "    \n",
    "    r[\"Ratio\"] = r[\"Within Cluster, $I(MSA\\,Match)=1$\"]/r[\"Across Cluster, $I(MSA\\,Match)=0$\"]\n",
    "    r = r.round(3)\n",
    "    r[\"Type\"] = k\n",
    "    \n",
    "    r = r[ind].T\n",
    "    r.loc[\"$N$\"] = r.loc[\"$N$\"].astype(int).astype(str)\n",
    "    rt = rt.append(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lcccc}\n",
      "\\toprule\n",
      "Year Group &     1975-85 &     1985-95 &     1995-05 &     2005-15 \\\\\n",
      "\\midrule\n",
      "Type                              &  naics_name &  naics_name &  naics_name &  naics_name \\\\\n",
      "Within Cluster, $I(MSA\\,Match)=1$ &       0.127 &       0.127 &       0.133 &       0.145 \\\\\n",
      "Across Cluster, $I(MSA\\,Match)=0$ &       0.124 &        0.12 &       0.125 &       0.137 \\\\\n",
      "Ratio                             &        1.02 &       1.059 &       1.062 &       1.056 \\\\\n",
      "$p$-value                         &       0.001 &           0 &           0 &           0 \\\\\n",
      "$N$                               &      194131 &      282112 &      443885 &      578056 \\\\\n",
      "Type                              &   primclass &   primclass &   primclass &   primclass \\\\\n",
      "Within Cluster, $I(MSA\\,Match)=1$ &       0.197 &       0.193 &       0.195 &       0.197 \\\\\n",
      "Across Cluster, $I(MSA\\,Match)=0$ &        0.19 &       0.182 &       0.184 &       0.188 \\\\\n",
      "Ratio                             &       1.036 &       1.059 &       1.063 &       1.044 \\\\\n",
      "$p$-value                         &           0 &           0 &           0 &           0 \\\\\n",
      "$N$                               &      171893 &      252886 &      407176 &      537878 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(rt.to_latex(index=True, escape=False, column_format = \"lcccc\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Summary including variance\n",
    "- Testing significant difference in variance: https://stackoverflow.com/questions/21494141/how-do-i-do-a-f-test-in-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "rt = pd.DataFrame()\n",
    "y = \"sim_docvecs\"\n",
    "for k in [\"naics_name\", \"primclass\"]:\n",
    "    v = fastparquet.ParquetFile(\"DataStore/2018-10/Reg1016/{0}_all_1016.parq\".format(k)).to_pandas()\n",
    "    v = v.dropna(subset=[y])\n",
    "    v2 = v[[y, \"year_group\", \"inv_msa_match\"]].groupby([\"year_group\", \"inv_msa_match\"]).mean().reset_index()\n",
    "    v3 = v[[y, \"year_group\", \"inv_msa_match\"]].groupby([\"year_group\", \"inv_msa_match\"]).std().reset_index()\n",
    "    \n",
    "    t_pct = {n:g[y].values for n,g in v.loc[v[\"inv_msa_match\"] == True, [\"year_group\", y]].groupby(\"year_group\")}\n",
    "    c_pct = {n:g[y].values for n,g in v.loc[v[\"inv_msa_match\"] == False, [\"year_group\", y]].groupby(\"year_group\")}\n",
    "    \n",
    "    tc = v2.loc[v2[\"inv_msa_match\"] == True, y].values\n",
    "    cc = v2.loc[v2[\"inv_msa_match\"] == False, y].values\n",
    "    \n",
    "    tsd = v3.loc[v3[\"inv_msa_match\"] == True, y].values\n",
    "    csd = v3.loc[v3[\"inv_msa_match\"] == False, y].values\n",
    "    \n",
    "    yg = v2.loc[v2[\"inv_msa_match\"] == True, \"year_group\"].values\n",
    "    # Equal means\n",
    "    p = [sp.stats.ttest_ind(t_pct[k], c_pct[k], equal_var=False, nan_policy=\"omit\")[1] for k in t_pct.keys()] \n",
    "    # Equal variance: F\n",
    "    F = [sp.stats.f.sf(np.var(t_pct[k])/np.var(c_pct[k]), len(t_pct[k])-1, len(c_pct[k])-1) for k in t_pct.keys()]\n",
    "    # Equal variance: Levene\n",
    "    L = [sp.stats.levene(t_pct[k], c_pct[k])[1] for k in t_pct.keys()]\n",
    "    \n",
    "    # Population size\n",
    "    t_n = [len(t_pct[k]) for k in t_pct.keys()]\n",
    "    c_n = [len(c_pct[k]) for k in c_pct.keys()]\n",
    "    \n",
    "    ind = [\"Type\", \"Within Cluster, $I(MSA\\,Match)=1$\", \"Within Cluster, S.D.\", \"Within Cluster, $N$\",\n",
    "           \"Across Clusters, $I(MSA\\,Match)=0$\", \"Across Clusters, S.D.\", \"Across Clusters, $N$\", \"Ratio\",\n",
    "           \"$p$-value, Equal Means\",\n",
    "           \"$p$-value, Equal Var (F-test)\",\"$p$-value, Equal Var (Levene)\"]\n",
    "    \n",
    "    r = pd.DataFrame({\"Year Group\": yg,\n",
    "                      \"Within Cluster, $I(MSA\\,Match)=1$\": tc,\n",
    "                      \"Within Cluster, S.D.\": tsd,\n",
    "                      \"Within Cluster, $N$\": t_n,\n",
    "                      \"Across Clusters, $I(MSA\\,Match)=0$\": cc,\n",
    "                      \"Across Clusters, S.D.\": csd,\n",
    "                      \"Across Clusters, $N$\": c_n,\n",
    "                      \"$p$-value, Equal Means\": p,\n",
    "                      \"$p$-value, Equal Var (F-test)\": F,\n",
    "                      \"$p$-value, Equal Var (Levene)\": L,\n",
    "                      })\n",
    "    \n",
    "#     r = r.loc[r[\"Year Group\"] != \"2005-15\"].set_index(\"Year Group\")\n",
    "    r = r.set_index(\"Year Group\")\n",
    "    \n",
    "    r[\"Ratio\"] = r[\"Within Cluster, $I(MSA\\,Match)=1$\"]/r[\"Across Clusters, $I(MSA\\,Match)=0$\"]\n",
    "    r = r.round(3)\n",
    "    r[\"Type\"] = k\n",
    "    \n",
    "    r = r[ind].T\n",
    "    r.loc[\"Across Clusters, $N$\"] = r.loc[\"Across Clusters, $N$\"].astype(int).astype(str)\n",
    "    r.loc[\"Within Cluster, $N$\"] = r.loc[\"Within Cluster, $N$\"].astype(int).astype(str)\n",
    "    rt = rt.append(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lcccc}\n",
      "\\toprule\n",
      "Year Group &     1975-85 &     1985-95 &     1995-05 &     2005-15 \\\\\n",
      "\\midrule\n",
      "Type                               &  naics_name &  naics_name &  naics_name &  naics_name \\\\\n",
      "Within Cluster, $I(MSA\\,Match)=1$  &       0.127 &       0.127 &       0.133 &       0.145 \\\\\n",
      "Within Cluster, S.D.               &       0.137 &       0.135 &       0.135 &       0.137 \\\\\n",
      "Within Cluster, $N$                &       45804 &       66749 &      106800 &      143309 \\\\\n",
      "Across Clusters, $I(MSA\\,Match)=0$ &       0.124 &        0.12 &       0.125 &       0.137 \\\\\n",
      "Across Clusters, S.D.              &       0.136 &       0.133 &       0.133 &       0.135 \\\\\n",
      "Across Clusters, $N$               &      147037 &      214473 &      330885 &      425943 \\\\\n",
      "Ratio                              &        1.02 &       1.059 &       1.062 &       1.056 \\\\\n",
      "$p$-value, Equal Means             &       0.001 &           0 &           0 &           0 \\\\\n",
      "$p$-value, Equal Var (F-test)      &       0.001 &           0 &           0 &           0 \\\\\n",
      "$p$-value, Equal Var (Levene)      &       0.011 &           0 &           0 &           0 \\\\\n",
      "Type                               &   primclass &   primclass &   primclass &   primclass \\\\\n",
      "Within Cluster, $I(MSA\\,Match)=1$  &       0.197 &       0.193 &       0.195 &       0.197 \\\\\n",
      "Within Cluster, S.D.               &       0.147 &       0.142 &       0.141 &       0.141 \\\\\n",
      "Within Cluster, $N$                &       30816 &       47927 &       85071 &      120795 \\\\\n",
      "Across Clusters, $I(MSA\\,Match)=0$ &        0.19 &       0.182 &       0.184 &       0.188 \\\\\n",
      "Across Clusters, S.D.              &       0.139 &       0.137 &       0.136 &       0.138 \\\\\n",
      "Across Clusters, $N$               &      140066 &      204247 &      316552 &      408891 \\\\\n",
      "Ratio                              &       1.036 &       1.059 &       1.063 &       1.044 \\\\\n",
      "$p$-value, Equal Means             &           0 &           0 &           0 &           0 \\\\\n",
      "$p$-value, Equal Var (F-test)      &           0 &           0 &           0 &           0 \\\\\n",
      "$p$-value, Equal Var (Levene)      &           0 &           0 &           0 &           0 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(rt.to_latex(index=True, escape=False, column_format = \"lcccc\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = fastparquet.ParquetFile(\"DataStore/2018-10/Reg1016/naics_name_all_1016.parq\").to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['tp', 'op', 'sim_docvecs', 'sim_ldavecs', 'tp_gyear', 'tp_naics_name',\n",
       "       'op_naics_name', 'op_primclass', 'op_inv_msa', 'inv_msa_match',\n",
       "       'primclass_match', 'norm_sim_ldavecs', 'norm_sim_docvecs', 'year_group',\n",
       "       'common_est_inv', 'common_pat_inv', 'lawyer_match', 'num_common_cited',\n",
       "       'norm_num_common_cited', 'tp_pct_common_cited',\n",
       "       'norm_tp_pct_common_cited', 'common_cited_match', 'common_npc_match',\n",
       "       'mean_sim_docvecs_pc', 'mean_sim_ldavecs_pc', 'mean_sim_docvecs_pc_msa',\n",
       "       'mean_sim_ldavecs_pc_msa', 'norm_mean_sim_docvecs_pc',\n",
       "       'norm_mean_sim_ldavecs_pc', 'norm_mean_sim_docvecs_pc_msa',\n",
       "       'norm_mean_sim_ldavecs_pc_msa', 'sd_sim_docvecs_pc',\n",
       "       'sd_sim_ldavecs_pc', 'sd_sim_docvecs_pc_msa', 'sd_sim_ldavecs_pc_msa',\n",
       "       'pc_msa_greater_0', 'pc_msa_less_0', 'num_common_npc',\n",
       "       'norm_num_common_npc', 'tp_primclass_FE', 'tp_inv_msa_FE',\n",
       "       'tp_examiner_FE', 'tp_lawyer_FE', 'examiner_match'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
