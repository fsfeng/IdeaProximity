{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy as sp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import timeit\n",
    "import re\n",
    "import json\n",
    "import pickle\n",
    "import fastparquet\n",
    "import os\n",
    "os.chdir('/mnt/t48/bighomes-active/sfeng/patentdiffusion/')\n",
    "seed = 3\n",
    "import seaborn as sns\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "import datetime\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "import statsmodels.iolib.summary2 as summary2\n",
    "import logging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Convert dataset to long for regression\n",
    "- Code for include other variables from here: https://sfengc7.stern.nyu.edu:8888/notebooks/patentdiffusion/201808Results/Reg1016/1-NewDataReg.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = {}\n",
    "ts1 = pd.read_pickle(\"DataStore/2018-07-P3/JTHReg0727/targ_cite_sim_reg_0727.pkl\")\n",
    "ts2 = pd.read_pickle(\"DataStore/2018-11/closest_nbr_control_1108.pkl\")[[\"tp\", \"closest_pat\", \"tp_match_10\", \"closest_pat_match\"]]\n",
    "ts2 = ts2.rename(columns={\"closest_pat\": \"cp\", \"closest_pat_match\": \"cp_match_10\"})\n",
    "ts[\"Sim\"] = ts2\n",
    "ts3 = pd.read_pickle(\"DataStore/2018-11/jth_rep_lawyers_control_1109.pkl\")[[\"tp\", \"tp_match_10\", \"lawyer_cp\", \"lawyer_cp_match_10\"]]\n",
    "ts3 = ts3.rename(columns={\"lawyer_cp\": \"cp\", \"lawyer_cp_match_10\": \"cp_match_10\"})\n",
    "ts[\"Lawyer\"] = ts3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsl = {}\n",
    "for k,v in ts.items():\n",
    "    tdf = v[[\"tp\", \"tp_match_10\"]].rename(columns={\"tp\": \"patent\", \"tp_match_10\": \"perc_match_10\"})\n",
    "    tdf[\"inv_msa_match\"] = True\n",
    "    cdf = v[[\"cp\", \"cp_match_10\"]].rename(columns={\"cp\": \"patent\", \"cp_match_10\": \"perc_match_10\"})\n",
    "    cdf[\"inv_msa_match\"] = False\n",
    "    tdf = tdf.append(cdf, ignore_index=True).reset_index(drop=True)\n",
    "    \n",
    "    tdf = tdf.dropna(how=\"any\")\n",
    "    tdf[\"patent\"] = tdf[\"patent\"].astype(int)\n",
    "    tsl[k] = tdf\n",
    "    del(tdf)\n",
    "    \n",
    "# Add original replication\n",
    "ts1[\"inv_msa_match\"] = ts1[\"inv_msa_match\"].astype(bool)\n",
    "ts1 = ts1.loc[ts1[\"perc_match_10\"].notnull()]\n",
    "tsl[\"PC\"] = ts1[[\"patent\", \"perc_match_10\", \"inv_msa_match\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add fixed effects and normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/homedir/eco/sfeng/bigdata/python/miniconda3/lib/python3.6/site-packages/numpy/lib/arraysetops.py:522: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n"
     ]
    }
   ],
   "source": [
    "pats_used = tsl[\"Sim\"][\"patent\"].tolist() + tsl[\"Lawyer\"][\"patent\"].tolist() + tsl[\"PC\"][\"patent\"].tolist()\n",
    "pats_used = np.unique(pats_used)\n",
    "\n",
    "# Patent examiner\n",
    "pe = fastparquet.ParquetFile(\"RawData/Cleaned/patexaminer1016.parq\").to_pandas()\n",
    "\n",
    "# Patent lawyers\n",
    "ld = pd.read_csv(\"RawData/Cleaned/patent_lawyer.csv\", index_col=0).drop_duplicates(\"patent\")\n",
    "\n",
    "# Top values\n",
    "topn = {}\n",
    "topn[\"examiner\"] = re[\"examiner_id\"].value_counts()[:100].index.tolist()\n",
    "topn[\"lawyer\"] = ld[\"lawyer_id\"].value_counts()[:100].index.tolist()\n",
    "\n",
    "# Use only what's in data\n",
    "pe = pe.loc[pe[\"patent_id\"].isin(pats_used)]\n",
    "ld = ld.loc[ld[\"patent\"].isin(pats_used)]\n",
    "\n",
    "pe = dict(zip(pe[\"patent_id\"], pe[\"examiner_id\"]))\n",
    "ld = dict(zip(ld[\"patent\"], ld[\"lawyer_id\"]))\n",
    "\n",
    "# Top MSAs & Primary classes\n",
    "pdf = fastparquet.ParquetFile(\"RawData/Cleaned/patent_loc_unique_us_0628.parq\").to_pandas([\"patent\", \"gyear\", \"primclass\", \"inv_msa\"])\n",
    "dup_pats = pd.read_pickle(\"RawData/Cleaned/duplicate_pattext_0712.pkl\").tolist()\n",
    "# Get relevant US Patents\n",
    "pdf = pdf.loc[~pdf[\"patent\"].isin(dup_pats)]\n",
    "\n",
    "topn[\"inv_msa\"] = pdf[\"inv_msa\"].value_counts()[:100].index.tolist()\n",
    "topn[\"primclass\"] = pdf[\"primclass\"].value_counts()[:100].index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:507870\n",
      "INFO:root:other    13746\n",
      "514.0     7543\n",
      "370.0     6470\n",
      "438.0     5762\n",
      "435.0     5705\n",
      "424.0     5174\n",
      "709.0     5124\n",
      "455.0     4934\n",
      "428.0     4833\n",
      "600.0     4704\n",
      "Name: tp_primclass_FE, dtype: int64\n",
      "INFO:root:other                                                 52674\n",
      "San Jose-Sunnyvale-Santa Clara, CA                    24057\n",
      "New York-Northern New Jersey-Long Island, NY-NJ-PA    21487\n",
      "Los Angeles-Long Beach-Santa Ana, CA                  16811\n",
      "San Francisco-Oakland-Fremont, CA                     15909\n",
      "Boston-Cambridge-Quincy, MA-NH                        13337\n",
      "Chicago-Joliet-Naperville, IL-IN-WI                   12742\n",
      "Detroit-Warren-Livonia, MI                             7925\n",
      "Minneapolis-St. Paul-Bloomington, MN-WI                7836\n",
      "Philadelphia-Camden-Wilmington, PA-NJ-DE-MD            7662\n",
      "Name: tp_inv_msa_FE, dtype: int64\n",
      "INFO:root:other                                       299881\n",
      "6de8dd1fabc379f2470e51f0d7613a78fb8add9e       535\n",
      "5dacd224066974a5b4abfe1c143f7544c6bb136c       464\n",
      "c1b51fc89c11ff4c7ec7f64e20ba5582f07ba3be       457\n",
      "a09d2b4594182ef8e16f3ae3b56476d55b2468fe       410\n",
      "e668b1af996324dcc1a77358fee76f6ed2b755cc       406\n",
      "25370a5b5cd238cec5a8c2eab99a1b27a0456c2c       398\n",
      "ea22c43e01bb0f2b32624967aa324084c83bb518       392\n",
      "5c12cedbe38f64278f4f8119d93c7013e5ef0c28       347\n",
      "6e277cf5dfee7df134b4bfbcc790381777529c1d       340\n",
      "Name: tp_examiner_FE, dtype: int64\n",
      "INFO:root:other                               291219\n",
      "666431f7aa7b06c9492d942543c7a273      2226\n",
      "a234863ccc5d44e13ecc289e7c27fa46      1726\n",
      "eb3ffd02919a1cba6ee7babba852fad5      1155\n",
      "3e652e4691792b59c38e944dde008ce0       959\n",
      "3db397f22635c783118b81804bf3b569       925\n",
      "1e16e011b0e768f8fc115cca2c811586       870\n",
      "625d08ced6dc24afc859b4bf1241db73       784\n",
      "1910defa94caf5de27665d297d08adc4       666\n",
      "5b0ea205f5ee633e48e994156cdebcd9       606\n",
      "Name: tp_lawyer_FE, dtype: int64\n",
      "INFO:root:other    15381\n",
      "370.0     6384\n",
      "514.0     6318\n",
      "435.0     5849\n",
      "709.0     5349\n",
      "424.0     5149\n",
      "600.0     4761\n",
      "438.0     4650\n",
      "606.0     4405\n",
      "604.0     4310\n",
      "Name: tp_primclass_FE, dtype: int64\n",
      "INFO:root:other                                                 53430\n",
      "San Jose-Sunnyvale-Santa Clara, CA                    20567\n",
      "San Francisco-Oakland-Fremont, CA                     14484\n",
      "New York-Northern New Jersey-Long Island, NY-NJ-PA    14188\n",
      "Los Angeles-Long Beach-Santa Ana, CA                  12505\n",
      "Boston-Cambridge-Quincy, MA-NH                        10528\n",
      "Chicago-Joliet-Naperville, IL-IN-WI                    8801\n",
      "Detroit-Warren-Livonia, MI                             5801\n",
      "San Diego-Carlsbad-San Marcos, CA                      5801\n",
      "Seattle-Tacoma-Bellevue, WA                            5759\n",
      "Name: tp_inv_msa_FE, dtype: int64\n",
      "INFO:root:other                                       234280\n",
      "6de8dd1fabc379f2470e51f0d7613a78fb8add9e       504\n",
      "c1b51fc89c11ff4c7ec7f64e20ba5582f07ba3be       452\n",
      "a09d2b4594182ef8e16f3ae3b56476d55b2468fe       405\n",
      "5dacd224066974a5b4abfe1c143f7544c6bb136c       402\n",
      "25370a5b5cd238cec5a8c2eab99a1b27a0456c2c       390\n",
      "e668b1af996324dcc1a77358fee76f6ed2b755cc       383\n",
      "2ddb6f309b038df3ae3a05d8ab955ebd0d68c9a3       371\n",
      "a21496f661c7a6e59ee6ebe915fbce2085946184       346\n",
      "c818cfad7894861e6114b56e2b464127e9f67052       341\n",
      "Name: tp_examiner_FE, dtype: int64\n",
      "INFO:root:other                               208211\n",
      "666431f7aa7b06c9492d942543c7a273      3165\n",
      "a234863ccc5d44e13ecc289e7c27fa46      2537\n",
      "eb3ffd02919a1cba6ee7babba852fad5      1768\n",
      "3e652e4691792b59c38e944dde008ce0      1459\n",
      "3db397f22635c783118b81804bf3b569      1437\n",
      "1e16e011b0e768f8fc115cca2c811586      1269\n",
      "625d08ced6dc24afc859b4bf1241db73      1115\n",
      "453d6d9f53931a11e721618126f194a8       945\n",
      "1910defa94caf5de27665d297d08adc4       922\n",
      "Name: tp_lawyer_FE, dtype: int64\n",
      "INFO:root:other    21841\n",
      "370.0    10612\n",
      "514.0     8932\n",
      "709.0     8555\n",
      "438.0     8472\n",
      "435.0     8460\n",
      "428.0     8137\n",
      "600.0     8060\n",
      "455.0     7982\n",
      "424.0     7897\n",
      "Name: tp_primclass_FE, dtype: int64\n",
      "INFO:root:other                                                 86136\n",
      "San Jose-Sunnyvale-Santa Clara, CA                    35304\n",
      "New York-Northern New Jersey-Long Island, NY-NJ-PA    33021\n",
      "Los Angeles-Long Beach-Santa Ana, CA                  27123\n",
      "San Francisco-Oakland-Fremont, CA                     24507\n",
      "Boston-Cambridge-Quincy, MA-NH                        20840\n",
      "Chicago-Joliet-Naperville, IL-IN-WI                   19901\n",
      "Minneapolis-St. Paul-Bloomington, MN-WI               12193\n",
      "Seattle-Tacoma-Bellevue, WA                           11968\n",
      "Detroit-Warren-Livonia, MI                            11671\n",
      "Name: tp_inv_msa_FE, dtype: int64\n",
      "INFO:root:other                                       473192\n",
      "6de8dd1fabc379f2470e51f0d7613a78fb8add9e       909\n",
      "c1b51fc89c11ff4c7ec7f64e20ba5582f07ba3be       795\n",
      "5dacd224066974a5b4abfe1c143f7544c6bb136c       733\n",
      "a09d2b4594182ef8e16f3ae3b56476d55b2468fe       701\n",
      "25370a5b5cd238cec5a8c2eab99a1b27a0456c2c       647\n",
      "2ddb6f309b038df3ae3a05d8ab955ebd0d68c9a3       616\n",
      "ea22c43e01bb0f2b32624967aa324084c83bb518       615\n",
      "e668b1af996324dcc1a77358fee76f6ed2b755cc       607\n",
      "5c12cedbe38f64278f4f8119d93c7013e5ef0c28       593\n",
      "Name: tp_examiner_FE, dtype: int64\n",
      "INFO:root:other                               461308\n",
      "666431f7aa7b06c9492d942543c7a273      3252\n",
      "a234863ccc5d44e13ecc289e7c27fa46      2527\n",
      "eb3ffd02919a1cba6ee7babba852fad5      1758\n",
      "3e652e4691792b59c38e944dde008ce0      1451\n",
      "3db397f22635c783118b81804bf3b569      1429\n",
      "1e16e011b0e768f8fc115cca2c811586      1262\n",
      "625d08ced6dc24afc859b4bf1241db73      1204\n",
      "1910defa94caf5de27665d297d08adc4      1026\n",
      "5b0ea205f5ee633e48e994156cdebcd9       982\n",
      "Name: tp_lawyer_FE, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Scaler: Normalize on JTH control and target\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "tsl[\"PC\"] = tsl[\"PC\"].loc[tsl[\"PC\"][\"perc_match_10\"].notnull()]\n",
    "print(len(tsl[\"PC\"]))\n",
    "scaler.fit(tsl[\"PC\"][\"perc_match_10\"].values.reshape(-1,1))\n",
    "\n",
    "# Get year group\n",
    "def get_year_group_10(x):\n",
    "    if x in range(1975,1985):\n",
    "        yg = \"1975-85\"\n",
    "    elif x in range(1985,1995):\n",
    "        yg = \"1985-95\"\n",
    "    elif x in range(1995, 2005):\n",
    "        yg = \"1995-05\"\n",
    "    elif x in range(2005,2015):\n",
    "        yg = \"2005-15\"\n",
    "    else:\n",
    "        yg = np.nan\n",
    "    return yg\n",
    "\n",
    "for k,v in tsl.items():\n",
    "    rs = v\n",
    "    rs[\"tp_gyear\"] = rs[\"patent\"].map(dict(zip(pdf[\"patent\"], pdf[\"gyear\"])))\n",
    "    rs[\"tp_inv_msa\"] = rs[\"patent\"].map(dict(zip(pdf[\"patent\"], pdf[\"inv_msa\"])))\n",
    "    rs[\"tp_primclass\"] = rs[\"patent\"].map(dict(zip(pdf[\"patent\"], pdf[\"primclass\"])))\n",
    "    rs[\"tp_examiner\"] = rs[\"patent\"].map(pe)\n",
    "    rs[\"tp_lawyer\"] = rs[\"patent\"].map(ld)\n",
    "    \n",
    "    for c in [\"primclass\", \"inv_msa\", \"examiner\", \"lawyer\"]:\n",
    "        rs[\"tp_{0}_FE\".format(c)] = rs[\"tp_{0}\".format(c)].astype(str)\n",
    "        rs.loc[~(rs[\"tp_{0}\".format(c)].isin(topn[c])), \"tp_{0}_FE\".format(c)] = \"other\"\n",
    "\n",
    "        print(rs[\"tp_{0}_FE\".format(c)].value_counts()[:10])\n",
    "        # Drop original\n",
    "        try:\n",
    "            rs = rs.drop(\"tp_{0}\".format(c), 1)\n",
    "        except Exception:\n",
    "            pass\n",
    "    \n",
    "    # Normalize perc cite match\n",
    "    rs = rs.loc[rs[\"perc_match_10\"].notnull()]\n",
    "    npm = scaler.transform(rs[\"perc_match_10\"].values.reshape(-1,1))\n",
    "    rs[\"norm_perc_match_10\"] = npm\n",
    "    \n",
    "    # Add year group\n",
    "    rs[\"year_group\"] = rs[\"tp_gyear\"].apply(get_year_group_10)\n",
    "    tsl[k] = rs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "del(pdf, pe, ld)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(tsl, open(\"DataStore/2018-11/jth_rep_control_long_dict_1112.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Sim\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>perc_match_10</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>year_group</th>\n",
       "      <th>inv_msa_match</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">1975-85</th>\n",
       "      <th>False</th>\n",
       "      <td>0.047628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>0.091571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">1985-95</th>\n",
       "      <th>False</th>\n",
       "      <td>0.040534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>0.097179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">1995-05</th>\n",
       "      <th>False</th>\n",
       "      <td>0.053538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>0.109568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">2005-15</th>\n",
       "      <th>False</th>\n",
       "      <td>0.062872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>0.129871</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          perc_match_10\n",
       "year_group inv_msa_match               \n",
       "1975-85    False               0.047628\n",
       "           True                0.091571\n",
       "1985-95    False               0.040534\n",
       "           True                0.097179\n",
       "1995-05    False               0.053538\n",
       "           True                0.109568\n",
       "2005-15    False               0.062872\n",
       "           True                0.129871"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Lawyer\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>perc_match_10</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>year_group</th>\n",
       "      <th>inv_msa_match</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">1975-85</th>\n",
       "      <th>False</th>\n",
       "      <td>0.075001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>0.093784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">1985-95</th>\n",
       "      <th>False</th>\n",
       "      <td>0.078928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>0.100434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">1995-05</th>\n",
       "      <th>False</th>\n",
       "      <td>0.088992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>0.114550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">2005-15</th>\n",
       "      <th>False</th>\n",
       "      <td>0.092595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>0.134609</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          perc_match_10\n",
       "year_group inv_msa_match               \n",
       "1975-85    False               0.075001\n",
       "           True                0.093784\n",
       "1985-95    False               0.078928\n",
       "           True                0.100434\n",
       "1995-05    False               0.088992\n",
       "           True                0.114550\n",
       "2005-15    False               0.092595\n",
       "           True                0.134609"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:PC\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>perc_match_10</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>year_group</th>\n",
       "      <th>inv_msa_match</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">1975-85</th>\n",
       "      <th>False</th>\n",
       "      <td>0.037690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>0.090860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">1985-95</th>\n",
       "      <th>False</th>\n",
       "      <td>0.034797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>0.097149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">1995-05</th>\n",
       "      <th>False</th>\n",
       "      <td>0.045208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>0.109797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">2005-15</th>\n",
       "      <th>False</th>\n",
       "      <td>0.055446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>0.130653</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          perc_match_10\n",
       "year_group inv_msa_match               \n",
       "1975-85    False               0.037690\n",
       "           True                0.090860\n",
       "1985-95    False               0.034797\n",
       "           True                0.097149\n",
       "1995-05    False               0.045208\n",
       "           True                0.109797\n",
       "2005-15    False               0.055446\n",
       "           True                0.130653"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Preview of results\n",
    "for k,v in tsl.items():\n",
    "    print(k)\n",
    "    display(v[[\"perc_match_10\", \"year_group\", \"inv_msa_match\"]].groupby([\"year_group\", \"inv_msa_match\"]).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Regression\n",
    "\n",
    "### 2.1 Specifying models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:good day to you madam fiona\n",
      "INFO:root:started\n",
      "INFO:root:2018-11-12 20:09:23.751297\n"
     ]
    }
   ],
   "source": [
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger.addHandler(logging.FileHandler('Logs/JTH_reg_{0}.log'.format(datetime.datetime.now().\\\n",
    "                                                            strftime(\"%Y-%m-%d\"), 'a')))\n",
    "print = logging.info\n",
    "print('good day to you madam fiona')\n",
    "print('started')\n",
    "print(datetime.datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "pathdir = \"DataStore/2018-11/JTHReg1112/\"\n",
    "regs = {}\n",
    "pc10 = {\n",
    "    \"PC FE-Year FE\": \"{0} ~ C(inv_msa_match) + C(tp_gyear) + C(tp_primclass_FE)\",\n",
    "    \"MSA FE-Year FE\": \"{0} ~ C(inv_msa_match) + C(tp_gyear) + C(tp_primclass_FE) + C(tp_inv_msa_FE)\",\n",
    "    \"Lawyer FE-Year FE\": \"{0} ~ C(inv_msa_match) + C(tp_gyear) + C(tp_primclass_FE)  + C(tp_inv_msa_FE)\\\n",
    "    + C(tp_lawyer_FE)\",\n",
    "    \"Examiner FE-Year FE\": \"{0} ~ C(inv_msa_match) + C(tp_gyear) + C(tp_primclass_FE) + C(tp_inv_msa_FE)\\\n",
    "    + C(tp_lawyer_FE) + C(tp_examiner_FE)\",\n",
    "}\n",
    "\n",
    "pc10_N = {\"N \"+k: \"norm_\"+v for k,v in pc10.items()}\n",
    "pc10.update(pc10_N)\n",
    "pc10 = {k: v.format(\"perc_match_10\") for k,v in pc10.items()}\n",
    "\n",
    "regs[\"JTH_model_names\"] = pd.Series(list(pc10.keys())) \n",
    "regs[\"JTH_cite\"] = pd.Series(list(pc10.values())) \n",
    "\n",
    "pickle.dump(regs, open(pathdir+\"reg_models_112.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "info_dict = {'$N$':lambda x: \"{0:d}\".format(int(x.nobs)),\n",
    "'Adjusted $R^2$':lambda x: \"{:.2f}\".format(x.rsquared_adj)}\n",
    "def get_fit(formula, grouped_data, group_col, cov_type = \"HC1\", return_fit = False):\n",
    "    summ = []\n",
    "    tables = {}\n",
    "    \n",
    "    # If formula uses mean similarity, use grant year above 1980\n",
    "    if \"mean_sim_\" in formula:\n",
    "        grouped_data = grouped_data.loc[(grouped_data[\"tp_gyear\"] >= 1980)]\n",
    "    \n",
    "    # Remove missing values used in formula\n",
    "    col_used = re.findall('\\((.*?)\\)',formula)\n",
    "    # Intersect with grouped_data columns\n",
    "    col_used = list(set(col_used).intersection(set(list(grouped_data.columns))))\n",
    "    print(col_used)\n",
    "    \n",
    "    grouped_data = grouped_data.dropna(how=\"any\", subset=col_used).copy().reset_index(drop=True)\n",
    "    \n",
    "    # Get length of data\n",
    "    print((\"Length of data\", len(grouped_data)))\n",
    "                                    \n",
    "    # Group and then get results\n",
    "    grouped_data = grouped_data.groupby(group_col)\n",
    "    \n",
    "    for n,g in grouped_data:\n",
    "        try:\n",
    "            if cov_type == \"HC1\":\n",
    "                fit = smf.ols(formula = formula, data = g, missing=\"drop\").fit(cov_type=\"HC1\")\n",
    "            else:\n",
    "                # Drop missing in the grouped data first\n",
    "                # Cluster uses primary class so must have primary class FE\n",
    "                cols_used2 = list(set(col_used).intersection(set(list(grouped_data.columns))))+[\"tp_primclass_FE\"]\n",
    "                g = g.dropna(subset=cols_used2, how=\"any\").copy().reset_index(drop=True)\n",
    "                fit = smf.ols(formula = formula, data = g).fit(cov_type=\"cluster\",\n",
    "                                                                              cov_kwds={'groups': g[\"tp_primclass_FE\"]})\n",
    "            # Get results tables\n",
    "            tables[n] = fit.summary2().tables\n",
    "            # Append results\n",
    "            summ.append(fit)\n",
    "        except Exception as e:\n",
    "            print(n)\n",
    "            logging.exception(\"Regression error\")\n",
    "            pass\n",
    "    # Get full results output\n",
    "    # Dataframe of full results\n",
    "    res_no_stars = summary2.summary_col(summ, stars = False, \\\n",
    "    model_names = [\"{0}\".format(n) for n in tables.keys()],\\\n",
    "        info_dict = info_dict).tables[0]\n",
    "    res_stars = summary2.summary_col(summ, stars = True, \\\n",
    "    model_names = [\"{0}\".format(n) for n in tables.keys()],\\\n",
    "        info_dict = info_dict).tables[0]\n",
    "    \n",
    "    # Get partial results\n",
    "    # 1. Get relevant variables from index of full results: UPDATED\n",
    "    regressors = [v for v in res_no_stars.index.unique() if (\"sim_\" in v) | (\"match\" in v) | (\"common_\" in v)]\n",
    "    # 2. Make sure regressors come last\n",
    "    regressors = regressors+[\"Intercept\"]\n",
    "    # 3. Get results with regressors\n",
    "    part_res_no_stars = summary2.summary_col(summ, stars = False, \\\n",
    "    model_names = [\"{0}\".format(n) for n in tables.keys()],\\\n",
    "        info_dict = info_dict, regressor_order = regressors).tables[0]\n",
    "    part_res_stars = summary2.summary_col(summ, stars = True, \\\n",
    "    model_names = [\"{0}\".format(n) for n in tables.keys()],\\\n",
    "        info_dict = info_dict, regressor_order = regressors).tables[0]\n",
    "    \n",
    "    # 4. Get index of where Intercept is and add 2 (to include standard error)\n",
    "    last_ind = list(part_res_stars.index).index(\"Intercept\")+2\n",
    "    \n",
    "    # 5. Get partial results\n",
    "    part_res_no_stars = pd.concat([part_res_no_stars.iloc[:last_ind], part_res_no_stars.iloc[-2::]])\n",
    "    part_res_stars = pd.concat([part_res_stars.iloc[:last_ind], part_res_stars.iloc[-2::]])\n",
    "    \n",
    "    if return_fit == True:\n",
    "        return summ, tables, res_no_stars, res_stars, part_res_no_stars, part_res_stars\n",
    "    else:\n",
    "        return tables, res_no_stars, res_stars, part_res_no_stars, part_res_stars\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Sim\n",
      "INFO:root:(0, 'perc_match_10 ~ C(inv_msa_match) + C(tp_gyear) + C(tp_primclass_FE)')\n",
      "INFO:root:2018-11-13 11:31:10.791651\n",
      "INFO:root:['tp_gyear', 'inv_msa_match', 'tp_primclass_FE']\n",
      "INFO:root:('Length of data', 321438)\n",
      "INFO:root:finished\n",
      "INFO:root:2018-11-13 11:31:30.897516\n",
      "INFO:root:(1, 'perc_match_10 ~ C(inv_msa_match) + C(tp_gyear) + C(tp_primclass_FE) + C(tp_inv_msa_FE)')\n",
      "INFO:root:2018-11-13 11:31:30.900474\n",
      "INFO:root:['tp_inv_msa_FE', 'tp_gyear', 'inv_msa_match', 'tp_primclass_FE']\n",
      "INFO:root:('Length of data', 321438)\n",
      "INFO:root:finished\n",
      "INFO:root:2018-11-13 11:32:01.677093\n",
      "INFO:root:(2, 'perc_match_10 ~ C(inv_msa_match) + C(tp_gyear) + C(tp_primclass_FE)  + C(tp_inv_msa_FE)    + C(tp_lawyer_FE)')\n",
      "INFO:root:2018-11-13 11:32:01.679815\n",
      "INFO:root:['tp_primclass_FE', 'tp_inv_msa_FE', 'tp_lawyer_FE', 'inv_msa_match', 'tp_gyear']\n",
      "INFO:root:('Length of data', 321438)\n",
      "INFO:root:finished\n",
      "INFO:root:2018-11-13 11:32:41.166316\n",
      "INFO:root:(3, 'perc_match_10 ~ C(inv_msa_match) + C(tp_gyear) + C(tp_primclass_FE) + C(tp_inv_msa_FE)    + C(tp_lawyer_FE) + C(tp_examiner_FE)')\n",
      "INFO:root:2018-11-13 11:32:41.169386\n",
      "INFO:root:['tp_primclass_FE', 'tp_inv_msa_FE', 'tp_lawyer_FE', 'tp_examiner_FE', 'inv_msa_match', 'tp_gyear']\n",
      "INFO:root:('Length of data', 321438)\n",
      "INFO:root:finished\n",
      "INFO:root:2018-11-13 11:33:32.250763\n",
      "INFO:root:(4, 'norm_perc_match_10 ~ C(inv_msa_match) + C(tp_gyear) + C(tp_primclass_FE)')\n",
      "INFO:root:2018-11-13 11:33:32.253995\n",
      "INFO:root:['tp_gyear', 'inv_msa_match', 'tp_primclass_FE']\n",
      "INFO:root:('Length of data', 321438)\n",
      "INFO:root:finished\n",
      "INFO:root:2018-11-13 11:33:50.923579\n",
      "INFO:root:(5, 'norm_perc_match_10 ~ C(inv_msa_match) + C(tp_gyear) + C(tp_primclass_FE) + C(tp_inv_msa_FE)')\n",
      "INFO:root:2018-11-13 11:33:50.926550\n",
      "INFO:root:['tp_inv_msa_FE', 'tp_gyear', 'inv_msa_match', 'tp_primclass_FE']\n",
      "INFO:root:('Length of data', 321438)\n",
      "INFO:root:finished\n",
      "INFO:root:2018-11-13 11:34:19.063569\n",
      "INFO:root:(6, 'norm_perc_match_10 ~ C(inv_msa_match) + C(tp_gyear) + C(tp_primclass_FE)  + C(tp_inv_msa_FE)    + C(tp_lawyer_FE)')\n",
      "INFO:root:2018-11-13 11:34:19.065857\n",
      "INFO:root:['tp_primclass_FE', 'tp_inv_msa_FE', 'tp_lawyer_FE', 'inv_msa_match', 'tp_gyear']\n",
      "INFO:root:('Length of data', 321438)\n",
      "INFO:root:finished\n",
      "INFO:root:2018-11-13 11:34:57.084977\n",
      "INFO:root:(7, 'norm_perc_match_10 ~ C(inv_msa_match) + C(tp_gyear) + C(tp_primclass_FE) + C(tp_inv_msa_FE)    + C(tp_lawyer_FE) + C(tp_examiner_FE)')\n",
      "INFO:root:2018-11-13 11:34:57.087220\n",
      "INFO:root:['tp_primclass_FE', 'tp_inv_msa_FE', 'tp_lawyer_FE', 'tp_examiner_FE', 'inv_msa_match', 'tp_gyear']\n",
      "INFO:root:('Length of data', 321438)\n",
      "INFO:root:finished\n",
      "INFO:root:2018-11-13 11:35:46.253521\n",
      "INFO:root:Lawyer\n",
      "INFO:root:(0, 'perc_match_10 ~ C(inv_msa_match) + C(tp_gyear) + C(tp_primclass_FE)')\n",
      "INFO:root:2018-11-13 11:35:46.330121\n",
      "INFO:root:['tp_gyear', 'inv_msa_match', 'tp_primclass_FE']\n",
      "INFO:root:('Length of data', 240677)\n",
      "INFO:root:finished\n",
      "INFO:root:2018-11-13 11:35:59.814446\n",
      "INFO:root:(1, 'perc_match_10 ~ C(inv_msa_match) + C(tp_gyear) + C(tp_primclass_FE) + C(tp_inv_msa_FE)')\n",
      "INFO:root:2018-11-13 11:35:59.817235\n",
      "INFO:root:['tp_inv_msa_FE', 'tp_gyear', 'inv_msa_match', 'tp_primclass_FE']\n",
      "INFO:root:('Length of data', 240677)\n",
      "INFO:root:finished\n",
      "INFO:root:2018-11-13 11:36:20.705382\n",
      "INFO:root:(2, 'perc_match_10 ~ C(inv_msa_match) + C(tp_gyear) + C(tp_primclass_FE)  + C(tp_inv_msa_FE)    + C(tp_lawyer_FE)')\n",
      "INFO:root:2018-11-13 11:36:20.707633\n",
      "INFO:root:['tp_primclass_FE', 'tp_inv_msa_FE', 'tp_lawyer_FE', 'inv_msa_match', 'tp_gyear']\n",
      "INFO:root:('Length of data', 240677)\n",
      "INFO:root:finished\n",
      "INFO:root:2018-11-13 11:36:50.415043\n",
      "INFO:root:(3, 'perc_match_10 ~ C(inv_msa_match) + C(tp_gyear) + C(tp_primclass_FE) + C(tp_inv_msa_FE)    + C(tp_lawyer_FE) + C(tp_examiner_FE)')\n",
      "INFO:root:2018-11-13 11:36:50.417703\n",
      "INFO:root:['tp_primclass_FE', 'tp_inv_msa_FE', 'tp_lawyer_FE', 'tp_examiner_FE', 'inv_msa_match', 'tp_gyear']\n",
      "INFO:root:('Length of data', 240677)\n",
      "INFO:root:finished\n",
      "INFO:root:2018-11-13 11:37:25.146617\n",
      "INFO:root:(4, 'norm_perc_match_10 ~ C(inv_msa_match) + C(tp_gyear) + C(tp_primclass_FE)')\n",
      "INFO:root:2018-11-13 11:37:25.148208\n",
      "INFO:root:['tp_gyear', 'inv_msa_match', 'tp_primclass_FE']\n",
      "INFO:root:('Length of data', 240677)\n",
      "INFO:root:finished\n",
      "INFO:root:2018-11-13 11:37:39.609029\n",
      "INFO:root:(5, 'norm_perc_match_10 ~ C(inv_msa_match) + C(tp_gyear) + C(tp_primclass_FE) + C(tp_inv_msa_FE)')\n",
      "INFO:root:2018-11-13 11:37:39.611482\n",
      "INFO:root:['tp_inv_msa_FE', 'tp_gyear', 'inv_msa_match', 'tp_primclass_FE']\n",
      "INFO:root:('Length of data', 240677)\n",
      "INFO:root:finished\n",
      "INFO:root:2018-11-13 11:38:03.048018\n",
      "INFO:root:(6, 'norm_perc_match_10 ~ C(inv_msa_match) + C(tp_gyear) + C(tp_primclass_FE)  + C(tp_inv_msa_FE)    + C(tp_lawyer_FE)')\n",
      "INFO:root:2018-11-13 11:38:03.056996\n",
      "INFO:root:['tp_primclass_FE', 'tp_inv_msa_FE', 'tp_lawyer_FE', 'inv_msa_match', 'tp_gyear']\n",
      "INFO:root:('Length of data', 240677)\n",
      "INFO:root:finished\n",
      "INFO:root:2018-11-13 11:38:29.875274\n",
      "INFO:root:(7, 'norm_perc_match_10 ~ C(inv_msa_match) + C(tp_gyear) + C(tp_primclass_FE) + C(tp_inv_msa_FE)    + C(tp_lawyer_FE) + C(tp_examiner_FE)')\n",
      "INFO:root:2018-11-13 11:38:29.877947\n",
      "INFO:root:['tp_primclass_FE', 'tp_inv_msa_FE', 'tp_lawyer_FE', 'tp_examiner_FE', 'inv_msa_match', 'tp_gyear']\n",
      "INFO:root:('Length of data', 240677)\n",
      "INFO:root:finished\n",
      "INFO:root:2018-11-13 11:39:05.510291\n",
      "INFO:root:PC\n",
      "INFO:root:(0, 'perc_match_10 ~ C(inv_msa_match) + C(tp_gyear) + C(tp_primclass_FE)')\n",
      "INFO:root:2018-11-13 11:39:05.589450\n",
      "INFO:root:['tp_gyear', 'inv_msa_match', 'tp_primclass_FE']\n",
      "INFO:root:('Length of data', 507870)\n",
      "INFO:root:finished\n",
      "INFO:root:2018-11-13 11:39:35.017644\n",
      "INFO:root:(1, 'perc_match_10 ~ C(inv_msa_match) + C(tp_gyear) + C(tp_primclass_FE) + C(tp_inv_msa_FE)')\n",
      "INFO:root:2018-11-13 11:39:35.020250\n",
      "INFO:root:['tp_inv_msa_FE', 'tp_gyear', 'inv_msa_match', 'tp_primclass_FE']\n",
      "INFO:root:('Length of data', 507870)\n",
      "INFO:root:finished\n",
      "INFO:root:2018-11-13 11:40:23.064508\n",
      "INFO:root:(2, 'perc_match_10 ~ C(inv_msa_match) + C(tp_gyear) + C(tp_primclass_FE)  + C(tp_inv_msa_FE)    + C(tp_lawyer_FE)')\n",
      "INFO:root:2018-11-13 11:40:23.067160\n",
      "INFO:root:['tp_primclass_FE', 'tp_inv_msa_FE', 'tp_lawyer_FE', 'inv_msa_match', 'tp_gyear']\n",
      "INFO:root:('Length of data', 507870)\n",
      "INFO:root:finished\n",
      "INFO:root:2018-11-13 11:41:26.245293\n",
      "INFO:root:(3, 'perc_match_10 ~ C(inv_msa_match) + C(tp_gyear) + C(tp_primclass_FE) + C(tp_inv_msa_FE)    + C(tp_lawyer_FE) + C(tp_examiner_FE)')\n",
      "INFO:root:2018-11-13 11:41:26.247100\n",
      "INFO:root:['tp_primclass_FE', 'tp_inv_msa_FE', 'tp_lawyer_FE', 'tp_examiner_FE', 'inv_msa_match', 'tp_gyear']\n",
      "INFO:root:('Length of data', 507870)\n",
      "INFO:root:finished\n",
      "INFO:root:2018-11-13 11:42:50.311203\n",
      "INFO:root:(4, 'norm_perc_match_10 ~ C(inv_msa_match) + C(tp_gyear) + C(tp_primclass_FE)')\n",
      "INFO:root:2018-11-13 11:42:50.312833\n",
      "INFO:root:['tp_gyear', 'inv_msa_match', 'tp_primclass_FE']\n",
      "INFO:root:('Length of data', 507870)\n",
      "INFO:root:finished\n",
      "INFO:root:2018-11-13 11:43:21.071661\n",
      "INFO:root:(5, 'norm_perc_match_10 ~ C(inv_msa_match) + C(tp_gyear) + C(tp_primclass_FE) + C(tp_inv_msa_FE)')\n",
      "INFO:root:2018-11-13 11:43:21.074041\n",
      "INFO:root:['tp_inv_msa_FE', 'tp_gyear', 'inv_msa_match', 'tp_primclass_FE']\n",
      "INFO:root:('Length of data', 507870)\n",
      "INFO:root:finished\n",
      "INFO:root:2018-11-13 11:44:10.143027\n",
      "INFO:root:(6, 'norm_perc_match_10 ~ C(inv_msa_match) + C(tp_gyear) + C(tp_primclass_FE)  + C(tp_inv_msa_FE)    + C(tp_lawyer_FE)')\n",
      "INFO:root:2018-11-13 11:44:10.144706\n",
      "INFO:root:['tp_primclass_FE', 'tp_inv_msa_FE', 'tp_lawyer_FE', 'inv_msa_match', 'tp_gyear']\n",
      "INFO:root:('Length of data', 507870)\n",
      "INFO:root:finished\n",
      "INFO:root:2018-11-13 11:45:11.218013\n",
      "INFO:root:(7, 'norm_perc_match_10 ~ C(inv_msa_match) + C(tp_gyear) + C(tp_primclass_FE) + C(tp_inv_msa_FE)    + C(tp_lawyer_FE) + C(tp_examiner_FE)')\n",
      "INFO:root:2018-11-13 11:45:11.222119\n",
      "INFO:root:['tp_primclass_FE', 'tp_inv_msa_FE', 'tp_lawyer_FE', 'tp_examiner_FE', 'inv_msa_match', 'tp_gyear']\n",
      "INFO:root:('Length of data', 507870)\n",
      "INFO:root:finished\n",
      "INFO:root:2018-11-13 11:46:38.133803\n"
     ]
    }
   ],
   "source": [
    "tsl = pickle.load(open(\"DataStore/2018-11/jth_rep_control_long_dict_1112.pkl\", \"rb\"))\n",
    "for k,rs in tsl.items():\n",
    "    print(k)\n",
    "    cov = \"HC1\"\n",
    "    samp_out = {}\n",
    "    formulas = list(regs['JTH_cite'])\n",
    "    formulas_ind = list(regs['JTH_cite'].index)\n",
    "    for i, j in zip(formulas_ind, formulas):\n",
    "        print((i, j))\n",
    "        print(datetime.datetime.now())\n",
    "        try:\n",
    "            out = get_fit(j, rs, \"year_group\", cov, return_fit = False)\n",
    "            samp_out[i] = {}\n",
    "            samp_out[i][\"model\"] = j\n",
    "            samp_out[i][\"tables\"] = out[0]\n",
    "            samp_out[i][\"res_no_stars\"] = out[1]\n",
    "            samp_out[i][\"res_stars\"] = out[2]\n",
    "            samp_out[i][\"part_res_no_stars\"] = out[3]\n",
    "            samp_out[i][\"part_res_stars\"] = out[4]\n",
    "        except Exception as e:\n",
    "            logging.exception(\"error here\")\n",
    "            pass\n",
    "        print(\"finished\")\n",
    "        print(datetime.datetime.now())\n",
    "\n",
    "    # Define outfile\n",
    "    o_f = \"JTH_Reg_{0}_out_1112.pkl\".format(k)\n",
    "    pickle.dump(samp_out, open(pathdir+o_f, \"wb\")) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "pathdir = \"DataStore/2018-11/JTHReg1112/\"\n",
    "res_out = pd.DataFrame()\n",
    "for c in [\"PC\", \"Sim\", \"Lawyer\"]:\n",
    "    o_f = \"JTH_Reg_{0}_out_1112.pkl\".format(c)\n",
    "    res = pickle.load(open(pathdir+o_f, \"rb\"))\n",
    "    for k in res.keys():\n",
    "        lks = res[k][\"model\"].split(\" ~ \")[0]\n",
    "\n",
    "        # Selecting portion of results without intercept\n",
    "        cdf = res[k][\"part_res_stars\"].reset_index()\n",
    "        ic_ind = cdf.loc[cdf[\"index\"] == \"Intercept\"].index[0]\n",
    "        # Include N & R^2\n",
    "        cdf = cdf.iloc[pd.np.r_[0:ic_ind,ic_ind+2:len(cdf)]]\n",
    "        # Just include R^2\n",
    "    #             cdf = cdf.iloc[pd.np.r_[0:ic_ind,ic_ind+2:len(cdf)-2, len(cdf)-1:len(cdf)]]\n",
    "        cdf[\"Model\"] = regs[\"JTH_model_names\"][k]\n",
    "        cdf[\"Model Num\"] = k\n",
    "        cdf[\"LKS\"] = lks\n",
    "        cdf[\"samp\"] = \"JTH Rep-\"+c\n",
    "\n",
    "        res_out = res_out.append(cdf)\n",
    "        \n",
    "res_out.to_csv(pathdir+\"jth_rep_reg_1112.csv\")"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "My Python",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
