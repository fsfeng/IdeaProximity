{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import scipy as sp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import timeit\n",
    "import re\n",
    "import json\n",
    "import pickle\n",
    "import fastparquet\n",
    "import os\n",
    "os.chdir('/mnt/t48/bighomes-active/sfeng/patentdiffusion/')\n",
    "seed = 3\n",
    "import seaborn as sns\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "import datetime\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "import statsmodels.iolib.summary2 as summary2\n",
    "import logging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on https://sfengc7.stern.nyu.edu:8888/notebooks/patentdiffusion/201808Results/Reg0919/1-CleanRegData-0919.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "naics_name\n",
      "1498184\n",
      "primclass\n",
      "1369833\n"
     ]
    }
   ],
   "source": [
    "# Create new datasets and save\n",
    "pathdir = \"DataStore/2018-07-P2/Reg0726/\"\n",
    "mod_keys = [\"naics_name\", \"primclass\"]\n",
    "# mod_keys = [\"primclass\"]\n",
    "\n",
    "for k in mod_keys:\n",
    "    print(k)\n",
    "    if k == \"naics_name\":\n",
    "        req_cols = ['tp', 'op',\n",
    "            'sim_docvecs', 'sim_ldavecs', 'tp_gyear', 'tp_naics_name',\n",
    "           'tp_primclass', 'tp_inv_msa', 'op_naics_name', 'op_primclass',\n",
    "           'op_inv_msa', 'inv_msa_match', 'primclass_match',\n",
    "           'norm_sim_ldavecs', 'norm_sim_docvecs', 'sim_mean_ldavecs_pc_msa',\n",
    "           'sim_mean_docvecs_pc_msa', 'sim_mean_docvecs_pc', 'sim_mean_ldavecs_pc',\n",
    "           'norm_sim_mean_ldavecs_pc_msa', 'norm_sim_mean_docvecs_pc_msa', 'norm_sim_mean_docvecs_pc', \n",
    "            'norm_sim_mean_ldavecs_pc', 'year_group']\n",
    "    else:\n",
    "        req_cols = ['tp', 'op',\n",
    "            'sim_docvecs', 'sim_ldavecs', 'tp_gyear', 'tp_naics_name',\n",
    "           'tp_primclass', 'tp_inv_msa', 'op_naics_name', 'op_primclass',\n",
    "           'op_inv_msa', 'inv_msa_match', 'primclass_match',\n",
    "           'norm_sim_ldavecs', 'norm_sim_docvecs', 'year_group', 'sim_mean_ldavecs_pc_msa',\n",
    "           'sim_mean_docvecs_pc_msa', 'norm_sim_mean_ldavecs_pc_msa',\n",
    "           'norm_sim_mean_docvecs_pc_msa']\n",
    "    # Load\n",
    "    rs = fastparquet.ParquetFile(pathdir+\"reg_{0}_sim_tr_0726.parq\".format(k)).to_pandas(req_cols)\n",
    "    #rename columns\n",
    "    rs = rs.rename(columns={'sim_mean_ldavecs_pc_msa': 'mean_sim_ldavecs_pc_msa_v',\n",
    "                            'sim_mean_docvecs_pc_msa': 'mean_sim_docvecs_pc_msa_v', \n",
    "                            'sim_mean_docvecs_pc': 'mean_sim_docvecs_pc_v', \n",
    "                            'sim_mean_ldavecs_pc': 'mean_sim_ldavecs_pc_v',\n",
    "                            'norm_sim_mean_ldavecs_pc_msa': 'norm_mean_sim_ldavecs_pc_msa_v',\n",
    "                            'norm_sim_mean_docvecs_pc_msa': 'norm_mean_sim_docvecs_pc_msa_v',\n",
    "                            'norm_sim_mean_docvecs_pc': 'norm_mean_sim_docvecs_pc_v', \n",
    "                            'norm_sim_mean_ldavecs_pc': 'norm_mean_sim_ldavecs_pc_v'})\n",
    "    \n",
    "    rs2 = fastparquet.ParquetFile(pathdir+\"{0}_common_inv_0726.parq\".format(k))\\\n",
    "    .to_pandas([\"tp\", \"op\", \"common_est_inv\", \"common_pat_inv\", \"lawyer_match\",\\\n",
    "                \"num_common_cited\", \"norm_num_common_cited\", \"tp_pct_common_cited\",\n",
    "                \"norm_tp_pct_common_cited\", \"common_cited_match\"])\n",
    "    rs = rs.merge(rs2, how=\"left\", on = [\"tp\", \"op\"])\n",
    "    del(rs2)\n",
    "    \n",
    "#     if k == \"naics_name\":\n",
    "#         # Get tp-pc similarities\n",
    "#         rs3 = pd.read_pickle(pathdir+\"naics_name_tp_pc_msa_0824.pkl\")[[\"tp\", \"sim_mean_ldavecs_tp_pc_msa\", \"sim_mean_docvecs_tp_pc_msa\"]]\n",
    "#         rs4 = pd.read_pickle(pathdir+\"naics_name_tp_pc_0824.pkl\")[[\"tp\", \"sim_mean_ldavecs_tp_pc\", \"sim_mean_docvecs_tp_pc\"]]\n",
    "#         rs3 = rs3.merge(rs4, how=\"left\", on = \"tp\").drop_duplicates()\n",
    "#         del(rs4)\n",
    "\n",
    "#         for c in [\"sim_mean_ldavecs_tp_pc_msa\", \"sim_mean_docvecs_tp_pc_msa\",\n",
    "#                  \"sim_mean_ldavecs_tp_pc\", \"sim_mean_docvecs_tp_pc_msa\"]:\n",
    "#             # Get normed values for all similarities\n",
    "#             rs3[\"norm_{0}\".format(c)] = np.nan\n",
    "#             rs3.loc[rs3[c].notnull(), \"norm_{0}\".format(c)] = \\\n",
    "#             scaler.fit_transform(rs3.loc[rs3[c].notnull(), c].values.reshape(-1,1))\n",
    "\n",
    "#         # Merge back with original\n",
    "#         print(len(rs))\n",
    "#         rs = rs.merge(rs3, how=\"left\", on = \"tp\")\n",
    "#         del(rs3)\n",
    "#     print(rs.columns)\n",
    "#     print(len(rs))\n",
    "    \n",
    "    # Add Mean Sim: Mean of past similarity\n",
    "    ps = fastparquet.ParquetFile(\"DataStore/2018-10/pc_sim_pairs_0929.parq\").to_pandas()\n",
    "    \n",
    "#     # Normalize similarities: remember to do ONLY FOR UNIQUE VALUES FIRST\n",
    "#     for c in [\"mean_sim_ldavecs_pc\", \"mean_sim_docvecs_pc\", \"mean_sim_ldavecs_pc_msa\", \"mean_sim_docvecs_pc_msa\"]:\n",
    "#             if (c == \"mean_sim_ldavecs_pc\") or (c == \"mean_sim_docvecs_pc\"):\n",
    "#                 # Drop duplicate observations on the index\n",
    "#                 p2 = ps[[\"tp_primclass\", \"op_primclass\", \"tp_gyear\", c]]\\\n",
    "#                 .dropna(how=\"any\").drop_duplicates([\"tp_primclass\", \"op_primclass\", \"tp_gyear\"])\n",
    "                \n",
    "#             else:\n",
    "#                 p2 = ps[[\"tp_primclass\", \"tp_inv_msa\", \"tp_gyear\",\n",
    "#                         \"op_primclass\", \"op_inv_msa\", c]]\\\n",
    "#                 .dropna(how=\"any\").drop_duplicates([\"tp_primclass\", \"tp_inv_msa\", \"tp_gyear\",\\\n",
    "#                                               \"op_primclass\", \"op_inv_msa\"])\n",
    "#                 print(len(ps))\n",
    "                \n",
    "#             print(len(ps), len(p2))\n",
    "#             # Fit\n",
    "#             scaler = StandardScaler().fit(p2[c].values.reshape(-1,1))\n",
    "\n",
    "#             #Transform\n",
    "#             ps.loc[ps[c].notnull(), \"norm_{0}\".format(c)] = \\\n",
    "#             scaler.transform(ps.loc[ps[c].notnull(), c].values.reshape(-1,1))\n",
    "#             del(p2)\n",
    "    \n",
    "    rs = rs.merge(ps, how=\"left\", on=[\"tp_primclass\", \"tp_inv_msa\", \"tp_gyear\",\n",
    "                                              \"op_primclass\", \"op_inv_msa\"])\n",
    "    print(len(rs))\n",
    "    \n",
    "    # Indicator for being in same MSA and having mean_sim_docvecs_pc above 1\n",
    "    rs[\"pc_msa_greater_0\"] = (rs[\"norm_mean_sim_docvecs_pc_msa\"] >= 0)\n",
    "    rs[\"pc_msa_greater_0\"] = rs[\"pc_msa_greater_0\"].astype(int)\n",
    "    rs[\"pc_msa_less_0\"] = 1-rs[\"pc_msa_greater_0\"]\n",
    "    \n",
    "    # Save\n",
    "    fastparquet.write(\"DataStore/2018-10/Reg0930/{0}_all_1004.parq\".format(k), rs, compression=\"GZIP\")\n",
    "    \n",
    "    del(rs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "fe = {\n",
    "    \n",
    "     \"No FE\": \"{0} ~ C(inv_msa_match) + C(tp_gyear)\",\n",
    "     \"PC FE\": \"{0} ~ C(inv_msa_match) + C(tp_gyear) + C(tp_primclass)\",\n",
    "     \"Inv FE\": \"{0} ~ C(inv_msa_match) + C(tp_gyear) + C(tp_primclass) + C(common_est_inv) + C(common_pat_inv)\",\n",
    "     \"Lawyer FE\": \"{0} ~ C(inv_msa_match) + C(tp_gyear) + C(tp_primclass) + C(common_est_inv) + C(common_pat_inv) + \\\n",
    "     C(lawyer_match)\",\n",
    "     \"All FE\": \"{0} ~ C(inv_msa_match) + C(tp_gyear) + C(tp_primclass) + C(common_est_inv) + C(common_pat_inv) + \\\n",
    "     C(lawyer_match) + C(primclass_match)\",\n",
    "}\n",
    "\n",
    "comp_fe = {\n",
    "     \n",
    "     \"Inv M\": \"{0} ~ C(common_pat_inv) + C(tp_gyear)\",\n",
    "     \"Inv M-PC FE\": \"{0} ~ C(common_pat_inv) + C(tp_gyear) + C(tp_primclass)\",\n",
    "     \"Lawyer M\": \"{0} ~ C(lawyer_match) + C(tp_gyear)\",\n",
    "     \"Lawyer M-PC FE\": \"{0} ~ C(lawyer_match) + C(tp_gyear) + C(tp_primclass)\",\n",
    "     \"CC M\": \"{0} ~ C(common_cited_match) + C(tp_gyear)\",\n",
    "     \"CC M-PC FE\": \"{0} ~ C(common_cited_match) + C(tp_gyear) + C(tp_primclass)\",\n",
    "     \"PC M\": \"{0} ~ C(primclass_match) + C(tp_gyear)\",\n",
    "     \"PC M-PC FE\": \"{0} ~ C(primclass_match) + C(tp_gyear) + C(tp_primclass)\",\n",
    "}\n",
    "\n",
    "techsim = {\n",
    "     # All sim\n",
    "    \n",
    "    \"Sim PC\": \"{0} ~ C(inv_msa_match) + C(tp_gyear) + mean_{0}_pc\",\n",
    "    \n",
    "    \"Int PC\": \"{0} ~ C(inv_msa_match)*mean_{0}_pc + C(tp_gyear)\",\n",
    "\n",
    "    \"Sim PC MSA\": \"{0} ~ C(inv_msa_match) + C(tp_gyear) + mean_{0}_pc_msa\",\n",
    "\n",
    "    \"Int PC MSA\": \"{0} ~ C(inv_msa_match)*mean_{0}_pc_msa + C(tp_gyear)\",\n",
    "    \n",
    "    # PC MSA Cubic\n",
    "    \"Sim PC MSA-Cb\": \"{0} ~ C(inv_msa_match) + C(tp_gyear) + mean_{0}_pc_msa + np.power(mean_{0}_pc_msa, 3)\",\n",
    "    \n",
    "#     \"Sim PC MSA-Break Cb\": \"{0} ~ C(inv_msa_match) + C(tp_gyear) + mean_{0}_pc_msa + np.power(mean_{0}_pc_msa, 3)\\\n",
    "#     + MSA_Match_Break:np.power(mean_{0}_pc_msa, 3)\",\n",
    "    \n",
    "     \"Int PC MSA-Add Cb\": \"{0} ~ C(inv_msa_match)*mean_{0}_pc_msa + np.power(mean_{0}_pc_msa,3) + C(tp_gyear)\",\n",
    "     \n",
    "#      \"Int PC MSA-Break Cb\": \"{0} ~ C(inv_msa_match)*mean_{0}_pc_msa + np.power(mean_{0}_pc_msa,3) +\\\n",
    "#      + MSA_Match_Break:np.power(mean_{0}_pc_msa, 3) + C(tp_gyear)\",\n",
    "    \n",
    "     \"Int PC MSA-Int Cb\": \"{0} ~ C(inv_msa_match)*mean_{0}_pc_msa + C(inv_msa_match)*np.power(mean_{0}_pc_msa,3)\\\n",
    "     + C(tp_gyear)\",\n",
    "    \n",
    "    \"Break Int PC MSA\": \"{0} ~ C(inv_msa_match) + pc_msa_greater_0:mean_{0}_pc_msa + \\\n",
    "    pc_msa_less_0:mean_{0}_pc_msa + C(inv_msa_match):pc_msa_greater_0:mean_{0}_pc_msa + \\\n",
    "    C(inv_msa_match):pc_msa_less_0:mean_{0}_pc_msa + C(tp_gyear)\"\n",
    "}\n",
    "    \n",
    "pc_fe_techsim = {\"PC FE-\"+k : v+\" + C(tp_primclass)\" for k,v in techsim.items()}\n",
    "all_fe_techsim = {\"All FE-\"+k : v+\" + C(tp_primclass) + C(common_est_inv) + \\\n",
    "C(common_pat_inv) + C(lawyer_match) + C(primclass_match)\" for k,v in techsim.items()}   \n",
    "inv_fe_techsim = {\"Inv FE-\"+k : v+\" + C(tp_primclass) + C(common_est_inv) + \\\n",
    "C(common_pat_inv) + C(lawyer_match)\" for k,v in techsim.items()}  \n",
    "inv_fe_pc_techsim = {\"Inv FE-\"+k : v+\" + C(common_est_inv) + \\\n",
    "C(common_pat_inv) + C(lawyer_match) + C(primclass_match)\" for k,v in techsim.items()}  \n",
    "\n",
    "# Models\n",
    "s1 = list(fe.values())+list(comp_fe.values())+list(all_fe_techsim.values())+list(inv_fe_techsim.values())\n",
    "s2 = [i.replace(\"{0} \", \"norm_{0} \").replace(\"mean_\", \"norm_mean_\") for i in s1]\n",
    "sim_regs = s1+s2\n",
    "\n",
    "n_eqns = len(s1)\n",
    "\n",
    "# Model names\n",
    "m1 = list(fe.keys())+list(comp_fe.keys())+list(all_fe_techsim.keys())+list(inv_fe_techsim.keys())\n",
    "# Add Norm\n",
    "m2 = [\"N \"+i for i in m1]\n",
    "mn = m1+m2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create regression dictionary\n",
    "regs = {}\n",
    "pathdir = \"DataStore/2018-10/Reg0930/\"\n",
    "reg_f = \"reg_model_1002.pkl\"\n",
    "\n",
    "regs[\"model_names\"] = pd.Series(mn)\n",
    "regs[\"n_eqns\"] = n_eqns\n",
    "regs[\"ldavecs\"] = pd.Series([i.format(\"sim_ldavecs\") for i in sim_regs])\n",
    "regs[\"docvecs\"] = pd.Series([i.format(\"sim_docvecs\") for i in sim_regs])\n",
    "\n",
    "# Include mean_sim_docvecs\n",
    "for c in [\"num_common_cited\", \"tp_pct_common_cited\"]:\n",
    "    # Just replace KS measure\n",
    "    l = [i.replace(\"sim_docvecs \", \"{0} \".format(c)) for i in regs[\"docvecs\"]]\n",
    "    regs[c] = pd.Series(l)\n",
    "pickle.dump(regs, open(pathdir+reg_f, \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
