{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/homedir/eco/sfeng/bigdata/python/miniconda3/lib/python3.6/site-packages/statsmodels/compat/pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.\n",
      "  from pandas.core import datetools\n"
     ]
    }
   ],
   "source": [
    "import scipy as sp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import timeit\n",
    "import re\n",
    "import json\n",
    "import pickle\n",
    "import fastparquet\n",
    "import os\n",
    "os.chdir('/mnt/t48/bighomes-active/sfeng/patentdiffusion/')\n",
    "seed = 3\n",
    "import seaborn as sns\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "import datetime\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "import statsmodels.iolib.summary2 as summary2\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:good day to you madam fiona\n",
      "INFO:root:started\n",
      "INFO:root:2018-07-28 20:44:35.223189\n"
     ]
    }
   ],
   "source": [
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger.addHandler(logging.FileHandler('Logs/JTH_reg_{0}.log'.format(datetime.datetime.now().\\\n",
    "                                                            strftime(\"%Y-%m-%d\"), 'a')))\n",
    "print = logging.info\n",
    "print('good day to you madam fiona')\n",
    "print('started')\n",
    "print(datetime.datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/homedir/eco/sfeng/bigdata/python/miniconda3/lib/python3.6/site-packages/ipykernel_launcher.py:29: FutureWarning: \n",
      "Passing list-likes to .loc or [] with any missing label will raise\n",
      "KeyError in the future, you can use .reindex() as an alternative.\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#deprecate-loc-reindex-listlike\n"
     ]
    }
   ],
   "source": [
    "r_f = \"DataStore/2018-07-P2/Reg0726/reg_model_0726.pkl\"\n",
    "regs = pickle.load(open(r_f, \"rb\"))\n",
    "\n",
    "# Similarity regressions\n",
    "cit_reg = []\n",
    "for c in ['perc_match_10','sim_ldavecs_cite_msa_match_10','sim_docvecs_cite_msa_match_10']:\n",
    "    cit_reg.extend([\n",
    "        \"{0} ~ C(inv_msa_match) + C(tp_gyear)\".format(c),\n",
    "        \"{0} ~ C(inv_msa_match) + C(tp_primclass)  + C(tp_gyear)\".format(c),\n",
    "        \"norm_{0} ~ C(inv_msa_match) + C(tp_gyear)\".format(c),\n",
    "        \"norm_{0} ~ C(inv_msa_match) + C(tp_primclass)  + C(tp_gyear)\".format(c),\n",
    "    ])\n",
    "    regs[\"JTH\"] = pd.Series(cit_reg)\n",
    "    \n",
    "    regs[\"JTH model names\"] = pd.Series([\n",
    "        \"Perc Match Targ MSA, Year FE\",\n",
    "        \"Perc Match Targ MSA, PC FE\",\n",
    "        \"N Perc Match Targ MSA, Year FE\",\n",
    "        \"N Perc Match Targ MSA, PC FE\",\n",
    "        \"Sim LDAVecs Match Targ MSA, Year FE\",\n",
    "        \"Sim LDAVecs Match Targ MSA, PC FE\",\n",
    "        \"N Sim LDAVecs Match Targ MSA, Year FE\",\n",
    "        \"N Sim LDAVecs Match Targ MSA, PC FE\",\n",
    "        \"Sim DocVecs Match Targ MSA, Year FE\",\n",
    "        \"Sim DocVecs Match Targ MSA, PC FE\", \n",
    "        \"N Sim DocVecs Match Targ MSA, Year FE\",\n",
    "        \"N Sim DocVecs Match Targ MSA, PC FE\", \n",
    "    ])\n",
    "    regs[\"JTH norm\"] = regs[\"JTH\"].loc[[2,3,6,7,10,11]]\n",
    "pickle.dump(regs, open(r_f, \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "info_dict = {'$N$':lambda x: \"{0:d}\".format(int(x.nobs)),\n",
    "'Adjusted $R^2$':lambda x: \"{:.2f}\".format(x.rsquared_adj)}\n",
    "def get_fit(formula, grouped_data, group_col, cov_type, return_fit = False):\n",
    "    summ = []\n",
    "    tables = {}\n",
    "    \n",
    "    # Remove missing values used in formula\n",
    "    col_used = re.findall('\\((.*?)\\)',formula)\n",
    "    grouped_data = grouped_data.dropna(how=\"any\", subset=col_used) # Should take care of gyear > 1980 issues\n",
    "    \n",
    "    # Group and then get results\n",
    "    grouped_data = grouped_data.groupby(group_col)\n",
    "    \n",
    "    for n,g in grouped_data:\n",
    "        fit = smf.ols(formula = formula, data = g, missing=\"drop\").fit(cov_type=cov_type)\n",
    "        # Get results tables\n",
    "        tables[n] = fit.summary2().tables\n",
    "        # Append results\n",
    "        summ.append(fit)\n",
    "    # Get full results output\n",
    "    # Dataframe of full results\n",
    "    res_no_stars = summary2.summary_col(summ, stars = False, \\\n",
    "    model_names = [\"{0}\".format(n) for n in grouped_data.groups.keys()],\\\n",
    "        info_dict = info_dict).tables[0]\n",
    "    res_stars = summary2.summary_col(summ, stars = True, \\\n",
    "    model_names = [\"{0}\".format(n) for n in grouped_data.groups.keys()],\\\n",
    "        info_dict = info_dict).tables[0]\n",
    "    \n",
    "    # Get partial results\n",
    "    # 1. Get relevant variables from index of full results\n",
    "    regressors = [v for v in res_no_stars.index.unique() if (\"sim_\" in v) | (\"match\" in v)]\n",
    "    # 2. Make sure regressors come last\n",
    "    regressors = regressors+[\"Intercept\"]\n",
    "    # 3. Get results with regressors\n",
    "    part_res_no_stars = summary2.summary_col(summ, stars = False, \\\n",
    "    model_names = [\"{0}\".format(n) for n in grouped_data.groups.keys()],\\\n",
    "        info_dict = info_dict, regressor_order = regressors).tables[0]\n",
    "    part_res_stars = summary2.summary_col(summ, stars = True, \\\n",
    "    model_names = [\"{0}\".format(n) for n in grouped_data.groups.keys()],\\\n",
    "        info_dict = info_dict, regressor_order = regressors).tables[0]\n",
    "    \n",
    "    # 4. Get index of where Intercept is and add 2 (to include standard error)\n",
    "    last_ind = list(part_res_stars.index).index(\"Intercept\")+2\n",
    "    \n",
    "    # 5. Get partial results\n",
    "    part_res_no_stars = pd.concat([part_res_no_stars.iloc[:last_ind], part_res_no_stars.iloc[-2::]])\n",
    "    part_res_stars = pd.concat([part_res_stars.iloc[:last_ind], part_res_stars.iloc[-2::]])\n",
    "    \n",
    "    if return_fit == True:\n",
    "        return summ, tables, res_no_stars, res_stars, part_res_no_stars, part_res_stars\n",
    "    else:\n",
    "        return tables, res_no_stars, res_stars, part_res_no_stars, part_res_stars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:started\n",
      "INFO:root:2018-07-28 12:29:00.454724\n",
      "INFO:root:564158\n",
      "INFO:root:0\n",
      "INFO:root:perc_match_10 ~ C(inv_msa_match) + C(tp_gyear)\n",
      "INFO:root:2018-07-28 12:29:00.531908\n",
      "INFO:root:finished\n",
      "INFO:root:2018-07-28 12:29:04.113536\n",
      "INFO:root:1\n",
      "INFO:root:perc_match_10 ~ C(inv_msa_match) + C(tp_primclass)  + C(tp_gyear)\n",
      "INFO:root:2018-07-28 12:29:04.115003\n",
      "INFO:root:finished\n",
      "INFO:root:2018-07-28 12:29:39.308190\n",
      "INFO:root:2\n",
      "INFO:root:norm_perc_match_10 ~ C(inv_msa_match) + C(tp_gyear)\n",
      "INFO:root:2018-07-28 12:29:39.309743\n",
      "INFO:root:finished\n",
      "INFO:root:2018-07-28 12:29:43.051090\n",
      "INFO:root:3\n",
      "INFO:root:norm_perc_match_10 ~ C(inv_msa_match) + C(tp_primclass)  + C(tp_gyear)\n",
      "INFO:root:2018-07-28 12:29:43.052602\n",
      "INFO:root:finished\n",
      "INFO:root:2018-07-28 12:30:19.389706\n",
      "INFO:root:4\n",
      "INFO:root:sim_ldavecs_cite_msa_match_10 ~ C(inv_msa_match) + C(tp_gyear)\n",
      "INFO:root:2018-07-28 12:30:19.390859\n",
      "INFO:root:finished\n",
      "INFO:root:2018-07-28 12:30:23.065702\n",
      "INFO:root:5\n",
      "INFO:root:sim_ldavecs_cite_msa_match_10 ~ C(inv_msa_match) + C(tp_primclass)  + C(tp_gyear)\n",
      "INFO:root:2018-07-28 12:30:23.070947\n",
      "INFO:root:finished\n",
      "INFO:root:2018-07-28 12:30:36.253424\n",
      "INFO:root:6\n",
      "INFO:root:norm_sim_ldavecs_cite_msa_match_10 ~ C(inv_msa_match) + C(tp_gyear)\n",
      "INFO:root:2018-07-28 12:30:36.254542\n",
      "INFO:root:finished\n",
      "INFO:root:2018-07-28 12:30:39.922969\n",
      "INFO:root:7\n",
      "INFO:root:norm_sim_ldavecs_cite_msa_match_10 ~ C(inv_msa_match) + C(tp_primclass)  + C(tp_gyear)\n",
      "INFO:root:2018-07-28 12:30:39.928450\n",
      "INFO:root:finished\n",
      "INFO:root:2018-07-28 12:30:53.957820\n",
      "INFO:root:8\n",
      "INFO:root:sim_docvecs_cite_msa_match_10 ~ C(inv_msa_match) + C(tp_gyear)\n",
      "INFO:root:2018-07-28 12:30:53.959247\n",
      "INFO:root:finished\n",
      "INFO:root:2018-07-28 12:30:57.569163\n",
      "INFO:root:9\n",
      "INFO:root:sim_docvecs_cite_msa_match_10 ~ C(inv_msa_match) + C(tp_primclass)  + C(tp_gyear)\n",
      "INFO:root:2018-07-28 12:30:57.570214\n",
      "INFO:root:finished\n",
      "INFO:root:2018-07-28 12:31:10.793256\n",
      "INFO:root:10\n",
      "INFO:root:norm_sim_docvecs_cite_msa_match_10 ~ C(inv_msa_match) + C(tp_gyear)\n",
      "INFO:root:2018-07-28 12:31:10.794601\n",
      "INFO:root:finished\n",
      "INFO:root:2018-07-28 12:31:14.413653\n",
      "INFO:root:11\n",
      "INFO:root:norm_sim_docvecs_cite_msa_match_10 ~ C(inv_msa_match) + C(tp_primclass)  + C(tp_gyear)\n",
      "INFO:root:2018-07-28 12:31:14.414875\n",
      "INFO:root:finished\n",
      "INFO:root:2018-07-28 12:31:27.897309\n"
     ]
    }
   ],
   "source": [
    "print(\"started\")\n",
    "print(datetime.datetime.now())\n",
    "# 1. Load file\n",
    "pathdir = \"DataStore/2018-07-P3/JTHReg0727/\"\n",
    "rs = pd.read_pickle(pathdir+\"targ_cite_sim_reg_0727.pkl\")\n",
    "regs = pd.read_pickle(open(\"DataStore/2018-07-P2/Reg0726/reg_model_0726.pkl\", \"rb\"))\n",
    "print(len(rs))\n",
    "# 3. Define output\n",
    "samp_out = {}\n",
    "formulas = list(regs[\"JTH\"])\n",
    "formulas_ind = list(regs[\"JTH\"].index)\n",
    "cov = \"HC1\"\n",
    "for i, j in zip(formulas_ind, formulas):\n",
    "    print(i)\n",
    "    print(j)\n",
    "    print(datetime.datetime.now())\n",
    "    try:\n",
    "        out = get_fit(j, rs, \"year_group\", cov, return_fit = False)\n",
    "        samp_out[i] = {}\n",
    "        samp_out[i][\"model\"] = j\n",
    "        samp_out[i][\"tables\"] = out[0]\n",
    "        samp_out[i][\"res_no_stars\"] = out[1]\n",
    "        samp_out[i][\"res_stars\"] = out[2]\n",
    "        samp_out[i][\"part_res_no_stars\"] = out[3]\n",
    "        samp_out[i][\"part_res_stars\"] = out[4]\n",
    "    except Exception as e:\n",
    "        logging.exception(\"error here\")\n",
    "        pass\n",
    "    print(\"finished\")\n",
    "    print(datetime.datetime.now())\n",
    "pickle.dump(samp_out, open(pathdir+\"JTH_cite_res_0727.pkl\", \"wb\"))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
