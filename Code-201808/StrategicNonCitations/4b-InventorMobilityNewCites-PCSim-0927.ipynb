{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/homedir/eco/sfeng/bigdata/python/miniconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "import timeit\n",
    "import datetime\n",
    "import time\n",
    "import pprint\n",
    "import itertools\n",
    "import pickle\n",
    "import sklearn\n",
    "import dask\n",
    "import os\n",
    "os.chdir('/mnt/t48/bighomes-active/sfeng/patentdiffusion/')\n",
    "import fastparquet\n",
    "seed = 3\n",
    "import seaborn as sns\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "import dask\n",
    "import dask.dataframe as dd\n",
    "import dask.array as da\n",
    "# Percentiles\n",
    "from scipy.stats import percentileofscore\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For sample generation, see: https://sfengc7.stern.nyu.edu:8888/notebooks/patentdiffusion/201808Results/StrategicNonCitations/Previous/1d-InventorMobilityNewCitations-0911.ipynb\n",
    "\n",
    "See previous notebook for similarity to cited patent:\n",
    "https://sfengc7.stern.nyu.edu:8888/notebooks/patentdiffusion/201808Results/StrategicNonCitations/4a-InventorMobilityNewCites-0918.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "yv = \"appyear\"\n",
    "c2 = pd.read_pickle(\"DataStore/2018-08/inv_move_cites_0912.pkl\")\n",
    "ip = pd.read_pickle(\"DataStore/2018-08/inv_move_pats_0912.pkl\")\n",
    "\n",
    "# Use unique assignees\n",
    "c2 = c2.drop([\"cited_asg\", \"citing_asg\"],1)\n",
    "asgs = fastparquet.ParquetFile(\"RawData/Cleaned/patent_assignees_unique_0628.parq\").to_pandas([\"patent\", \"assignee_id\"])\n",
    "pdf = fastparquet.ParquetFile(\"RawData/Cleaned/patent_loc_unique_us_0628.parq\")\\\n",
    ".to_pandas([\"patent\", \"primclass\", \"appyear\"])\n",
    "pdf = pdf.merge(asgs, how = \"left\", on = \"patent\")\n",
    "\n",
    "c2 = c2.merge(asgs, how=\"left\", left_on=\"citing\", right_on=\"patent\").rename(columns={\"assignee_id\": \"citing_asg\"}).drop(\"patent\",1)\n",
    "c2 = c2.merge(asgs, how=\"left\", left_on=\"cited\", right_on=\"patent\").rename(columns={\"assignee_id\": \"cited_asg\"}).drop(\"patent\",1)\n",
    "del(asgs)\n",
    "\n",
    "# New firms that cite prior patent post move\n",
    "a1 = c2.loc[(c2[\"citing_appyear\"] < c2[\"sec_fyear\"]), \"citing_asg\"].tolist()\n",
    "a2 = c2.loc[(c2[\"citing_appyear\"] >= c2[\"sec_fyear\"]), \"citing_asg\"].tolist()\n",
    "new_cite_asgs = list(set(a2).difference(set(a1)))\n",
    "\n",
    "c3 = pd.read_pickle(\"DataStore/2018-08/inv_mob_cite_pc_control_0918.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1975\n",
      "2018-09-28 10:51:40.175795\n",
      "1976\n",
      "2018-09-28 10:51:41.564468\n",
      "1977\n",
      "2018-09-28 10:51:42.454555\n",
      "1978\n",
      "2018-09-28 10:51:43.595936\n",
      "1979\n",
      "2018-09-28 10:51:45.023820\n",
      "1980\n",
      "2018-09-28 10:51:46.626723\n",
      "1981\n",
      "2018-09-28 10:51:48.356156\n",
      "1982\n",
      "2018-09-28 10:51:50.578169\n",
      "1983\n",
      "2018-09-28 10:51:52.489608\n",
      "1984\n",
      "2018-09-28 10:51:54.427730\n",
      "1985\n",
      "2018-09-28 10:51:56.325800\n",
      "1986\n",
      "2018-09-28 10:51:58.427202\n",
      "1987\n",
      "2018-09-28 10:52:00.606020\n",
      "1988\n",
      "2018-09-28 10:52:02.852763\n",
      "1989\n",
      "2018-09-28 10:52:05.200777\n",
      "1990\n",
      "2018-09-28 10:52:07.716460\n",
      "1991\n",
      "2018-09-28 10:52:10.650861\n",
      "1992\n",
      "2018-09-28 10:52:13.579003\n",
      "1993\n",
      "2018-09-28 10:52:17.492835\n",
      "1994\n",
      "2018-09-28 10:52:21.006468\n",
      "1995\n",
      "2018-09-28 10:52:24.883178\n",
      "1996\n",
      "2018-09-28 10:52:29.185886\n",
      "1997\n",
      "2018-09-28 10:52:34.038337\n",
      "1998\n",
      "2018-09-28 10:52:39.403452\n",
      "1999\n",
      "2018-09-28 10:52:45.051059\n",
      "2000\n",
      "2018-09-28 10:52:51.210615\n",
      "2001\n",
      "2018-09-28 10:52:58.005438\n",
      "2002\n",
      "2018-09-28 10:53:05.971672\n",
      "2003\n",
      "2018-09-28 10:53:14.623323\n",
      "2004\n",
      "2018-09-28 10:53:23.679349\n",
      "2005\n",
      "2018-09-28 10:53:33.227107\n",
      "2006\n",
      "2018-09-28 10:53:42.175788\n",
      "2007\n",
      "2018-09-28 10:53:51.083859\n",
      "2008\n",
      "2018-09-28 10:53:58.636047\n",
      "2009\n",
      "2018-09-28 10:54:06.210262\n",
      "2010\n",
      "2018-09-28 10:54:12.604421\n",
      "2011\n",
      "2018-09-28 10:54:17.639800\n",
      "2012\n",
      "2018-09-28 10:54:21.161083\n",
      "2013\n",
      "2018-09-28 10:54:23.315013\n",
      "2014\n",
      "2018-09-28 10:54:24.376200\n",
      "2015\n",
      "2018-09-28 10:54:24.733661\n"
     ]
    }
   ],
   "source": [
    "# Patents by newly citing assignees\n",
    "pdf = pdf.loc[pdf[\"assignee_id\"].isin(new_cite_asgs)]\n",
    "len(pdf)\n",
    "\n",
    "# Sort by assignee, primclass, app year\n",
    "pdf = pdf.sort_values([\"assignee_id\", \"primclass\", yv], ascending = [1,1,0])\n",
    "\n",
    "# Control patent by assignee, primclass\n",
    "cdict = {}\n",
    "adict = {}\n",
    "for yr in range(1975, 2016):\n",
    "    print(yr)\n",
    "    print(datetime.datetime.now())\n",
    "    # Patent by assignee, primclass\n",
    "    p2 = pdf.loc[(pdf[\"appyear\"].isin(range(yr-5,yr+1))), \\\n",
    "        [\"appyear\", \"assignee_id\", \"primclass\", \"patent\"]].groupby([\"assignee_id\", \"primclass\"])\n",
    "    p2 = {n+(yr,): (g[\"patent\"].tolist() if len(g[\"patent\"].tolist()) >= 1 else None) for n,g in p2}\n",
    "    cdict.update(p2)\n",
    "    del(p2)\n",
    "    \n",
    "     # Patent by assignee\n",
    "    p2 = pdf.loc[(pdf[\"appyear\"].isin(range(yr-5,yr+1))), \\\n",
    "        [\"appyear\", \"assignee_id\", \"primclass\", \"patent\"]].groupby([\"assignee_id\"])\n",
    "    p2 = {(n,yr): (g[\"patent\"].tolist() if len(g[\"patent\"].tolist()) >= 1 else None) for n,g in p2}\n",
    "    adict.update(p2)\n",
    "    del(p2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get all of cited patent's citations\n",
    "c2 = pd.read_pickle(\"DataStore/2018-08/inv_move_cites_0912.pkl\")\n",
    "c2 = {n:g[\"citing\"].tolist() for n,g in c2[[\"cited\", \"citing\"]].groupby(\"cited\")}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 55.9 ms, sys: 7.03 ms, total: 62.9 ms\n",
      "Wall time: 60.2 ms\n",
      "CPU times: user 87.9 ms, sys: 1.99 ms, total: 89.9 ms\n",
      "Wall time: 89.9 ms\n",
      "CPU times: user 593 ms, sys: 4.76 ms, total: 598 ms\n",
      "Wall time: 600 ms\n"
     ]
    }
   ],
   "source": [
    "# Get all firm's patents\n",
    "%time a = [adict.get((asg, fyr), []) for asg,fyr in zip(c3[\"citing_asg\"], c3[\"citing_appyear\"])]\n",
    "c3[\"asg_pats\"] = a\n",
    "\n",
    "# Get list of potential control candidates\n",
    "%time c = [cdict.get((asg, pc, fyr), []) for asg,pc,fyr in zip(c3[\"citing_asg\"], c3[\"citing_primclass\"],\\\n",
    "                                                     c3[\"citing_appyear\"])]\n",
    "\n",
    "# Remove patents that cite the cited patent\n",
    "%time c_2 = [list(set(i)-set(c2.get(j, []))) for i,j in zip(c, c3[\"cited\"])]\n",
    "\n",
    "# Add to dataframe\n",
    "c3[\"asg_pc_pats\"] = c\n",
    "c3[\"asg_pc_pats_c\"] = c_2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "c3.to_pickle(\"DataStore/2018-08/inv_mob_cite_pc_control_0928.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create similarity pair sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create pairs for the citing patent all firm's PC patents in previous five years with citing patent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "c3 = pd.read_pickle(\"DataStore/2018-08/inv_mob_cite_pc_control_0928.pkl\")\n",
    "c3[\"citing_l\"] = c3[\"citing\"].apply(lambda x: [x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "223901\n"
     ]
    }
   ],
   "source": [
    "c4 = pd.DataFrame()\n",
    "for c in [\"asg_pc_pats_c\", \"citing_l\"]:\n",
    "    apats = (itertools.product(l,[j],[k]) for l,j,k in zip(c3[c], c3[\"cited\"], c3[\"citing\"]))\n",
    "    apats = [item for sublist in apats for item in sublist]\n",
    "    s = pd.DataFrame({\"tp\": [i[0] for i in apats], \n",
    "                      \"op\": [i[1] for i in apats],\n",
    "                      \"cited\": [i[1] for i in apats],\n",
    "                      \"citing\": [i[2] for i in apats]})\n",
    "    s[\"type\"] = c\n",
    "    c4 = c4.append(s, ignore_index=True)\n",
    "# Delete duplicates and self similarity\n",
    "c4 = c4.loc[~(c4[\"tp\"] == c4[\"op\"])]\n",
    "c4 = c4.drop_duplicates()\n",
    "print(len(c4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting row values\n",
      "2018-09-28 11:35:53.640521\n",
      "('ldavecs', 'started')\n",
      "Loading matrix and dict\n",
      "2018-09-28 11:35:55.820078\n",
      "97262\n",
      "Getting chunks\n",
      "2018-09-28 11:36:13.418898\n",
      "Getting patent pair cosine similarity\n",
      "2018-09-28 11:36:13.732763\n",
      "223901\n",
      "finished\n",
      "2018-09-28 11:36:23.436870\n",
      "('docvecs', 'started')\n",
      "Loading matrix and dict\n",
      "2018-09-28 11:36:23.440571\n",
      "97262\n",
      "Getting chunks\n",
      "2018-09-28 11:36:44.004392\n",
      "Getting patent pair cosine similarity\n",
      "2018-09-28 11:36:44.682682\n",
      "223901\n",
      "finished\n",
      "2018-09-28 11:37:00.053980\n"
     ]
    }
   ],
   "source": [
    "def grouper(n, iterable):\n",
    "    \"\"\"\n",
    "    >>> list(grouper(3, 'ABCDEFG'))\n",
    "    [['A', 'B', 'C'], ['D', 'E', 'F'], ['G']]\n",
    "    \"\"\"\n",
    "    iterable = iter(iterable)\n",
    "    return iter(lambda: list(itertools.islice(iterable, n)), [])\n",
    "\n",
    "\n",
    "import scipy.spatial.distance as distance\n",
    "dms = [\"ldavecs\", \"docvecs\"]\n",
    "\n",
    "print(\"Getting row values\")\n",
    "print(datetime.datetime.now())\n",
    "pat_dict = fastparquet.ParquetFile(\"RawData/Cleaned/patabs7615_us_no_dup.parq\").to_pandas([\"patent\"])[\"patent\"].tolist()\n",
    "pat_dict = dict(zip(pat_dict, range(len(pat_dict))))\n",
    "\n",
    "\n",
    "l2 = c4.copy()\n",
    "\n",
    "for dm in dms:\n",
    "    print((dm,\"started\"))\n",
    "    print(\"Loading matrix and dict\")\n",
    "    print(datetime.datetime.now())\n",
    "    \n",
    "    if dm == \"ldavecs\":\n",
    "        ncols = 60\n",
    "    else:\n",
    "        ncols = 100\n",
    "\n",
    "    pm = fastparquet.ParquetFile(\"DataStore/2018-07-P2/ML/{0}_pats_0712.parq\".format(dm))\\\n",
    "    .to_pandas().values\n",
    "    \n",
    "    \n",
    "    l3 = l2[[\"tp\", \"op\"]]\n",
    "    l3 = l3.dropna(how=\"any\").drop_duplicates()\n",
    "    # Store copy as array\n",
    "    l3 = l3.loc[l3[\"tp\"].isin(pat_dict.keys()) & l3[\"op\"].isin(pat_dict.keys())]\n",
    "    print(len(l3))\n",
    "\n",
    "    # Convert to chunks\n",
    "    print(\"Getting chunks\")\n",
    "    print(datetime.datetime.now())\n",
    "    # Split into chunks\n",
    "    n_rows = 3000\n",
    "    n_chunks = int(np.round(len(l3)/n_rows))\n",
    "    tp_chunks = grouper(n_rows, pm[[pat_dict[p[1]] for p in l3[\"tp\"].iteritems()]])\n",
    "    op_chunks = grouper(n_rows, pm[[pat_dict[p[1]] for p in l3[\"op\"].iteritems()]])\n",
    "\n",
    "    chunks = itertools.zip_longest(tp_chunks, op_chunks)\n",
    "\n",
    "    print(\"Getting patent pair cosine similarity\")\n",
    "    print(datetime.datetime.now())\n",
    "    # Cosine\n",
    "\n",
    "    cos_dis = np.empty(len(l3))\n",
    "\n",
    "    for r, c in enumerate(chunks):\n",
    "        cos_dis[r*n_rows:r*n_rows+n_rows] = np.diag(distance.cdist(c[0],c[1], metric = \"cosine\"))\n",
    "\n",
    "    l3[\"sim_{0}\".format(dm)] = 1-cos_dis\n",
    "\n",
    "    # Rename columns\n",
    "    l2 = l2.merge(l3, how = \"left\", on = [\"tp\", \"op\"])\n",
    "    print(len(l2))\n",
    "    del(l3)\n",
    "    print(\"finished\")\n",
    "    print(datetime.datetime.now())\n",
    "    del(pm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "c4 = l2\n",
    "del(l2)\n",
    "c4.to_pickle(\"DataStore/2018-08/inv_mob_cite_pc_control_0928.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rank similarity data for each firm's primary class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "c4 = pd.read_pickle(\"DataStore/2018-08/inv_mob_cite_pc_control_0928.pkl\")\n",
    "c4 = c4.dropna(subset=[\"sim_ldavecs\", \"sim_docvecs\"], how=\"any\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/homedir/eco/sfeng/bigdata/python/miniconda3/lib/python3.6/site-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "/homedir/eco/sfeng/bigdata/python/miniconda3/lib/python3.6/site-packages/ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if sys.path[0] == '':\n"
     ]
    }
   ],
   "source": [
    "# For each citing patent, what percentile is the citing similarity at compared to the other similarities?\n",
    "# c4 = c4.rename(columns={\"sim_ldavecs\": \"asg_pc_ldavecs\", \"sim_docvecs\": \"asg_pc_docvecs\"})\n",
    "# c3 = c3.rename(columns={\"sim_ldavecs\": \"citing_ldavecs\", \"sim_docvecs\": \"citing_docvecs\"})\n",
    "\n",
    "# Merge with citing similarity\n",
    "# c4 = c4.merge(c3[[\"citing\", \"cited\", \"citing_ldavecs\", \"citing_docvecs\"]], how=\"left\", on=[\"citing\", \"cited\"])\n",
    "\n",
    "# Rank data for each \"citing\" assignee primclass similarity group\n",
    "c5 = pd.DataFrame()\n",
    "for n,g in c4.groupby(\"citing\"):\n",
    "    g[\"ldavecs_rank\"] = sp.stats.rankdata(1-g[\"sim_ldavecs\"].values, method=\"min\")\n",
    "    g[\"docvecs_rank\"] = sp.stats.rankdata(1-g[\"sim_docvecs\"].values, method=\"min\")\n",
    "    g[\"num_asg_pc\"] = len(g)\n",
    "    c5 = c5.append(g, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "c5.to_pickle(\"DataStore/2018-08/inv_mob_cite_pc_control_0928.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>docvecs_rank</th>\n",
       "      <th>ldavecs_rank</th>\n",
       "      <th>citing</th>\n",
       "      <th>cited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>13875.000000</td>\n",
       "      <td>13875.000000</td>\n",
       "      <td>1.387500e+04</td>\n",
       "      <td>1.387500e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>7.110198</td>\n",
       "      <td>7.349477</td>\n",
       "      <td>6.853216e+06</td>\n",
       "      <td>5.229942e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>20.394489</td>\n",
       "      <td>21.741898</td>\n",
       "      <td>7.887254e+05</td>\n",
       "      <td>7.071117e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.077916e+06</td>\n",
       "      <td>3.930285e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.358993e+06</td>\n",
       "      <td>4.653940e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>7.024403e+06</td>\n",
       "      <td>5.258030e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>7.480044e+06</td>\n",
       "      <td>5.794207e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>583.000000</td>\n",
       "      <td>567.000000</td>\n",
       "      <td>7.861161e+06</td>\n",
       "      <td>7.613631e+06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       docvecs_rank  ldavecs_rank        citing         cited\n",
       "count  13875.000000  13875.000000  1.387500e+04  1.387500e+04\n",
       "mean       7.110198      7.349477  6.853216e+06  5.229942e+06\n",
       "std       20.394489     21.741898  7.887254e+05  7.071117e+05\n",
       "min        1.000000      1.000000  4.077916e+06  3.930285e+06\n",
       "25%        1.000000      1.000000  6.358993e+06  4.653940e+06\n",
       "50%        2.000000      2.000000  7.024403e+06  5.258030e+06\n",
       "75%        5.000000      5.000000  7.480044e+06  5.794207e+06\n",
       "max      583.000000    567.000000  7.861161e+06  7.613631e+06"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c6 = c5.loc[(c5[\"type\"] == \"citing_l\") & (c5[\"num_asg_pc\"] > 1), \n",
    "            [\"docvecs_rank\", \"ldavecs_rank\", \"citing\", \"cited\"]]\n",
    "c6.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Merge with c3\n",
    "c3 = c3.merge(c6, how=\"left\",on=[\"citing\", \"cited\"])\n",
    "c3.to_pickle(\"DataStore/2018-08/inv_mob_cite_pc_control_0928.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['citing', 'cited', 'sim_ldavecs', 'sim_docvecs', 'cited_inv_msa',\n",
       "       'citing_inv_msa', 'cited_appyear', 'citing_appyear', 'sec_inv_msa',\n",
       "       'sec_fyear', 'sec_inv_msa_match', 'citing_asg', 'cited_asg',\n",
       "       'citing_primclass', 'citing_control_asg_pc',\n",
       "       'sim_ldavecs_citing_control_asg_pc',\n",
       "       'sim_docvecs_citing_control_asg_pc', 'asg_pats', 'asg_pc_pats',\n",
       "       'asg_pc_pats_c', 'citing_l', 'docvecs_rank', 'ldavecs_rank'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c3.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.30033072971641683"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(c3.loc[c3[\"docvecs_rank\"].notnull() & (c3[\"docvecs_rank\"]==1)])/len(c3.loc[c3[\"docvecs_rank\"].notnull()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis: Create data tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dm = \"docvecs\"\n",
    "tab = pd.DataFrame({})\n",
    "for c in [dm, \"mean_asg_{0}\".format(dm), \"mean_asg_pc_{0}\".format(dm)]:\n",
    "    c4 = c3.dropna(subset=[\"citing_{0}\".format(c), \"control_{0}\".format(c)], how=\"any\")\n",
    "    cite_m = c4[\"citing_{0}\".format(c)].mean()\n",
    "    cont_m = c4[\"control_{0}\".format(c)].mean()\n",
    "    # Independent samples\n",
    "#     t1 = sp.stats.ttest_ind(c3[\"citing_{0}\".format(c)], c3[\"control_{0}\".format(c)], equal_var=False, nan_policy=\"omit\")\n",
    "    # Related samples\n",
    "    t2 = sp.stats.ttest_rel(c4[\"citing_{0}\".format(c)], c4[\"control_{0}\".format(c)], nan_policy=\"omit\")\n",
    "    tab[c] = [cite_m, cont_m, t2[0], t2[1], len(c4)]\n",
    "    \n",
    "tab.columns = [\"Sim DocVecs to Cited\", \"\\makecell{Mean Sim Docvecs,\\\\\\\\Own Prior Pats}\",\n",
    "               \"\\makecell{Mean Sim Docvecs,\\\\\\\\Own Prior Pats in Citing PC}\"]\n",
    "tab.index = [\"Citing\", \"Control\", \"$t$-value\", \"$p$-value\", \"$N$\"]\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lccc}\n",
      "\\toprule\n",
      "{} & Sim DocVecs to Cited & \\makecell{Mean Sim Docvecs,\\\\Own Prior Pats} & \\makecell{Mean Sim Docvecs,\\\\Own Prior Pats in Citing PC} \\\\\n",
      "\\midrule\n",
      "Citing    &                0.278 &                                        0.281 &                                              0.328 \\\\\n",
      "Control   &                0.234 &                                         0.28 &                                              0.327 \\\\\n",
      "$t$-value &               26.637 &                                        1.096 &                                              1.458 \\\\\n",
      "$p$-value &                    0 &                                        0.273 &                                              0.145 \\\\\n",
      "$N$       &                 8951 &                                         6407 &                                               6338 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tab2 = np.round(tab,3)\n",
    "tab2.loc[\"$N$\"] = tab2.loc[\"$N$\"].astype(int).astype(str)\n",
    "print(tab2.to_latex(escape=False,column_format=\"lccc\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stats on inventors moving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140076\n"
     ]
    }
   ],
   "source": [
    "yv = \"appyear\"\n",
    "# All inventors who have moved\n",
    "ip = pd.read_pickle(\"DataStore/2018-07/inv_move_pats_0712.pkl\")\n",
    "print(len(ip))\n",
    "\n",
    "pdf = fastparquet.ParquetFile(\"RawData/Cleaned/patent_loc_unique_us_0628.parq\")\\\n",
    ".to_pandas([\"patent\", \"inv_msa\", \"gyear\", \"appyear\"])\n",
    "\n",
    "# Add application year\n",
    "ip[yv] = ip[\"patent\"].map(dict(zip(pdf[\"patent\"], pdf[yv])))\n",
    "\n",
    "# Sort by inventor, grant year\n",
    "ip = ip.sort_values([\"inventor_id\", yv])\n",
    "\n",
    "# Only look at inventors' first and second cities\n",
    "ip = ip.loc[(ip[\"inv_asg_rank\"] <= 1)]\n",
    "\n",
    "# Inventors' second cities\n",
    "sc = ip.loc[(ip[\"inv_asg_rank\"] == 1), [\"inventor_id\", \"inv_msa\", yv]].drop_duplicates([\"inventor_id\", \"inv_msa\"])\n",
    "\n",
    "# Inventors' second city compared to first\n",
    "ip[\"sec_inv_msa\"] = ip[\"inventor_id\"].map(dict(zip(sc[\"inventor_id\"], sc[\"inv_msa\"])))\n",
    "\n",
    "# Second city's first grant year\n",
    "ip[\"sec_fyear\"] = ip[\"inventor_id\"].map(dict(zip(sc[\"inventor_id\"], sc[yv])))\n",
    "\n",
    "# # Get rid of the inventors whose second MSA matches the first\n",
    "# ip = ip.loc[~(ip[\"inv_msa\"] == ip[\"sec_inv_msa\"])]\n",
    "# print(len(ip))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12846 53944 66790 0.1923341817637371\n"
     ]
    }
   ],
   "source": [
    "print(len(ip.loc[~(ip[\"inv_msa\"] == ip[\"sec_inv_msa\"])]), len(ip.loc[(ip[\"inv_msa\"] == ip[\"sec_inv_msa\"])]),\n",
    "      len(ip), len(ip.loc[~(ip[\"inv_msa\"] == ip[\"sec_inv_msa\"])])/len(ip))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mobile inventors' prior patent citations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['patent', 'inventor_id', 'location_id', 'city', 'state', 'country',\n",
       "       'inv_msa', 'gyear', 'assignee_id', 'inv_asg_rank', 'appyear',\n",
       "       'sec_inv_msa', 'sec_fyear', 'sec_inv_msa_match_prior',\n",
       "       'sec_inv_msa_match_post', 'sim_docvecs_prior', 'sim_docvecs_post',\n",
       "       'sim_ldavecs_prior', 'sim_ldavecs_post'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ip = pd.read_pickle(\"DataStore/2018-08/inv_move_pats_0912.pkl\")\n",
    "ip.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sec_inv_msa_match_prior</th>\n",
       "      <th>sec_inv_msa_match_post</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2754.000000</td>\n",
       "      <td>2754.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.058752</td>\n",
       "      <td>0.097849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.189363</td>\n",
       "      <td>0.215061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.076923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       sec_inv_msa_match_prior  sec_inv_msa_match_post\n",
       "count              2754.000000             2754.000000\n",
       "mean                  0.058752                0.097849\n",
       "std                   0.189363                0.215061\n",
       "min                   0.000000                0.000000\n",
       "25%                   0.000000                0.000000\n",
       "50%                   0.000000                0.000000\n",
       "75%                   0.000000                0.076923\n",
       "max                   1.000000                1.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sec_inv_msa_match_prior</th>\n",
       "      <th>sec_inv_msa_match_post</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>6497.000000</td>\n",
       "      <td>6497.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.029152</td>\n",
       "      <td>0.077534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.136997</td>\n",
       "      <td>0.198578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       sec_inv_msa_match_prior  sec_inv_msa_match_post\n",
       "count              6497.000000             6497.000000\n",
       "mean                  0.029152                0.077534\n",
       "std                   0.136997                0.198578\n",
       "min                   0.000000                0.000000\n",
       "25%                   0.000000                0.000000\n",
       "50%                   0.000000                0.000000\n",
       "75%                   0.000000                0.000000\n",
       "max                   1.000000                1.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ip.head()\n",
    "# Two approaches\n",
    "# 1. Drop rows with missing values\n",
    "i2 = ip[['sec_inv_msa_match_prior', 'sec_inv_msa_match_post']].dropna(how=\"any\")\n",
    "display(i2.describe())\n",
    "\n",
    "# 2. Only use patents that received citations, i.e. is not null for both prior and post. Then Fill nan with 0.\n",
    "i3 = ip[['sec_inv_msa_match_prior', 'sec_inv_msa_match_post']].dropna(how=\"all\").fillna(0)\n",
    "display(i3.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of assignees that cite mobile inventors patents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4316 10578 8497 0.803270939686141\n"
     ]
    }
   ],
   "source": [
    "print(len(set(a1)), len(set(a2)), len(set(new_cite_asgs)), len(set(new_cite_asgs))/len(set(a2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27817\n"
     ]
    }
   ],
   "source": [
    "# Number of citations from new assignees\n",
    "print(len(c3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
