{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/homedir/eco/sfeng/bigdata/python/miniconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "import timeit\n",
    "import datetime\n",
    "import time\n",
    "import pprint\n",
    "import itertools\n",
    "import pickle\n",
    "import sklearn\n",
    "import dask\n",
    "import os\n",
    "os.chdir('/mnt/t48/bighomes-active/sfeng/patentdiffusion/')\n",
    "import fastparquet\n",
    "seed = 3\n",
    "import seaborn as sns\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "import dask\n",
    "import dask.dataframe as dd\n",
    "import dask.array as da\n",
    "# Percentiles\n",
    "from scipy.stats import percentileofscore\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For sample generation, see: https://sfengc7.stern.nyu.edu:8888/notebooks/patentdiffusion/201808Results/StrategicNonCitations/Previous/1d-InventorMobilityNewCitations-0911.ipynb\n",
    "\n",
    "See previous notebook for similarity to cited patent:\n",
    "https://sfengc7.stern.nyu.edu:8888/notebooks/patentdiffusion/201808Results/StrategicNonCitations/4a-InventorMobilityNewCites-0918.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/homedir/eco/sfeng/bigdata/python/miniconda3/lib/python3.6/site-packages/ipykernel_launcher.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "yv = \"appyear\"\n",
    "c2 = pd.read_pickle(\"DataStore/2018-08/inv_move_cites_0912.pkl\")\n",
    "ip = pd.read_pickle(\"DataStore/2018-08/inv_move_pats_0912.pkl\")\n",
    "\n",
    "# Use unique assignees\n",
    "c2 = c2.drop([\"cited_asg\", \"citing_asg\"],1)\n",
    "asgs = fastparquet.ParquetFile(\"RawData/Cleaned/patent_assignees_unique_0628.parq\").to_pandas([\"patent\", \"assignee_id\"])\n",
    "pdf = fastparquet.ParquetFile(\"RawData/Cleaned/patent_loc_unique_us_0628.parq\")\\\n",
    ".to_pandas([\"patent\", \"primclass\", \"appyear\"])\n",
    "pdf = pdf.merge(asgs, how = \"left\", on = \"patent\")\n",
    "\n",
    "c2 = c2.merge(asgs, how=\"left\", left_on=\"citing\", right_on=\"patent\").rename(columns={\"assignee_id\": \"citing_asg\"}).drop(\"patent\",1)\n",
    "c2 = c2.merge(asgs, how=\"left\", left_on=\"cited\", right_on=\"patent\").rename(columns={\"assignee_id\": \"cited_asg\"}).drop(\"patent\",1)\n",
    "del(asgs)\n",
    "\n",
    "# New firms that cite prior patent post move\n",
    "a1 = c2.loc[(c2[\"citing_appyear\"] < c2[\"sec_fyear\"]), \"citing_asg\"].tolist()\n",
    "a2 = c2.loc[(c2[\"citing_appyear\"] >= c2[\"sec_fyear\"]), \"citing_asg\"].tolist()\n",
    "new_cite_asgs = list(set(a2).difference(set(a1)))\n",
    "\n",
    "c3 = pd.read_pickle(\"DataStore/2018-08/inv_mob_cite_pc_control_0918.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1975\n",
      "2018-09-27 12:02:22.616578\n",
      "1976\n",
      "2018-09-27 12:02:23.769388\n",
      "1977\n",
      "2018-09-27 12:02:24.669426\n",
      "1978\n",
      "2018-09-27 12:02:26.075173\n",
      "1979\n",
      "2018-09-27 12:02:27.812179\n",
      "1980\n",
      "2018-09-27 12:02:29.702357\n",
      "1981\n",
      "2018-09-27 12:02:31.276082\n",
      "1982\n",
      "2018-09-27 12:02:32.916224\n",
      "1983\n",
      "2018-09-27 12:02:34.581170\n",
      "1984\n",
      "2018-09-27 12:02:36.883197\n",
      "1985\n",
      "2018-09-27 12:02:39.371705\n",
      "1986\n",
      "2018-09-27 12:02:41.593707\n",
      "1987\n",
      "2018-09-27 12:02:43.628441\n",
      "1988\n",
      "2018-09-27 12:02:45.751639\n",
      "1989\n",
      "2018-09-27 12:02:48.046682\n",
      "1990\n",
      "2018-09-27 12:02:50.923579\n",
      "1991\n",
      "2018-09-27 12:02:54.131999\n",
      "1992\n",
      "2018-09-27 12:02:57.090262\n",
      "1993\n",
      "2018-09-27 12:03:01.017521\n",
      "1994\n",
      "2018-09-27 12:03:05.228901\n",
      "1995\n",
      "2018-09-27 12:03:10.064504\n",
      "1996\n",
      "2018-09-27 12:03:14.296597\n",
      "1997\n",
      "2018-09-27 12:03:19.123585\n",
      "1998\n",
      "2018-09-27 12:03:24.965483\n",
      "1999\n",
      "2018-09-27 12:03:30.686432\n",
      "2000\n",
      "2018-09-27 12:03:38.721005\n",
      "2001\n",
      "2018-09-27 12:03:47.812166\n",
      "2002\n",
      "2018-09-27 12:03:57.910829\n",
      "2003\n",
      "2018-09-27 12:04:06.070504\n",
      "2004\n",
      "2018-09-27 12:04:15.736518\n",
      "2005\n",
      "2018-09-27 12:04:26.182237\n",
      "2006\n",
      "2018-09-27 12:04:36.000451\n",
      "2007\n",
      "2018-09-27 12:04:45.028441\n",
      "2008\n",
      "2018-09-27 12:04:53.832845\n",
      "2009\n",
      "2018-09-27 12:05:01.040283\n",
      "2010\n",
      "2018-09-27 12:05:06.991256\n",
      "2011\n",
      "2018-09-27 12:05:12.229586\n",
      "2012\n",
      "2018-09-27 12:05:16.295214\n",
      "2013\n",
      "2018-09-27 12:05:18.428392\n",
      "2014\n",
      "2018-09-27 12:05:19.465866\n",
      "2015\n",
      "2018-09-27 12:05:19.808193\n"
     ]
    }
   ],
   "source": [
    "# Patents by newly citing assignees\n",
    "pdf = pdf.loc[pdf[\"assignee_id\"].isin(new_cite_asgs)]\n",
    "len(pdf)\n",
    "\n",
    "# Sort by assignee, primclass, app year\n",
    "pdf = pdf.sort_values([\"assignee_id\", \"primclass\", yv], ascending = [1,1,0])\n",
    "\n",
    "# Control patent by assignee, primclass\n",
    "cdict = {}\n",
    "adict = {}\n",
    "for yr in range(1975, 2016):\n",
    "    print(yr)\n",
    "    print(datetime.datetime.now())\n",
    "    # Patent by assignee, primclass\n",
    "    p2 = pdf.loc[(pdf[\"appyear\"].isin(range(yr-5,yr+1))), \\\n",
    "        [\"appyear\", \"assignee_id\", \"primclass\", \"patent\"]].groupby([\"assignee_id\", \"primclass\"])\n",
    "    p2 = {n+(yr,): (g[\"patent\"].tolist() if len(g[\"patent\"].tolist()) >= 1 else None) for n,g in p2}\n",
    "    cdict.update(p2)\n",
    "    del(p2)\n",
    "    \n",
    "     # Patent by assignee\n",
    "    p2 = pdf.loc[(pdf[\"appyear\"].isin(range(yr-5,yr+1))), \\\n",
    "        [\"appyear\", \"assignee_id\", \"primclass\", \"patent\"]].groupby([\"assignee_id\"])\n",
    "    p2 = {(n,yr): (g[\"patent\"].tolist() if len(g[\"patent\"].tolist()) >= 1 else None) for n,g in p2}\n",
    "    adict.update(p2)\n",
    "    del(p2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get all of cited patent's citations\n",
    "c2 = pd.read_pickle(\"DataStore/2018-08/inv_move_cites_0912.pkl\")\n",
    "c2 = {n:g[\"citing\"].tolist() for n,g in c2[[\"cited\", \"citing\"]].groupby(\"cited\")}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 61.2 ms, sys: 2.41 ms, total: 63.6 ms\n",
      "Wall time: 56.5 ms\n",
      "CPU times: user 78.5 ms, sys: 195 Âµs, total: 78.7 ms\n",
      "Wall time: 74.3 ms\n"
     ]
    }
   ],
   "source": [
    "# Get all firm's patents\n",
    "%time a = [adict.get((asg, fyr), []) for asg,fyr in zip(c3[\"citing_asg\"], c3[\"citing_appyear\"])]\n",
    "c3[\"asg_pats\"] = a\n",
    "\n",
    "# Get list of potential control candidates\n",
    "%time c = [cdict.get((asg, pc, fyr), []) for asg,pc,fyr in zip(c3[\"citing_asg\"], c3[\"citing_primclass\"],\\\n",
    "                                                     c3[\"citing_appyear\"])]\n",
    "# Add to dataframe\n",
    "c3[\"asg_pc_pats\"] = c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "c3.to_pickle(\"DataStore/2018-08/inv_mob_cite_pc_control_0927.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create similarity pair sample\n",
    "\n",
    "#### First, find how long each pairwise list would be for (i) all firm's patents in previous 5 years; (ii) all firm's primary class patents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "209681377\n",
      "27788655\n"
     ]
    }
   ],
   "source": [
    "# Use itertools to get pairwise list\n",
    "apats = (itertools.product(l,l) for l in c3[\"asg_pats\"])\n",
    "apats = [item for sublist in apats for item in sublist]\n",
    "print(len(apats))\n",
    "\n",
    "ppats = (itertools.product(l,l) for l in c3[\"asg_pc_pats\"])\n",
    "ppats = [item for sublist in ppats for item in sublist]\n",
    "print(len(ppats))\n",
    "\n",
    "del(apats, ppats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del(apats, ppats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create pairs for the citing patent and control patent, each crossed with all firm's patents in in previous five years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# c4 = pd.DataFrame()\n",
    "\n",
    "# for c in [\"citing\", \"citing_control_asg_pc\"]:\n",
    "#     apats = (itertools.product([i],l) for i,l in zip(c3[c], c3[\"asg_pats\"]))\n",
    "#     apats = [item for sublist in apats for item in sublist]\n",
    "#     apats = pd.DataFrame({\"tp\": [i[0] for i in apats], \"op\": [i[1] for i in apats]})\n",
    "#     apats[\"type\"] = c\n",
    "#     c4 = c4.append(apats, ignore_index=True)\n",
    "#     del(apats)\n",
    "# print(len(c4))\n",
    "\n",
    "# # Delete duplicates and self similarity\n",
    "# c4 = c4.loc[~(c4[\"tp\"] == c4[\"op\"])]\n",
    "# c4 = c4.drop_duplicates()\n",
    "\n",
    "# Add original citing\n",
    "co = dict(zip(c3[\"citing\"], c3[\"citing\"]))\n",
    "co.update(dict(zip(c3[\"citing_control_asg_pc\"], c3[\"citing\"])))\n",
    "c4[\"citing\"] = c4[\"tp\"].map(co)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting row values\n",
      "2018-09-27 12:50:26.593922\n",
      "('ldavecs', 'started')\n",
      "Loading matrix and dict\n",
      "2018-09-27 12:50:27.941563\n",
      "634330\n",
      "Getting chunks\n",
      "2018-09-27 12:50:41.917328\n",
      "Getting patent pair cosine similarity\n",
      "2018-09-27 12:50:44.813701\n",
      "1741394\n",
      "finished\n",
      "2018-09-27 12:51:57.410473\n",
      "('docvecs', 'started')\n",
      "Loading matrix and dict\n",
      "2018-09-27 12:51:57.415277\n",
      "634330\n",
      "Getting chunks\n",
      "2018-09-27 12:52:16.414043\n",
      "Getting patent pair cosine similarity\n",
      "2018-09-27 12:52:23.671629\n",
      "1741394\n",
      "finished\n",
      "2018-09-27 12:54:13.375081\n"
     ]
    }
   ],
   "source": [
    "def grouper(n, iterable):\n",
    "    \"\"\"\n",
    "    >>> list(grouper(3, 'ABCDEFG'))\n",
    "    [['A', 'B', 'C'], ['D', 'E', 'F'], ['G']]\n",
    "    \"\"\"\n",
    "    iterable = iter(iterable)\n",
    "    return iter(lambda: list(itertools.islice(iterable, n)), [])\n",
    "\n",
    "\n",
    "import scipy.spatial.distance as distance\n",
    "dms = [\"ldavecs\", \"docvecs\"]\n",
    "\n",
    "print(\"Getting row values\")\n",
    "print(datetime.datetime.now())\n",
    "pat_dict = fastparquet.ParquetFile(\"RawData/Cleaned/patabs7615_us_no_dup.parq\").to_pandas([\"patent\"])[\"patent\"].tolist()\n",
    "pat_dict = dict(zip(pat_dict, range(len(pat_dict))))\n",
    "\n",
    "\n",
    "l2 = c4.copy()\n",
    "\n",
    "for dm in dms:\n",
    "    print((dm,\"started\"))\n",
    "    print(\"Loading matrix and dict\")\n",
    "    print(datetime.datetime.now())\n",
    "    \n",
    "    if dm == \"ldavecs\":\n",
    "        ncols = 60\n",
    "    else:\n",
    "        ncols = 100\n",
    "\n",
    "    pm = fastparquet.ParquetFile(\"DataStore/2018-07-P2/ML/{0}_pats_0712.parq\".format(dm))\\\n",
    "    .to_pandas().values\n",
    "    \n",
    "    \n",
    "    l3 = l2[[\"tp\", \"op\"]]\n",
    "    l3 = l3.dropna(how=\"any\").drop_duplicates()\n",
    "    # Store copy as array\n",
    "    l3 = l3.loc[l3[\"tp\"].isin(pat_dict.keys()) & l3[\"op\"].isin(pat_dict.keys())]\n",
    "    print(len(l3))\n",
    "\n",
    "    # Convert to chunks\n",
    "    print(\"Getting chunks\")\n",
    "    print(datetime.datetime.now())\n",
    "    # Split into chunks\n",
    "    n_rows = 3000\n",
    "    n_chunks = int(np.round(len(l3)/n_rows))\n",
    "    tp_chunks = grouper(n_rows, pm[[pat_dict[p[1]] for p in l3[\"tp\"].iteritems()]])\n",
    "    op_chunks = grouper(n_rows, pm[[pat_dict[p[1]] for p in l3[\"op\"].iteritems()]])\n",
    "\n",
    "    chunks = itertools.zip_longest(tp_chunks, op_chunks)\n",
    "\n",
    "    print(\"Getting patent pair cosine similarity\")\n",
    "    print(datetime.datetime.now())\n",
    "    # Cosine\n",
    "\n",
    "    cos_dis = np.empty(len(l3))\n",
    "\n",
    "    for r, c in enumerate(chunks):\n",
    "        cos_dis[r*n_rows:r*n_rows+n_rows] = np.diag(distance.cdist(c[0],c[1], metric = \"cosine\"))\n",
    "\n",
    "    l3[\"sim_{0}\".format(dm)] = 1-cos_dis\n",
    "\n",
    "    # Rename columns\n",
    "    l2 = l2.merge(l3, how = \"left\", on = [\"tp\", \"op\"])\n",
    "    print(len(l2))\n",
    "    del(l3)\n",
    "    print(\"finished\")\n",
    "    print(datetime.datetime.now())\n",
    "    del(pm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "c4 = l2\n",
    "c4 = c4.loc[~(c4[\"tp\"] == c4[\"op\"])]\n",
    "c4 = c4.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add primary class of citing and other\n",
    "pdf = fastparquet.ParquetFile(\"RawData/Cleaned/patent_loc_unique_us_0628.parq\")\\\n",
    ".to_pandas([\"patent\", \"primclass\"])\n",
    "pdf = dict(zip(pdf[\"patent\"], pdf[\"primclass\"]))\n",
    "c4[\"citing_primclass\"] = c4[\"citing\"].map(pdf)\n",
    "c4[\"op_primclass\"] = c4[\"op\"].map(pdf)\n",
    "c4[\"citing_primclass_match\"] = (c4[\"citing_primclass\"] == c4[\"op_primclass\"])\n",
    "print(len(c4))\n",
    "c4.to_pickle(\"DataStore/2018-08/inv_mobility_cite_sim_0927.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "acite = c4.loc[(c4[\"type\"] == \"citing\"), [\"citing\", \"sim_ldavecs\", \"sim_docvecs\"]].groupby(\"citing\").mean()\\\n",
    ".rename(columns={\"sim_ldavecs\": \"citing_mean_asg_ldavecs\", \"sim_docvecs\": \"citing_mean_asg_docvecs\"})\n",
    "acont = c4.loc[(c4[\"type\"] == \"citing_control_asg_pc\"), [\"citing\", \"sim_ldavecs\", \"sim_docvecs\"]].groupby(\"citing\").mean()\\\n",
    ".rename(columns={\"sim_ldavecs\": \"control_mean_asg_ldavecs\", \"sim_docvecs\": \"control_mean_asg_docvecs\"})\n",
    "pcite = c4.loc[(c4[\"type\"] == \"citing\") & (c4[\"citing_primclass_match\"] == True),\n",
    "               [\"citing\", \"sim_ldavecs\", \"sim_docvecs\"]].groupby(\"citing\").mean()\\\n",
    ".rename(columns={\"sim_ldavecs\": \"citing_mean_asg_pc_ldavecs\", \"sim_docvecs\": \"citing_mean_asg_pc_docvecs\"})\n",
    "pcont = c4.loc[(c4[\"type\"] == \"citing_control_asg_pc\") & (c4[\"citing_primclass_match\"] == True),\n",
    "               [\"citing\", \"sim_ldavecs\", \"sim_docvecs\"]].groupby(\"citing\").mean()\\\n",
    ".rename(columns={\"sim_ldavecs\": \"control_mean_asg_pc_ldavecs\", \"sim_docvecs\": \"control_mean_asg_pc_docvecs\"})\n",
    "\n",
    "\n",
    "c5 = pd.concat([acite, acont, pcite, pcont], axis=1).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>citing</th>\n",
       "      <th>citing_mean_asg_ldavecs</th>\n",
       "      <th>citing_mean_asg_docvecs</th>\n",
       "      <th>control_mean_asg_ldavecs</th>\n",
       "      <th>control_mean_asg_docvecs</th>\n",
       "      <th>citing_mean_asg_pc_ldavecs</th>\n",
       "      <th>citing_mean_asg_pc_docvecs</th>\n",
       "      <th>control_mean_asg_pc_ldavecs</th>\n",
       "      <th>control_mean_asg_pc_docvecs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4.552000e+03</td>\n",
       "      <td>4552.000000</td>\n",
       "      <td>4552.000000</td>\n",
       "      <td>4552.000000</td>\n",
       "      <td>4552.000000</td>\n",
       "      <td>4552.000000</td>\n",
       "      <td>4552.000000</td>\n",
       "      <td>4552.000000</td>\n",
       "      <td>4552.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>6.656108e+06</td>\n",
       "      <td>0.443163</td>\n",
       "      <td>0.276347</td>\n",
       "      <td>0.442195</td>\n",
       "      <td>0.274165</td>\n",
       "      <td>0.519948</td>\n",
       "      <td>0.325458</td>\n",
       "      <td>0.520451</td>\n",
       "      <td>0.323640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>8.680338e+05</td>\n",
       "      <td>0.199616</td>\n",
       "      <td>0.131502</td>\n",
       "      <td>0.198718</td>\n",
       "      <td>0.132960</td>\n",
       "      <td>0.215114</td>\n",
       "      <td>0.149217</td>\n",
       "      <td>0.212739</td>\n",
       "      <td>0.150510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>4.077916e+06</td>\n",
       "      <td>0.022381</td>\n",
       "      <td>-0.219281</td>\n",
       "      <td>0.021534</td>\n",
       "      <td>-0.202524</td>\n",
       "      <td>0.003420</td>\n",
       "      <td>-0.247424</td>\n",
       "      <td>0.003420</td>\n",
       "      <td>-0.202524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>6.098831e+06</td>\n",
       "      <td>0.286974</td>\n",
       "      <td>0.186439</td>\n",
       "      <td>0.291407</td>\n",
       "      <td>0.184888</td>\n",
       "      <td>0.364968</td>\n",
       "      <td>0.228775</td>\n",
       "      <td>0.364290</td>\n",
       "      <td>0.224118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>6.833612e+06</td>\n",
       "      <td>0.424437</td>\n",
       "      <td>0.260221</td>\n",
       "      <td>0.417002</td>\n",
       "      <td>0.257215</td>\n",
       "      <td>0.517190</td>\n",
       "      <td>0.310277</td>\n",
       "      <td>0.518015</td>\n",
       "      <td>0.309350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7.354067e+06</td>\n",
       "      <td>0.578274</td>\n",
       "      <td>0.342578</td>\n",
       "      <td>0.577924</td>\n",
       "      <td>0.344953</td>\n",
       "      <td>0.674154</td>\n",
       "      <td>0.403715</td>\n",
       "      <td>0.673964</td>\n",
       "      <td>0.402988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>7.861161e+06</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.870421</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.870421</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.911395</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.911395</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             citing  citing_mean_asg_ldavecs  citing_mean_asg_docvecs  \\\n",
       "count  4.552000e+03              4552.000000              4552.000000   \n",
       "mean   6.656108e+06                 0.443163                 0.276347   \n",
       "std    8.680338e+05                 0.199616                 0.131502   \n",
       "min    4.077916e+06                 0.022381                -0.219281   \n",
       "25%    6.098831e+06                 0.286974                 0.186439   \n",
       "50%    6.833612e+06                 0.424437                 0.260221   \n",
       "75%    7.354067e+06                 0.578274                 0.342578   \n",
       "max    7.861161e+06                 1.000000                 0.870421   \n",
       "\n",
       "       control_mean_asg_ldavecs  control_mean_asg_docvecs  \\\n",
       "count               4552.000000               4552.000000   \n",
       "mean                   0.442195                  0.274165   \n",
       "std                    0.198718                  0.132960   \n",
       "min                    0.021534                 -0.202524   \n",
       "25%                    0.291407                  0.184888   \n",
       "50%                    0.417002                  0.257215   \n",
       "75%                    0.577924                  0.344953   \n",
       "max                    1.000000                  0.870421   \n",
       "\n",
       "       citing_mean_asg_pc_ldavecs  citing_mean_asg_pc_docvecs  \\\n",
       "count                 4552.000000                 4552.000000   \n",
       "mean                     0.519948                    0.325458   \n",
       "std                      0.215114                    0.149217   \n",
       "min                      0.003420                   -0.247424   \n",
       "25%                      0.364968                    0.228775   \n",
       "50%                      0.517190                    0.310277   \n",
       "75%                      0.674154                    0.403715   \n",
       "max                      1.000000                    0.911395   \n",
       "\n",
       "       control_mean_asg_pc_ldavecs  control_mean_asg_pc_docvecs  \n",
       "count                  4552.000000                  4552.000000  \n",
       "mean                      0.520451                     0.323640  \n",
       "std                       0.212739                     0.150510  \n",
       "min                       0.003420                    -0.202524  \n",
       "25%                       0.364290                     0.224118  \n",
       "50%                       0.518015                     0.309350  \n",
       "75%                       0.673964                     0.402988  \n",
       "max                       1.000000                     0.911395  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c5.dropna(how=\"any\").describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "c3 = c3.merge(c5, how=\"left\", on=\"citing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "c3 = c3.rename(columns={\"sim_ldavecs\": \"citing_ldavecs\", \"sim_docvecs\": \"citing_docvecs\",\n",
    "                       \"sim_ldavecs_citing_control_asg_pc\": \"control_ldavecs\",\n",
    "                        'sim_docvecs_citing_control_asg_pc': \"control_docvecs\"})\n",
    "\n",
    "c3.to_pickle(\"DataStore/2018-08/inv_mob_cite_pc_control_0927.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis: Create data tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "dm = \"docvecs\"\n",
    "tab = pd.DataFrame({})\n",
    "for c in [dm, \"mean_asg_{0}\".format(dm), \"mean_asg_pc_{0}\".format(dm)]:\n",
    "    c4 = c3.dropna(subset=[\"citing_{0}\".format(c), \"control_{0}\".format(c)], how=\"any\")\n",
    "    cite_m = c4[\"citing_{0}\".format(c)].mean()\n",
    "    cont_m = c4[\"control_{0}\".format(c)].mean()\n",
    "    # Independent samples\n",
    "#     t1 = sp.stats.ttest_ind(c3[\"citing_{0}\".format(c)], c3[\"control_{0}\".format(c)], equal_var=False, nan_policy=\"omit\")\n",
    "    # Related samples\n",
    "    t2 = sp.stats.ttest_rel(c4[\"citing_{0}\".format(c)], c4[\"control_{0}\".format(c)], nan_policy=\"omit\")\n",
    "    tab[c] = [cite_m, cont_m, t2[0], t2[1], len(c4)]\n",
    "    \n",
    "tab.columns = [\"Sim DocVecs to Cited\", \"\\makecell{Mean Sim Docvecs,\\\\\\\\Own Prior Pats}\",\n",
    "               \"\\makecell{Mean Sim Docvecs,\\\\\\\\Own Prior Pats in Citing PC}\"]\n",
    "tab.index = [\"Citing\", \"Control\", \"$t$-value\", \"$p$-value\", \"$N$\"]\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lccc}\n",
      "\\toprule\n",
      "{} & Sim DocVecs to Cited & \\makecell{Mean Sim Docvecs,\\\\Own Prior Pats} & \\makecell{Mean Sim Docvecs,\\\\Own Prior Pats in Citing PC} \\\\\n",
      "\\midrule\n",
      "Citing    &                0.278 &                                        0.281 &                                              0.328 \\\\\n",
      "Control   &                0.234 &                                         0.28 &                                              0.327 \\\\\n",
      "$t$-value &               26.637 &                                        1.096 &                                              1.458 \\\\\n",
      "$p$-value &                    0 &                                        0.273 &                                              0.145 \\\\\n",
      "$N$       &                 8951 &                                         6407 &                                               6338 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tab2 = np.round(tab,3)\n",
    "tab2.loc[\"$N$\"] = tab2.loc[\"$N$\"].astype(int).astype(str)\n",
    "print(tab2.to_latex(escape=False,column_format=\"lccc\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stats on inventors moving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140076\n"
     ]
    }
   ],
   "source": [
    "yv = \"appyear\"\n",
    "# All inventors who have moved\n",
    "ip = pd.read_pickle(\"DataStore/2018-07/inv_move_pats_0712.pkl\")\n",
    "print(len(ip))\n",
    "\n",
    "pdf = fastparquet.ParquetFile(\"RawData/Cleaned/patent_loc_unique_us_0628.parq\")\\\n",
    ".to_pandas([\"patent\", \"inv_msa\", \"gyear\", \"appyear\"])\n",
    "\n",
    "# Add application year\n",
    "ip[yv] = ip[\"patent\"].map(dict(zip(pdf[\"patent\"], pdf[yv])))\n",
    "\n",
    "# Sort by inventor, grant year\n",
    "ip = ip.sort_values([\"inventor_id\", yv])\n",
    "\n",
    "# Only look at inventors' first and second cities\n",
    "ip = ip.loc[(ip[\"inv_asg_rank\"] <= 1)]\n",
    "\n",
    "# Inventors' second cities\n",
    "sc = ip.loc[(ip[\"inv_asg_rank\"] == 1), [\"inventor_id\", \"inv_msa\", yv]].drop_duplicates([\"inventor_id\", \"inv_msa\"])\n",
    "\n",
    "# Inventors' second city compared to first\n",
    "ip[\"sec_inv_msa\"] = ip[\"inventor_id\"].map(dict(zip(sc[\"inventor_id\"], sc[\"inv_msa\"])))\n",
    "\n",
    "# Second city's first grant year\n",
    "ip[\"sec_fyear\"] = ip[\"inventor_id\"].map(dict(zip(sc[\"inventor_id\"], sc[yv])))\n",
    "\n",
    "# # Get rid of the inventors whose second MSA matches the first\n",
    "# ip = ip.loc[~(ip[\"inv_msa\"] == ip[\"sec_inv_msa\"])]\n",
    "# print(len(ip))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12846 53944 66790 0.1923341817637371\n"
     ]
    }
   ],
   "source": [
    "print(len(ip.loc[~(ip[\"inv_msa\"] == ip[\"sec_inv_msa\"])]), len(ip.loc[(ip[\"inv_msa\"] == ip[\"sec_inv_msa\"])]),\n",
    "      len(ip), len(ip.loc[~(ip[\"inv_msa\"] == ip[\"sec_inv_msa\"])])/len(ip))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mobile inventors' prior patent citations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['patent', 'inventor_id', 'location_id', 'city', 'state', 'country',\n",
       "       'inv_msa', 'gyear', 'assignee_id', 'inv_asg_rank', 'appyear',\n",
       "       'sec_inv_msa', 'sec_fyear', 'sec_inv_msa_match_prior',\n",
       "       'sec_inv_msa_match_post', 'sim_docvecs_prior', 'sim_docvecs_post',\n",
       "       'sim_ldavecs_prior', 'sim_ldavecs_post'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ip = pd.read_pickle(\"DataStore/2018-08/inv_move_pats_0912.pkl\")\n",
    "ip.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sec_inv_msa_match_prior</th>\n",
       "      <th>sec_inv_msa_match_post</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2754.000000</td>\n",
       "      <td>2754.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.058752</td>\n",
       "      <td>0.097849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.189363</td>\n",
       "      <td>0.215061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.076923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       sec_inv_msa_match_prior  sec_inv_msa_match_post\n",
       "count              2754.000000             2754.000000\n",
       "mean                  0.058752                0.097849\n",
       "std                   0.189363                0.215061\n",
       "min                   0.000000                0.000000\n",
       "25%                   0.000000                0.000000\n",
       "50%                   0.000000                0.000000\n",
       "75%                   0.000000                0.076923\n",
       "max                   1.000000                1.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sec_inv_msa_match_prior</th>\n",
       "      <th>sec_inv_msa_match_post</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>6497.000000</td>\n",
       "      <td>6497.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.029152</td>\n",
       "      <td>0.077534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.136997</td>\n",
       "      <td>0.198578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       sec_inv_msa_match_prior  sec_inv_msa_match_post\n",
       "count              6497.000000             6497.000000\n",
       "mean                  0.029152                0.077534\n",
       "std                   0.136997                0.198578\n",
       "min                   0.000000                0.000000\n",
       "25%                   0.000000                0.000000\n",
       "50%                   0.000000                0.000000\n",
       "75%                   0.000000                0.000000\n",
       "max                   1.000000                1.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ip.head()\n",
    "# Two approaches\n",
    "# 1. Drop rows with missing values\n",
    "i2 = ip[['sec_inv_msa_match_prior', 'sec_inv_msa_match_post']].dropna(how=\"any\")\n",
    "display(i2.describe())\n",
    "\n",
    "# 2. Only use patents that received citations, i.e. is not null for both prior and post. Then Fill nan with 0.\n",
    "i3 = ip[['sec_inv_msa_match_prior', 'sec_inv_msa_match_post']].dropna(how=\"all\").fillna(0)\n",
    "display(i3.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of assignees that cite mobile inventors patents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4316 10578 8497 0.803270939686141\n"
     ]
    }
   ],
   "source": [
    "print(len(set(a1)), len(set(a2)), len(set(new_cite_asgs)), len(set(new_cite_asgs))/len(set(a2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27817\n"
     ]
    }
   ],
   "source": [
    "# Number of citations from new assignees\n",
    "print(len(c3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
