{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/homedir/eco/sfeng/bigdata/python/miniconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "import timeit\n",
    "import datetime\n",
    "import time\n",
    "import pprint\n",
    "import itertools\n",
    "import pickle\n",
    "import sklearn\n",
    "import dask\n",
    "import os\n",
    "os.chdir('/mnt/t48/bighomes-active/sfeng/patentdiffusion/')\n",
    "import fastparquet\n",
    "seed = 3\n",
    "import seaborn as sns\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "import dask\n",
    "import dask.dataframe as dd\n",
    "import dask.array as da\n",
    "# Percentiles\n",
    "from scipy.stats import percentileofscore\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inventor mobility effects on citations at new location\n",
    "\n",
    "1.1 Find new location citations to inventor's old patents and inventor's new patents\n",
    "- Show new patents have greater rates of citation compared to old patents\n",
    "\n",
    "1.2 Show rate of citation at new location increases, but doesn't translate to more similar inventions\n",
    "1. Find new patent's citations in new location\n",
    "2. Find new patents' similarity to new citations\n",
    "3. Find new patents' similarity to old patents of same assignee who don't cite new patent\n",
    "\n",
    "### Find inventors who moved and their patents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140076\n",
      "12846\n",
      "10826\n"
     ]
    }
   ],
   "source": [
    "yv = \"appyear\"\n",
    "# All inventors who have moved\n",
    "ip = pd.read_pickle(\"DataStore/2018-07/inv_move_pats_0712.pkl\")\n",
    "print(len(ip))\n",
    "\n",
    "pdf = fastparquet.ParquetFile(\"RawData/Cleaned/patent_loc_unique_us_0628.parq\")\\\n",
    ".to_pandas([\"patent\", \"inv_msa\", \"gyear\", \"appyear\"])\n",
    "\n",
    "# Add application year\n",
    "ip[yv] = ip[\"patent\"].map(dict(zip(pdf[\"patent\"], pdf[yv])))\n",
    "\n",
    "# Sort by inventor, grant year\n",
    "ip = ip.sort_values([\"inventor_id\", yv])\n",
    "\n",
    "# Only look at inventors' first and second cities\n",
    "ip = ip.loc[(ip[\"inv_asg_rank\"] <= 1)]\n",
    "\n",
    "# Inventors' second cities\n",
    "sc = ip.loc[(ip[\"inv_asg_rank\"] == 1), [\"inventor_id\", \"inv_msa\", yv]].drop_duplicates([\"inventor_id\", \"inv_msa\"])\n",
    "\n",
    "# Inventors' second city compared to first\n",
    "ip[\"sec_inv_msa\"] = ip[\"inventor_id\"].map(dict(zip(sc[\"inventor_id\"], sc[\"inv_msa\"])))\n",
    "\n",
    "# Second city's first grant year\n",
    "ip[\"sec_fyear\"] = ip[\"inventor_id\"].map(dict(zip(sc[\"inventor_id\"], sc[yv])))\n",
    "\n",
    "# Get rid of the inventors whose second MSA matches the first\n",
    "ip = ip.loc[~(ip[\"inv_msa\"] == ip[\"sec_inv_msa\"])]\n",
    "print(len(ip))\n",
    "\n",
    "# Get rid inventors with any missing cities\n",
    "missing_cities = ip.loc[(ip[\"inv_msa\"].isnull() | ip[\"sec_inv_msa\"].isnull()), \"inventor_id\"].tolist()\n",
    "ip = ip.loc[~ip[\"inventor_id\"].isin(missing_cities)]\n",
    "print(len(ip))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Citations to each of mobile inventors' patents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 14s, sys: 34.7 s, total: 2min 49s\n",
      "Wall time: 1min 25s\n",
      "CPU times: user 50 ms, sys: 0 ns, total: 50 ms\n",
      "Wall time: 47.2 ms\n",
      "CPU times: user 1.72 s, sys: 0 ns, total: 1.72 s\n",
      "Wall time: 1.62 s\n",
      "331597\n"
     ]
    }
   ],
   "source": [
    "cit = dd.read_parquet(\"RawData/Cleaned/cit_0628.parq\")\n",
    "\n",
    "%time c2 = cit[cit[\"cited\"].isin(ip[\"patent\"])].compute()\n",
    "\n",
    "# Remove self-citations\n",
    "asgs = pickle.load(open(\"RawData/Cleaned/patent_assignee_dict_0628.pkl\", \"rb\"))\n",
    "\n",
    "%time asg_match = (set(asgs.get(cited, [])).intersection(asgs.get(citing, [])) for cited, citing \\\n",
    "                   in zip(c2[\"cited\"], c2[\"citing\"]))\n",
    "%time asg_match = [len(i) for i in asg_match]\n",
    "c2[\"asg_match\"] = asg_match\n",
    "c2 = c2.loc[c2[\"asg_match\"] == 0]\n",
    "c2 = c2[[\"citing\", \"cited\"]]\n",
    "\n",
    "# Add assignees\n",
    "c2[\"cited_asg\"] = c2[\"cited\"].map(asgs)\n",
    "c2[\"citing_asg\"] = c2[\"citing\"].map(asgs)\n",
    "del(asgs)\n",
    "\n",
    "print(len(c2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Similarities for citation pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting row values\n",
      "2018-09-12 17:18:15.702909\n",
      "('ldavecs', 'started')\n",
      "Loading matrix and dict\n",
      "2018-09-12 17:18:18.019595\n",
      "Getting chunks\n",
      "2018-09-12 17:18:27.765365\n",
      "Getting patent pair cosine similarity\n",
      "2018-09-12 17:18:28.850094\n",
      "finished\n",
      "2018-09-12 17:18:48.055166\n",
      "('docvecs', 'started')\n",
      "Loading matrix and dict\n",
      "2018-09-12 17:18:48.055292\n",
      "Getting chunks\n",
      "2018-09-12 17:19:06.406469\n",
      "Getting patent pair cosine similarity\n",
      "2018-09-12 17:19:08.236596\n",
      "finished\n",
      "2018-09-12 17:19:34.887668\n"
     ]
    }
   ],
   "source": [
    "def grouper(n, iterable):\n",
    "    \"\"\"\n",
    "    >>> list(grouper(3, 'ABCDEFG'))\n",
    "    [['A', 'B', 'C'], ['D', 'E', 'F'], ['G']]\n",
    "    \"\"\"\n",
    "    iterable = iter(iterable)\n",
    "    return iter(lambda: list(itertools.islice(iterable, n)), [])\n",
    "\n",
    "\n",
    "import scipy.spatial.distance as distance\n",
    "dms = [\"ldavecs\", \"docvecs\"]\n",
    "\n",
    "print(\"Getting row values\")\n",
    "print(datetime.datetime.now())\n",
    "pat_dict = fastparquet.ParquetFile(\"RawData/Cleaned/patabs7615_us_no_dup.parq\").to_pandas([\"patent\"])[\"patent\"].tolist()\n",
    "pat_dict = dict(zip(pat_dict, range(len(pat_dict))))\n",
    "\n",
    "l2 = pd.DataFrame({\"tp\": c2[\"cited\"], \"op\": c2[\"citing\"]})\n",
    "\n",
    "for dm in dms:\n",
    "    print((dm,\"started\"))\n",
    "    print(\"Loading matrix and dict\")\n",
    "    print(datetime.datetime.now())\n",
    "    # Store copy as array\n",
    "    l3 = l2.loc[l2[\"tp\"].isin(pat_dict.keys()) & l2[\"op\"].isin(pat_dict.keys()), [\"tp\", \"op\"]].copy()\n",
    "\n",
    "    if dm == \"ldavecs\":\n",
    "        ncols = 60\n",
    "    else:\n",
    "        ncols = 100\n",
    "\n",
    "    pm = fastparquet.ParquetFile(\"DataStore/2018-07-P2/ML/{0}_pats_0712.parq\".format(dm))\\\n",
    ".to_pandas().values\n",
    "\n",
    "    # Convert to chunks\n",
    "    print(\"Getting chunks\")\n",
    "    print(datetime.datetime.now())\n",
    "    # Split into chunks\n",
    "    n_rows = 3000\n",
    "    n_chunks = int(np.round(len(l3)/n_rows))\n",
    "    tp_chunks = grouper(n_rows, pm[[pat_dict[p[1]] for p in l3[\"tp\"].iteritems()]])\n",
    "    op_chunks = grouper(n_rows, pm[[pat_dict[p[1]] for p in l3[\"op\"].iteritems()]])\n",
    "    del(pm)\n",
    "    chunks = itertools.zip_longest(tp_chunks, op_chunks)\n",
    "\n",
    "    print(\"Getting patent pair cosine similarity\")\n",
    "    print(datetime.datetime.now())\n",
    "    # Cosine\n",
    "\n",
    "    cos_dis = np.empty(len(l3))\n",
    "\n",
    "    for r, c in enumerate(chunks):\n",
    "        cos_dis[r*n_rows:r*n_rows+n_rows] = np.diag(distance.cdist(c[0],c[1], metric = \"cosine\"))\n",
    "\n",
    "    l3[\"sim_{0}\".format(dm)] = 1-cos_dis\n",
    "    \n",
    "    # Rename columns\n",
    "    l3 = l3.rename(columns={\"tp\": \"cited\", \"op\": \"citing\"})\n",
    "    c2 = c2.merge(l3, how = \"left\", on = [\"cited\", \"citing\"])\n",
    "    del(l3)\n",
    "    print(\"finished\")\n",
    "    print(datetime.datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get location for each patent\n",
    "# pdf = fastparquet.ParquetFile(\"RawData/Cleaned/patent_loc_unique_us_0628.parq\")\\\n",
    "# .to_pandas([\"patent\", \"inv_msa\", \"gyear\", \"appyear\"])\n",
    "\n",
    "# Get MSA of cited patent\n",
    "c2[\"cited_inv_msa\"] = c2[\"cited\"].map(dict(zip(pdf[\"patent\"], pdf[\"inv_msa\"])))\n",
    "c2[\"citing_inv_msa\"] = c2[\"citing\"].map(dict(zip(pdf[\"patent\"], pdf[\"inv_msa\"])))\n",
    "\n",
    "# Get gyear of cited patent\n",
    "c2[\"cited_\"+yv] = c2[\"cited\"].map(dict(zip(pdf[\"patent\"], pdf[yv])))\n",
    "c2[\"citing_\"+yv] = c2[\"citing\"].map(dict(zip(pdf[\"patent\"], pdf[yv])))\n",
    "del(pdf)\n",
    "\n",
    "# Get second cities for each patent\n",
    "c2[\"sec_inv_msa\"] = c2[\"cited\"].map(dict(zip(ip[\"patent\"], ip[\"sec_inv_msa\"])))\n",
    "\n",
    "# Get second cities first grant year for each patent\n",
    "c2[\"sec_fyear\"] = c2[\"cited\"].map(dict(zip(ip[\"patent\"], ip[\"sec_fyear\"])))\n",
    "\n",
    "# Matching citing patent MSA to second MSA\n",
    "c2[\"sec_inv_msa_match\"] = (c2[\"citing_inv_msa\"] == c2[\"sec_inv_msa\"])\n",
    "\n",
    "# Match rate to second MSA\n",
    "# Before move\n",
    "prior = c2.loc[(c2[\"citing_\"+yv] < c2[\"sec_fyear\"]), [\"cited\", \"sec_inv_msa_match\"]].groupby(\"cited\").mean()\n",
    "# After move\n",
    "post = c2.loc[(c2[\"citing_\"+yv] >= c2[\"sec_fyear\"]), [\"cited\", \"sec_inv_msa_match\"]].groupby(\"cited\").mean()\n",
    "\n",
    "# Average similarity before and after move\n",
    "for c in [\"sim_docvecs\", \"sim_ldavecs\"]:\n",
    "    # Average of second MSA citations similarity to cited patent, before and after move\n",
    "    c3 = c2.loc[(c2[\"citing_\"+yv] < c2[\"sec_fyear\"]) & (c2[\"sec_inv_msa_match\"] == True),\n",
    "                [\"cited\", c]].groupby(\"cited\").mean()\n",
    "    c4 = c2.loc[(c2[\"citing_\"+yv] >= c2[\"sec_fyear\"]) & (c2[\"sec_inv_msa_match\"] == True),\n",
    "                [\"cited\", c]].groupby(\"cited\").mean()\n",
    "    prior = pd.concat([prior, c3], axis=1)\n",
    "    post = pd.concat([post, c4], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10826\n",
      "10826\n"
     ]
    }
   ],
   "source": [
    "# Get match rate to second MSA for each patent\n",
    "for c in [\"sec_inv_msa_match\", \"sim_docvecs\", \"sim_ldavecs\"]:\n",
    "    ip[\"{0}_prior\".format(c)] = ip[\"patent\"].map(prior[c])\n",
    "    ip[\"{0}_post\".format(c)] = ip[\"patent\"].map(post[c])\n",
    "print(len(ip))\n",
    "# Get rid of the inventors whose second MSA matches the first\n",
    "ip = ip.loc[~(ip[\"inv_msa\"] == ip[\"sec_inv_msa\"])]\n",
    "print(len(ip))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sec_inv_msa_match_prior</th>\n",
       "      <th>sec_inv_msa_match_post</th>\n",
       "      <th>sim_docvecs_prior</th>\n",
       "      <th>sim_docvecs_post</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>inv_asg_rank</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.053176</td>\n",
       "      <td>0.088089</td>\n",
       "      <td>0.311498</td>\n",
       "      <td>0.311007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.083393</td>\n",
       "      <td>0.070523</td>\n",
       "      <td>0.317783</td>\n",
       "      <td>0.299359</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              sec_inv_msa_match_prior  sec_inv_msa_match_post  \\\n",
       "inv_asg_rank                                                    \n",
       "0                            0.053176                0.088089   \n",
       "1                            0.083393                0.070523   \n",
       "\n",
       "              sim_docvecs_prior  sim_docvecs_post  \n",
       "inv_asg_rank                                       \n",
       "0                      0.311498          0.311007  \n",
       "1                      0.317783          0.299359  "
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ip[[\"inv_asg_rank\", \"sec_inv_msa_match_prior\", \"sec_inv_msa_match_post\",\n",
    "   \"sim_docvecs_prior\", \"sim_docvecs_post\"]].groupby(\"inv_asg_rank\").mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "c2.to_pickle(\"DataStore/2018-08/inv_move_cites_0912.pkl\")\n",
    "ip.to_pickle(\"DataStore/2018-08/inv_move_pats_0912.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare new assignees at new location's similarity to assignees who already cite prior patent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "yv = \"appyear\"\n",
    "c2 = pd.read_pickle(\"DataStore/2018-08/inv_move_cites_0912.pkl\")\n",
    "ip = pd.read_pickle(\"DataStore/2018-08/inv_move_pats_0912.pkl\")\n",
    "\n",
    "# Use unique assignees\n",
    "c2 = c2.drop([\"cited_asg\", \"citing_asg\"],1)\n",
    "asgs = fastparquet.ParquetFile(\"RawData/Cleaned/patent_assignees_unique_0628.parq\").to_pandas([\"patent\", \"assignee_id\"])\n",
    "pdf = fastparquet.ParquetFile(\"RawData/Cleaned/patent_loc_unique_us_0628.parq\")\\\n",
    ".to_pandas([\"patent\", \"primclass\", \"appyear\"])\n",
    "pdf = pdf.merge(asgs, how = \"left\", on = \"patent\")\n",
    "\n",
    "c2 = c2.merge(asgs, how=\"left\", left_on=\"citing\", right_on=\"patent\").rename(columns={\"assignee_id\": \"citing_asg\"}).drop(\"patent\",1)\n",
    "c2 = c2.merge(asgs, how=\"left\", left_on=\"cited\", right_on=\"patent\").rename(columns={\"assignee_id\": \"cited_asg\"}).drop(\"patent\",1)\n",
    "del(asgs)\n",
    "\n",
    "# New firms that cite prior patent post move\n",
    "a1 = c2.loc[(c2[\"citing_appyear\"] < c2[\"sec_fyear\"]), \"citing_asg\"].tolist()\n",
    "a2 = c2.loc[(c2[\"citing_appyear\"] >= c2[\"sec_fyear\"]), \"citing_asg\"].tolist()\n",
    "new_cite_asgs = list(set(a2).difference(set(a1)))\n",
    "prev_cite_asgs = list(set(a2).intersection(set(a1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "csim = {}\n",
    "csim[\"prev_prior\"] = c2.loc[(c2[\"citing_\"+yv] < c2[\"sec_fyear\"]) & (c2[\"sec_inv_msa_match\"] == True)\\\n",
    "            & c2[\"citing_asg\"].isin(prev_cite_asgs),\n",
    "            [\"cited\", \"sim_docvecs\", \"sim_ldavecs\"]].groupby(\"cited\").mean().add_prefix(\"prev_prior\").reset_index()\n",
    "csim[\"prev_post\"] = c2.loc[(c2[\"citing_\"+yv] >= c2[\"sec_fyear\"]) & (c2[\"sec_inv_msa_match\"] == True)\\\n",
    "            & c2[\"citing_asg\"].isin(prev_cite_asgs),\n",
    "            [\"cited\", \"sim_docvecs\", \"sim_ldavecs\"]].groupby(\"cited\").mean().add_prefix(\"prev_post\").reset_index()\n",
    "csim[\"new_post\"] = c2.loc[(c2[\"citing_\"+yv] >= c2[\"sec_fyear\"]) & (c2[\"sec_inv_msa_match\"] == True)\\\n",
    "            & c2[\"citing_asg\"].isin(new_cite_asgs),\n",
    "            [\"cited\", \"sim_docvecs\", \"sim_ldavecs\"]].groupby(\"cited\").mean().add_prefix(\"new_post_\").reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['patent', 'inventor_id', 'location_id', 'city', 'state', 'country',\n",
       "       'inv_msa', 'gyear', 'assignee_id', 'inv_asg_rank', 'appyear',\n",
       "       'sec_inv_msa', 'sec_fyear', 'sec_inv_msa_match_prior',\n",
       "       'sec_inv_msa_match_post', 'sim_docvecs_prior', 'sim_docvecs_post',\n",
       "       'sim_ldavecs_prior', 'sim_ldavecs_post', 'prev_priorsim_docvecs',\n",
       "       'prev_priorsim_ldavecs', 'prev_postsim_docvecs', 'prev_postsim_ldavecs',\n",
       "       'new_post_sim_docvecs', 'new_post_sim_ldavecs'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ip.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get match rate to second MSA for each patent\n",
    "for k,v in csim.items():\n",
    "    ip = ip.merge(v, how=\"left\", left_on=\"patent\", right_on=\"cited\").drop(\"cited\",1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sec_inv_msa_match_prior    0.057886\n",
       "sec_inv_msa_match_post     0.084252\n",
       "sim_docvecs_prior          0.312521\n",
       "sim_docvecs_post           0.308676\n",
       "sim_ldavecs_prior          0.550057\n",
       "sim_ldavecs_post           0.527295\n",
       "prev_priorsim_docvecs      0.312827\n",
       "prev_priorsim_ldavecs      0.556394\n",
       "prev_postsim_docvecs       0.291704\n",
       "prev_postsim_ldavecs       0.526657\n",
       "new_post_sim_docvecs       0.316823\n",
       "new_post_sim_ldavecs       0.524154\n",
       "dtype: float64"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ip[['sec_inv_msa_match_prior',\n",
    "       'sec_inv_msa_match_post', 'sim_docvecs_prior', 'sim_docvecs_post',\n",
    "       'sim_ldavecs_prior', 'sim_ldavecs_post', 'prev_priorsim_docvecs',\n",
    "       'prev_priorsim_ldavecs', 'prev_postsim_docvecs', 'prev_postsim_ldavecs',\n",
    "       'new_post_sim_docvecs', 'new_post_sim_ldavecs']].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alternatively: Find control patent for each post-move citation\n",
    "- Find new firms that cite prior patent post-move\n",
    "- For each post-move citation at second MSA to inventor's prior move patent, collect all prior 5 year patents from the new citations.\n",
    "- Find \"pre-move\" control in same primary class as citation\n",
    "- Compare their similarities to the prior patent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "yv = \"appyear\"\n",
    "c2 = pd.read_pickle(\"DataStore/2018-08/inv_move_cites_0912.pkl\")\n",
    "ip = pd.read_pickle(\"DataStore/2018-08/inv_move_pats_0912.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Use unique assignees\n",
    "c2 = c2.drop([\"cited_asg\", \"citing_asg\"],1)\n",
    "asgs = fastparquet.ParquetFile(\"RawData/Cleaned/patent_assignees_unique_0628.parq\").to_pandas([\"patent\", \"assignee_id\"])\n",
    "pdf = fastparquet.ParquetFile(\"RawData/Cleaned/patent_loc_unique_us_0628.parq\")\\\n",
    ".to_pandas([\"patent\", \"primclass\", \"appyear\"])\n",
    "pdf = pdf.merge(asgs, how = \"left\", on = \"patent\")\n",
    "\n",
    "c2 = c2.merge(asgs, how=\"left\", left_on=\"citing\", right_on=\"patent\").rename(columns={\"assignee_id\": \"citing_asg\"}).drop(\"patent\",1)\n",
    "c2 = c2.merge(asgs, how=\"left\", left_on=\"cited\", right_on=\"patent\").rename(columns={\"assignee_id\": \"cited_asg\"}).drop(\"patent\",1)\n",
    "del(asgs)\n",
    "# New firms that cite prior patent post move\n",
    "a1 = c2.loc[(c2[\"citing_appyear\"] < c2[\"sec_fyear\"]), \"citing_asg\"].tolist()\n",
    "a2 = c2.loc[(c2[\"citing_appyear\"] >= c2[\"sec_fyear\"]), \"citing_asg\"].tolist()\n",
    "new_cite_asgs = list(set(a2).difference(set(a1)))\n",
    "\n",
    "# New cites\n",
    "c3 = c2.loc[(c2[\"citing_appyear\"] >= c2[\"sec_fyear\"]) & c2[\"citing_asg\"].isin(new_cite_asgs)]\n",
    "\n",
    "# Merge new citing patents with pdf\n",
    "c3[\"citing_primclass\"] = c3[\"patent\"].map(dict(zip(pdf[\"patent\"], pdf[\"primclass\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1975, datetime.datetime(2018, 9, 12, 18, 28, 51, 635257))\n",
      "(1976, datetime.datetime(2018, 9, 12, 18, 28, 52, 135947))\n",
      "(1977, datetime.datetime(2018, 9, 12, 18, 28, 52, 835931))\n",
      "(1978, datetime.datetime(2018, 9, 12, 18, 28, 53, 726811))\n",
      "(1979, datetime.datetime(2018, 9, 12, 18, 28, 55, 496199))\n",
      "(1980, datetime.datetime(2018, 9, 12, 18, 28, 56, 776997))\n",
      "(1981, datetime.datetime(2018, 9, 12, 18, 28, 59, 236089))\n",
      "(1982, datetime.datetime(2018, 9, 12, 18, 29, 0, 969631))\n",
      "(1983, datetime.datetime(2018, 9, 12, 18, 29, 3, 8536))\n",
      "(1984, datetime.datetime(2018, 9, 12, 18, 29, 4, 930146))\n",
      "(1985, datetime.datetime(2018, 9, 12, 18, 29, 7, 101588))\n",
      "(1986, datetime.datetime(2018, 9, 12, 18, 29, 9, 467290))\n",
      "(1987, datetime.datetime(2018, 9, 12, 18, 29, 11, 997276))\n",
      "(1988, datetime.datetime(2018, 9, 12, 18, 29, 14, 729875))\n",
      "(1989, datetime.datetime(2018, 9, 12, 18, 29, 17, 744897))\n",
      "(1990, datetime.datetime(2018, 9, 12, 18, 29, 21, 451266))\n",
      "(1991, datetime.datetime(2018, 9, 12, 18, 29, 25, 27712))\n",
      "(1992, datetime.datetime(2018, 9, 12, 18, 29, 28, 997574))\n",
      "(1993, datetime.datetime(2018, 9, 12, 18, 29, 33, 379715))\n",
      "(1994, datetime.datetime(2018, 9, 12, 18, 29, 38, 123509))\n",
      "(1995, datetime.datetime(2018, 9, 12, 18, 29, 43, 488655))\n",
      "(1996, datetime.datetime(2018, 9, 12, 18, 29, 49, 225796))\n",
      "(1997, datetime.datetime(2018, 9, 12, 18, 29, 55, 513731))\n",
      "(1998, datetime.datetime(2018, 9, 12, 18, 30, 2, 811214))\n",
      "(1999, datetime.datetime(2018, 9, 12, 18, 30, 10, 854931))\n",
      "(2000, datetime.datetime(2018, 9, 12, 18, 30, 19, 755074))\n",
      "(2001, datetime.datetime(2018, 9, 12, 18, 30, 29, 509610))\n",
      "(2002, datetime.datetime(2018, 9, 12, 18, 30, 40, 2515))\n",
      "(2003, datetime.datetime(2018, 9, 12, 18, 30, 51, 682806))\n",
      "(2004, datetime.datetime(2018, 9, 12, 18, 31, 4, 728667))\n",
      "(2005, datetime.datetime(2018, 9, 12, 18, 31, 18, 207744))\n",
      "(2006, datetime.datetime(2018, 9, 12, 18, 31, 32, 319123))\n",
      "(2007, datetime.datetime(2018, 9, 12, 18, 31, 46, 634498))\n",
      "(2008, datetime.datetime(2018, 9, 12, 18, 32, 1, 284520))\n",
      "(2009, datetime.datetime(2018, 9, 12, 18, 32, 16, 446217))\n",
      "(2010, datetime.datetime(2018, 9, 12, 18, 32, 31, 365475))\n",
      "(2011, datetime.datetime(2018, 9, 12, 18, 32, 47, 412215))\n",
      "(2012, datetime.datetime(2018, 9, 12, 18, 33, 4, 64196))\n",
      "(2013, datetime.datetime(2018, 9, 12, 18, 33, 19, 292013))\n",
      "(2014, datetime.datetime(2018, 9, 12, 18, 33, 35, 716793))\n",
      "(2015, datetime.datetime(2018, 9, 12, 18, 33, 50, 746354))\n"
     ]
    }
   ],
   "source": [
    "# Patents by newly citing assignees\n",
    "pdf = pdf.loc[pdf[\"assignee_id\"].isin(new_cite_asgs)]\n",
    "len(pdf)\n",
    "\n",
    "# Sort by assignee, primclass, app year\n",
    "pdf = pdf.sort_values([\"assignee_id\", \"primclass\", yv], ascending = [1,1,0])\n",
    "\n",
    "# Groupby assignee, primclass, app year\n",
    "p2 = pdf.groupby([\"assignee_id\", \"primclass\"])\n",
    "\n",
    "# Control patent by assignee, primclass and by assignee\n",
    "cdict = {}\n",
    "adict = {}\n",
    "for yr in range(1975, 2016):\n",
    "    print(yr)\n",
    "    print(datetime.datetime.now())\n",
    "    # Control patent by assignee, primclass\n",
    "    p2 = pdf.loc[pdf[\"appyear\"] <= yr].groupby([\"assignee_id\", \"primclass\"])\n",
    "    p2 = {n+(yr,): (g[\"patent\"].tolist()[0] if len(g[\"patent\"].tolist()) >= 1 else None) for n,g in p2}\n",
    "    cdict.update(p2)\n",
    "    del(p2)\n",
    "    \n",
    "    # Control patent by assignee\n",
    "    p2 = pdf.loc[pdf[\"appyear\"] <= yr].groupby([\"assignee_id\"])\n",
    "    p2 = {n+(yr,): (g[\"patent\"].tolist()[0] if len(g[\"patent\"].tolist()) >= 1 else None) for n,g in p2}\n",
    "    adict.update(p2)\n",
    "    del(p2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1975\n",
      "2018-09-12 18:40:39.833854\n",
      "1976\n",
      "2018-09-12 18:40:40.281794\n",
      "1977\n",
      "2018-09-12 18:40:40.829632\n",
      "1978\n",
      "2018-09-12 18:40:41.458402\n",
      "1979\n",
      "2018-09-12 18:40:41.817494\n",
      "1980\n",
      "2018-09-12 18:40:42.116286\n",
      "1981\n",
      "2018-09-12 18:40:42.429928\n",
      "1982\n",
      "2018-09-12 18:40:42.777987\n",
      "1983\n",
      "2018-09-12 18:40:43.177171\n",
      "1984\n",
      "2018-09-12 18:40:43.583857\n",
      "1985\n",
      "2018-09-12 18:40:44.020038\n",
      "1986\n",
      "2018-09-12 18:40:44.491436\n",
      "1987\n",
      "2018-09-12 18:40:45.025346\n",
      "1988\n",
      "2018-09-12 18:40:45.604174\n",
      "1989\n",
      "2018-09-12 18:40:46.243011\n",
      "1990\n",
      "2018-09-12 18:40:46.963860\n",
      "1991\n",
      "2018-09-12 18:40:48.049021\n",
      "1992\n",
      "2018-09-12 18:40:48.867267\n",
      "1993\n",
      "2018-09-12 18:40:49.760100\n",
      "1994\n",
      "2018-09-12 18:40:51.412896\n",
      "1995\n",
      "2018-09-12 18:40:52.493863\n",
      "1996\n",
      "2018-09-12 18:40:53.827819\n",
      "1997\n",
      "2018-09-12 18:40:55.554711\n",
      "1998\n",
      "2018-09-12 18:40:56.962803\n",
      "1999\n",
      "2018-09-12 18:40:58.554763\n",
      "2000\n",
      "2018-09-12 18:41:00.336829\n",
      "2001\n",
      "2018-09-12 18:41:02.270491\n",
      "2002\n",
      "2018-09-12 18:41:04.289600\n",
      "2003\n",
      "2018-09-12 18:41:06.791542\n",
      "2004\n",
      "2018-09-12 18:41:09.193989\n",
      "2005\n",
      "2018-09-12 18:41:11.706246\n",
      "2006\n",
      "2018-09-12 18:41:14.239478\n",
      "2007\n",
      "2018-09-12 18:41:16.928428\n",
      "2008\n",
      "2018-09-12 18:41:19.636886\n",
      "2009\n",
      "2018-09-12 18:41:23.233507\n",
      "2010\n",
      "2018-09-12 18:41:25.847131\n",
      "2011\n",
      "2018-09-12 18:41:28.538769\n",
      "2012\n",
      "2018-09-12 18:41:31.228834\n",
      "2013\n",
      "2018-09-12 18:41:33.866569\n",
      "2014\n",
      "2018-09-12 18:41:36.534505\n",
      "2015\n",
      "2018-09-12 18:41:39.163725\n"
     ]
    }
   ],
   "source": [
    "adict = {}\n",
    "for yr in range(1975, 2016):\n",
    "    print(yr)\n",
    "    print(datetime.datetime.now())\n",
    "    # Control patent by assignee\n",
    "    p2 = pdf.loc[pdf[\"appyear\"] <= yr].groupby([\"assignee_id\"])\n",
    "    p2 = {(n,yr): (g[\"patent\"].tolist()[0] if len(g[\"patent\"].tolist()) >= 1 else None) for n,g in p2}\n",
    "    adict.update(p2)\n",
    "    del(p2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "c3[\"citing_control_asg_pc\"] = [cdict.get((asg, pc, fyr)) for asg,pc,fyr in \\\n",
    "                        zip(c3[\"citing_asg\"], c3[\"citing_primclass\"], c3[\"sec_fyear\"])]\n",
    "c3[\"citing_control_asg\"] = [adict.get((asg, fyr)) for asg,fyr in \\\n",
    "                        zip(c3[\"citing_asg\"], c3[\"sec_fyear\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "c3.to_pickle(\"DataStore/2018-08/post_move_new_asgs_cites_0912.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting row values\n",
      "2018-09-12 19:00:47.175140\n",
      "('ldavecs', 'started')\n",
      "Loading matrix and dict\n",
      "2018-09-12 19:00:48.730896\n",
      "20279\n",
      "Getting chunks\n",
      "2018-09-12 19:01:00.924875\n",
      "Getting patent pair cosine similarity\n",
      "2018-09-12 19:01:01.124369\n",
      "27817\n",
      "finished\n",
      "2018-09-12 19:01:08.122148\n",
      "3155\n",
      "Getting chunks\n",
      "2018-09-12 19:01:08.680456\n",
      "Getting patent pair cosine similarity\n",
      "2018-09-12 19:01:08.713049\n",
      "27817\n",
      "finished\n",
      "2018-09-12 19:01:09.393616\n",
      "5177\n",
      "Getting chunks\n",
      "2018-09-12 19:01:10.158479\n",
      "Getting patent pair cosine similarity\n",
      "2018-09-12 19:01:10.209352\n",
      "27817\n",
      "finished\n",
      "2018-09-12 19:01:10.764584\n",
      "('docvecs', 'started')\n",
      "Loading matrix and dict\n",
      "2018-09-12 19:01:10.844574\n",
      "20279\n",
      "Getting chunks\n",
      "2018-09-12 19:01:27.229880\n",
      "Getting patent pair cosine similarity\n",
      "2018-09-12 19:01:27.420612\n",
      "27817\n",
      "finished\n",
      "2018-09-12 19:01:30.879961\n",
      "3155\n",
      "Getting chunks\n",
      "2018-09-12 19:01:31.411230\n",
      "Getting patent pair cosine similarity\n",
      "2018-09-12 19:01:31.446447\n",
      "27817\n",
      "finished\n",
      "2018-09-12 19:01:32.018743\n",
      "5177\n",
      "Getting chunks\n",
      "2018-09-12 19:01:32.920898\n",
      "Getting patent pair cosine similarity\n",
      "2018-09-12 19:01:33.056912\n",
      "27817\n",
      "finished\n",
      "2018-09-12 19:01:34.255841\n"
     ]
    }
   ],
   "source": [
    "def grouper(n, iterable):\n",
    "    \"\"\"\n",
    "    >>> list(grouper(3, 'ABCDEFG'))\n",
    "    [['A', 'B', 'C'], ['D', 'E', 'F'], ['G']]\n",
    "    \"\"\"\n",
    "    iterable = iter(iterable)\n",
    "    return iter(lambda: list(itertools.islice(iterable, n)), [])\n",
    "\n",
    "\n",
    "import scipy.spatial.distance as distance\n",
    "dms = [\"ldavecs\", \"docvecs\"]\n",
    "\n",
    "print(\"Getting row values\")\n",
    "print(datetime.datetime.now())\n",
    "pat_dict = fastparquet.ParquetFile(\"RawData/Cleaned/patabs7615_us_no_dup.parq\").to_pandas([\"patent\"])[\"patent\"].tolist()\n",
    "pat_dict = dict(zip(pat_dict, range(len(pat_dict))))\n",
    "\n",
    "\n",
    "l2 = c3.copy()\n",
    "\n",
    "for dm in dms:\n",
    "    print((dm,\"started\"))\n",
    "    print(\"Loading matrix and dict\")\n",
    "    print(datetime.datetime.now())\n",
    "    \n",
    "    if dm == \"ldavecs\":\n",
    "        ncols = 60\n",
    "    else:\n",
    "        ncols = 100\n",
    "\n",
    "    pm = fastparquet.ParquetFile(\"DataStore/2018-07-P2/ML/{0}_pats_0712.parq\".format(dm))\\\n",
    "    .to_pandas().values\n",
    "    \n",
    "    for col in [\"citing\", \"citing_control_asg_pc\", \"citing_control_asg\"]:\n",
    "        l3 = pd.DataFrame({\"tp\": c3[\"cited\"], \"op\": c3[col]})\n",
    "        l3 = l3.dropna(how=\"any\").drop_duplicates()\n",
    "        # Store copy as array\n",
    "        l3 = l3.loc[l3[\"tp\"].isin(pat_dict.keys()) & l3[\"op\"].isin(pat_dict.keys())]\n",
    "        print(len(l3))\n",
    "\n",
    "        # Convert to chunks\n",
    "        print(\"Getting chunks\")\n",
    "        print(datetime.datetime.now())\n",
    "        # Split into chunks\n",
    "        n_rows = 3000\n",
    "        n_chunks = int(np.round(len(l3)/n_rows))\n",
    "        tp_chunks = grouper(n_rows, pm[[pat_dict[p[1]] for p in l3[\"tp\"].iteritems()]])\n",
    "        op_chunks = grouper(n_rows, pm[[pat_dict[p[1]] for p in l3[\"op\"].iteritems()]])\n",
    "        \n",
    "        chunks = itertools.zip_longest(tp_chunks, op_chunks)\n",
    "\n",
    "        print(\"Getting patent pair cosine similarity\")\n",
    "        print(datetime.datetime.now())\n",
    "        # Cosine\n",
    "\n",
    "        cos_dis = np.empty(len(l3))\n",
    "\n",
    "        for r, c in enumerate(chunks):\n",
    "            cos_dis[r*n_rows:r*n_rows+n_rows] = np.diag(distance.cdist(c[0],c[1], metric = \"cosine\"))\n",
    "\n",
    "        l3[\"sim_{0}_{1}\".format(dm,col)] = 1-cos_dis\n",
    "\n",
    "        # Rename columns\n",
    "        l3 = l3.rename(columns={\"tp\": \"cited\", \"op\": col})\n",
    "        l2 = l2.merge(l3, how = \"left\", on = [\"cited\", col])\n",
    "        print(len(l2))\n",
    "        del(l3)\n",
    "        print(\"finished\")\n",
    "        print(datetime.datetime.now())\n",
    "    del(pm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "c3 = l2\n",
    "c4 = c3[[\"cited\", \"sim_docvecs_citing\", \"sim_docvecs_citing_control_asg_pc\", \"sim_docvecs_citing_control_asg\"]]\\\n",
    ".groupby(\"cited\").mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sim_docvecs_citing                   0.296676\n",
       "sim_docvecs_citing_control_asg_pc    0.259042\n",
       "dtype: float64"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l2.dropna(subset=[\"sim_docvecs_citing\", \"sim_docvecs_citing_control_asg_pc\"], how=\"any\")\\\n",
    "[[\"sim_docvecs_citing\", \"sim_docvecs_citing_control_asg_pc\"]].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sim_docvecs_citing                0.281617\n",
       "sim_docvecs_citing_control_asg    0.176468\n",
       "dtype: float64"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l2.dropna(subset=[\"sim_docvecs_citing\", \"sim_docvecs_citing_control_asg\"], how=\"any\")\\\n",
    "[[\"sim_docvecs_citing\", \"sim_docvecs_citing_control_asg\"]].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sim_docvecs_citing</th>\n",
       "      <th>sim_docvecs_citing_control_asg_pc</th>\n",
       "      <th>sim_docvecs_citing_control_asg</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cited</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3930285</th>\n",
       "      <td>0.152503</td>\n",
       "      <td>-0.031136</td>\n",
       "      <td>0.310015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3932329</th>\n",
       "      <td>0.248710</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.087314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3932330</th>\n",
       "      <td>0.351866</td>\n",
       "      <td>0.350457</td>\n",
       "      <td>-0.027972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3932797</th>\n",
       "      <td>0.434263</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3933628</th>\n",
       "      <td>0.286781</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3934161</th>\n",
       "      <td>0.301041</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3934528</th>\n",
       "      <td>0.441375</td>\n",
       "      <td>0.161984</td>\n",
       "      <td>0.055646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3934617</th>\n",
       "      <td>0.276021</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.094469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3934618</th>\n",
       "      <td>0.146126</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.002138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3934727</th>\n",
       "      <td>0.399669</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3935847</th>\n",
       "      <td>0.075920</td>\n",
       "      <td>0.075920</td>\n",
       "      <td>0.075920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3935848</th>\n",
       "      <td>0.097822</td>\n",
       "      <td>0.097822</td>\n",
       "      <td>0.097822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3936178</th>\n",
       "      <td>0.387777</td>\n",
       "      <td>0.387777</td>\n",
       "      <td>0.385671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3936211</th>\n",
       "      <td>0.312789</td>\n",
       "      <td>0.306695</td>\n",
       "      <td>0.306695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3936220</th>\n",
       "      <td>0.208187</td>\n",
       "      <td>0.223780</td>\n",
       "      <td>-0.059716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3936565</th>\n",
       "      <td>0.282744</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3938535</th>\n",
       "      <td>0.474463</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3939311</th>\n",
       "      <td>0.205294</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3940006</th>\n",
       "      <td>0.308009</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.280825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3940547</th>\n",
       "      <td>0.358596</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3940807</th>\n",
       "      <td>0.394996</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3940826</th>\n",
       "      <td>0.292034</td>\n",
       "      <td>0.251965</td>\n",
       "      <td>0.254570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3940962</th>\n",
       "      <td>0.502591</td>\n",
       "      <td>0.391958</td>\n",
       "      <td>0.355954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3941160</th>\n",
       "      <td>0.463460</td>\n",
       "      <td>0.369738</td>\n",
       "      <td>0.117262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3941196</th>\n",
       "      <td>0.068717</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3941994</th>\n",
       "      <td>0.638461</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3942601</th>\n",
       "      <td>0.270315</td>\n",
       "      <td>0.270315</td>\n",
       "      <td>0.049304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3942869</th>\n",
       "      <td>0.449515</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3943020</th>\n",
       "      <td>0.229155</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3943047</th>\n",
       "      <td>0.203802</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7177872</th>\n",
       "      <td>0.092685</td>\n",
       "      <td>0.132737</td>\n",
       "      <td>0.156366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7180716</th>\n",
       "      <td>0.412559</td>\n",
       "      <td>0.214822</td>\n",
       "      <td>0.351532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7182771</th>\n",
       "      <td>0.459927</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7186190</th>\n",
       "      <td>0.379166</td>\n",
       "      <td>0.573722</td>\n",
       "      <td>0.430366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7192436</th>\n",
       "      <td>0.194451</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7201725</th>\n",
       "      <td>0.404381</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.510079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7216290</th>\n",
       "      <td>0.311624</td>\n",
       "      <td>-0.041829</td>\n",
       "      <td>0.085580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7220001</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.185748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7240059</th>\n",
       "      <td>0.103924</td>\n",
       "      <td>-0.078892</td>\n",
       "      <td>0.146165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7249050</th>\n",
       "      <td>0.215257</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7251406</th>\n",
       "      <td>0.267792</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.002370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7253109</th>\n",
       "      <td>0.260852</td>\n",
       "      <td>0.092423</td>\n",
       "      <td>-0.006563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7265947</th>\n",
       "      <td>0.470863</td>\n",
       "      <td>0.147210</td>\n",
       "      <td>0.359940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7267787</th>\n",
       "      <td>0.220057</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7289295</th>\n",
       "      <td>0.592796</td>\n",
       "      <td>0.314796</td>\n",
       "      <td>0.415666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7295702</th>\n",
       "      <td>0.186185</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.031445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7311858</th>\n",
       "      <td>0.302727</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7318998</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7343319</th>\n",
       "      <td>0.340814</td>\n",
       "      <td>0.165876</td>\n",
       "      <td>0.165876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7343339</th>\n",
       "      <td>0.381024</td>\n",
       "      <td>0.381024</td>\n",
       "      <td>0.381024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7345575</th>\n",
       "      <td>0.395378</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7368798</th>\n",
       "      <td>0.119033</td>\n",
       "      <td>0.075022</td>\n",
       "      <td>0.186857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7403942</th>\n",
       "      <td>0.175929</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7427762</th>\n",
       "      <td>0.025790</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7460224</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7472349</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.026278</td>\n",
       "      <td>0.103407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7504854</th>\n",
       "      <td>0.320191</td>\n",
       "      <td>0.320191</td>\n",
       "      <td>-0.039277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7506274</th>\n",
       "      <td>0.627571</td>\n",
       "      <td>0.338517</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7536349</th>\n",
       "      <td>0.099419</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.269324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7613631</th>\n",
       "      <td>0.367075</td>\n",
       "      <td>0.233033</td>\n",
       "      <td>0.100745</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4520 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         sim_docvecs_citing  sim_docvecs_citing_control_asg_pc  \\\n",
       "cited                                                            \n",
       "3930285            0.152503                          -0.031136   \n",
       "3932329            0.248710                                NaN   \n",
       "3932330            0.351866                           0.350457   \n",
       "3932797            0.434263                                NaN   \n",
       "3933628            0.286781                                NaN   \n",
       "3934161            0.301041                                NaN   \n",
       "3934528            0.441375                           0.161984   \n",
       "3934617            0.276021                                NaN   \n",
       "3934618            0.146126                                NaN   \n",
       "3934727            0.399669                                NaN   \n",
       "3935847            0.075920                           0.075920   \n",
       "3935848            0.097822                           0.097822   \n",
       "3936178            0.387777                           0.387777   \n",
       "3936211            0.312789                           0.306695   \n",
       "3936220            0.208187                           0.223780   \n",
       "3936565            0.282744                                NaN   \n",
       "3938535            0.474463                                NaN   \n",
       "3939311            0.205294                                NaN   \n",
       "3940006            0.308009                                NaN   \n",
       "3940547            0.358596                                NaN   \n",
       "3940807            0.394996                                NaN   \n",
       "3940826            0.292034                           0.251965   \n",
       "3940962            0.502591                           0.391958   \n",
       "3941160            0.463460                           0.369738   \n",
       "3941196            0.068717                                NaN   \n",
       "3941994            0.638461                                NaN   \n",
       "3942601            0.270315                           0.270315   \n",
       "3942869            0.449515                                NaN   \n",
       "3943020            0.229155                                NaN   \n",
       "3943047            0.203802                                NaN   \n",
       "...                     ...                                ...   \n",
       "7177872            0.092685                           0.132737   \n",
       "7180716            0.412559                           0.214822   \n",
       "7182771            0.459927                                NaN   \n",
       "7186190            0.379166                           0.573722   \n",
       "7192436            0.194451                                NaN   \n",
       "7201725            0.404381                                NaN   \n",
       "7216290            0.311624                          -0.041829   \n",
       "7220001                 NaN                                NaN   \n",
       "7240059            0.103924                          -0.078892   \n",
       "7249050            0.215257                                NaN   \n",
       "7251406            0.267792                                NaN   \n",
       "7253109            0.260852                           0.092423   \n",
       "7265947            0.470863                           0.147210   \n",
       "7267787            0.220057                                NaN   \n",
       "7289295            0.592796                           0.314796   \n",
       "7295702            0.186185                                NaN   \n",
       "7311858            0.302727                                NaN   \n",
       "7318998                 NaN                                NaN   \n",
       "7343319            0.340814                           0.165876   \n",
       "7343339            0.381024                           0.381024   \n",
       "7345575            0.395378                                NaN   \n",
       "7368798            0.119033                           0.075022   \n",
       "7403942            0.175929                                NaN   \n",
       "7427762            0.025790                                NaN   \n",
       "7460224                 NaN                                NaN   \n",
       "7472349                 NaN                           0.026278   \n",
       "7504854            0.320191                           0.320191   \n",
       "7506274            0.627571                           0.338517   \n",
       "7536349            0.099419                                NaN   \n",
       "7613631            0.367075                           0.233033   \n",
       "\n",
       "         sim_docvecs_citing_control_asg  \n",
       "cited                                    \n",
       "3930285                        0.310015  \n",
       "3932329                        0.087314  \n",
       "3932330                       -0.027972  \n",
       "3932797                             NaN  \n",
       "3933628                             NaN  \n",
       "3934161                             NaN  \n",
       "3934528                        0.055646  \n",
       "3934617                        0.094469  \n",
       "3934618                        0.002138  \n",
       "3934727                             NaN  \n",
       "3935847                        0.075920  \n",
       "3935848                        0.097822  \n",
       "3936178                        0.385671  \n",
       "3936211                        0.306695  \n",
       "3936220                       -0.059716  \n",
       "3936565                             NaN  \n",
       "3938535                             NaN  \n",
       "3939311                             NaN  \n",
       "3940006                        0.280825  \n",
       "3940547                             NaN  \n",
       "3940807                             NaN  \n",
       "3940826                        0.254570  \n",
       "3940962                        0.355954  \n",
       "3941160                        0.117262  \n",
       "3941196                             NaN  \n",
       "3941994                             NaN  \n",
       "3942601                        0.049304  \n",
       "3942869                             NaN  \n",
       "3943020                             NaN  \n",
       "3943047                             NaN  \n",
       "...                                 ...  \n",
       "7177872                        0.156366  \n",
       "7180716                        0.351532  \n",
       "7182771                             NaN  \n",
       "7186190                        0.430366  \n",
       "7192436                             NaN  \n",
       "7201725                        0.510079  \n",
       "7216290                        0.085580  \n",
       "7220001                       -0.185748  \n",
       "7240059                        0.146165  \n",
       "7249050                             NaN  \n",
       "7251406                        0.002370  \n",
       "7253109                       -0.006563  \n",
       "7265947                        0.359940  \n",
       "7267787                             NaN  \n",
       "7289295                        0.415666  \n",
       "7295702                        0.031445  \n",
       "7311858                             NaN  \n",
       "7318998                             NaN  \n",
       "7343319                        0.165876  \n",
       "7343339                        0.381024  \n",
       "7345575                             NaN  \n",
       "7368798                        0.186857  \n",
       "7403942                             NaN  \n",
       "7427762                             NaN  \n",
       "7460224                             NaN  \n",
       "7472349                        0.103407  \n",
       "7504854                       -0.039277  \n",
       "7506274                             NaN  \n",
       "7536349                        0.269324  \n",
       "7613631                        0.100745  \n",
       "\n",
       "[4520 rows x 3 columns]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
