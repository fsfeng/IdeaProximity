{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/homedir/eco/sfeng/bigdata/python/miniconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "import timeit\n",
    "import datetime\n",
    "import time\n",
    "import pprint\n",
    "import itertools\n",
    "import pickle\n",
    "import sklearn\n",
    "import dask\n",
    "import dask.dataframe as dd\n",
    "import os\n",
    "os.chdir('/mnt/t48/bighomes-active/sfeng/patentdiffusion/')\n",
    "import fastparquet\n",
    "seed = 3\n",
    "import seaborn as sns\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "# Distances\n",
    "import scipy.spatial.distance as distance\n",
    "# KL\n",
    "from scipy.stats import entropy\n",
    "# Normalize\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "# Pairwise distances\n",
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "import h5py\n",
    "import logging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding variables\n",
    "- NAICS: PC Match, Patents share inventor, Patent assignee share inventor\n",
    "- PC: Patents share inventor, Patent assignee share inventor\n",
    "\n",
    "### Common inventor at establishment (assignee-MSA)\n",
    "\n",
    "1. Get patent-assignee-msaname\n",
    "2. Get patent-inventors\n",
    "3. Merge\n",
    "4. Groupby assignee_id, msaname (establishment). Have to do this by grant year. Only get inventors in previous 10 years at establishment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5017246\n",
      "4438592\n",
      "4438592\n"
     ]
    }
   ],
   "source": [
    "# # Get assignees and their locations (not inventors)\n",
    "# asg = fastparquet.ParquetFile(\"RawData/Cleaned/patent_assignees_0628.parq\").to_pandas([\"assignee_id\", \"msaname\", \"patent\", \"type\"])\n",
    "# asg = asg.groupby([\"patent\", \"assignee_id\", \"msaname\"]).count().reset_index().sort_values(\"type\", ascending=False).drop_duplicates(\"patent\")\n",
    "# asg = asg.drop(\"type\",1)\n",
    "\n",
    "\n",
    "# # Merge inventors to patents\n",
    "# inv = fastparquet.ParquetFile(\"RawData/Cleaned/patent_inventors_0628.parq\").to_pandas([\"patent\", \"inventor_id\"])\n",
    "# inv = inv.merge(asg, how=\"left\", on=\"patent\")\n",
    "# del(asg)\n",
    "# print(len(inv))\n",
    "# inv = inv.dropna(how=\"any\")\n",
    "# print(len(inv))\n",
    "\n",
    "# # Merge grant year\n",
    "# pdf = fastparquet.ParquetFile(\"RawData/Cleaned/patent_loc_unique_us_0628.parq\").to_pandas([\"patent\", \"gyear\"])\n",
    "# inv = inv.merge(pdf, how=\"left\", on=\"patent\")\n",
    "# del(pdf)\n",
    "# print(len(inv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save inventor-assignee-patent data\n",
    "# fastparquet.write(\"RawData/Cleaned/patent_inv_asg_0808.parq\", inv, compression=\"GZIP\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5min 12s, sys: 2.18 s, total: 5min 14s\n",
      "Wall time: 5min 14s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "inv = fastparquet.ParquetFile(\"RawData/Cleaned/patent_inv_asg_0808.parq\").to_pandas()\n",
    "inv_dict = {}\n",
    "for gy in range(1976,2016):\n",
    "    p2 = inv.loc[inv[\"gyear\"].isin(range(gy-10,gy)), [\"assignee_id\", \"msaname\", \"inventor_id\"]].\\\n",
    "    groupby([\"assignee_id\", \"msaname\"])\n",
    "    invd = {n+(gy,): g[\"inventor_id\"].tolist() for n,g in p2}\n",
    "    inv_dict.update(invd)\n",
    "    del(p2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get necessary stuff ready for other files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1498184\n",
      "reg_naics_name_sim_tr_0726.parq\n",
      "1369833\n",
      "reg_primclass_sim_tr_0726.parq\n"
     ]
    }
   ],
   "source": [
    "# Save necessary data\n",
    "files = [\"reg_naics_name_sim_tr_0726.parq\", \"reg_primclass_sim_tr_0726.parq\"]\n",
    "pathdir = \"DataStore/2018-07-P2/Reg0726/\"\n",
    "for f in files:\n",
    "    mdc = fastparquet.ParquetFile(pathdir+f).to_pandas(columns=['tp', 'op', 'tp_gyear', 'tp_inv_msa', 'op_inv_msa'])\n",
    "    print(len(mdc))\n",
    "    print(f)\n",
    "    # Other patent grant year\n",
    "    pdf = fastparquet.ParquetFile(\"RawData/Cleaned/patent_loc_unique_us_0628.parq\").to_pandas([\"patent\", \"gyear\"])\n",
    "    mdc[\"op_gyear\"] = mdc[\"op\"].map(dict(zip(pdf[\"patent\"], pdf[\"gyear\"])))\n",
    "    del(pdf)\n",
    "    \n",
    "    # Unique assignee for each patent\n",
    "    asg = fastparquet.ParquetFile(\"RawData/Cleaned/patent_inv_asg_0808.parq\").to_pandas([\"patent\", \"assignee_id\", \"msaname\"]).drop_duplicates()\n",
    "    mdc = mdc.merge(asg.add_prefix(\"tp_\"), how = \"left\", left_on = \"tp\", right_on = \"tp_patent\").drop(\"tp_patent\",1)\n",
    "    mdc = mdc.merge(asg.add_prefix(\"op_\"), how = \"left\", left_on = \"op\", right_on = \"op_patent\").drop(\"op_patent\",1)\n",
    "    del(asg)\n",
    "    \n",
    "    # Save output\n",
    "    if \"naics_name\" in f:\n",
    "        fn = \"naics_name_common_inv_0726.parq\"\n",
    "    else:\n",
    "        fn = \"primclass_common_inv_0726.parq\"\n",
    "    \n",
    "    fastparquet.write(pathdir+fn, mdc, compression=\"GZIP\")\n",
    "    del(mdc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "naics_name_common_inv_0726.parq\n",
      "1498184\n",
      "CPU times: user 10min 29s, sys: 150 ms, total: 10min 29s\n",
      "Wall time: 10min 28s\n",
      "False    656592\n",
      "True     158028\n",
      "Name: common_est_inv, dtype: int64\n",
      "primclass_common_inv_0726.parq\n",
      "1369833\n",
      "CPU times: user 10min 6s, sys: 143 ms, total: 10min 6s\n",
      "Wall time: 10min 4s\n",
      "False    585932\n",
      "True     181347\n",
      "Name: common_est_inv, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Load new files and get common inventors\n",
    "files = [\"naics_name_common_inv_0726.parq\", \"primclass_common_inv_0726.parq\"]\n",
    "# files = [\"naics_name_common_inv_0726.parq\"]\n",
    "pathdir = \"DataStore/2018-07-P2/Reg0726/\"\n",
    "\n",
    "for f in files:\n",
    "    mdc = fastparquet.ParquetFile(pathdir+f).to_pandas()\n",
    "    print(f)\n",
    "    print(len(mdc))\n",
    "    %time num_common_inv = [len(set(inv_dict[tp]).intersection(inv_dict[op])) if (tp in inv_dict.keys()) & (op in inv_dict.keys())\\\n",
    "                      else np.nan for tp, op in zip(list(zip(mdc[\"tp_assignee_id\"], mdc[\"tp_msaname\"], mdc[\"tp_gyear\"])),\\\n",
    "                                                    list(zip(mdc[\"op_assignee_id\"], mdc[\"op_msaname\"], mdc[\"op_gyear\"])))]\n",
    "    mdc[\"num_common_est_inv\"] = num_common_inv\n",
    "    del(num_common_inv)\n",
    "    mdc[\"common_est_inv\"] = np.nan\n",
    "    mdc.loc[mdc[\"num_common_est_inv\"] >= 1, \"common_est_inv\"] = True\n",
    "    mdc.loc[mdc[\"num_common_est_inv\"] == 0, \"common_est_inv\"] = False\n",
    "    print(mdc[\"common_est_inv\"].value_counts())\n",
    "    fastparquet.write(pathdir+f, mdc, compression=\"GZIP\")\n",
    "    del(mdc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del(inv_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add number of common inventors in each patent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7min 10s, sys: 313 ms, total: 7min 10s\n",
      "Wall time: 7min 9s\n"
     ]
    }
   ],
   "source": [
    "inv = fastparquet.ParquetFile(\"RawData/Cleaned/patent_inventors_0628.parq\").to_pandas([\"patent\", \"inventor_id\"])\n",
    "%time inv = {n: g[\"inventor_id\"].tolist() for n, g in inv.groupby(\"patent\")}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "naics_name_common_inv_0726.parq\n",
      "1498184\n",
      "CPU times: user 4.25 s, sys: 11.1 ms, total: 4.26 s\n",
      "Wall time: 4.23 s\n",
      "0    1496604\n",
      "1       1408\n",
      "2        143\n",
      "3         26\n",
      "4          3\n",
      "Name: num_common_pat_inv, dtype: int64\n",
      "1498184\n",
      "primclass_common_inv_0726.parq\n",
      "1369833\n",
      "CPU times: user 4.77 s, sys: 7.98 ms, total: 4.77 s\n",
      "Wall time: 4.77 s\n",
      "0    1365446\n",
      "1       3779\n",
      "2        470\n",
      "3        105\n",
      "4         20\n",
      "5          6\n",
      "8          3\n",
      "6          3\n",
      "7          1\n",
      "Name: num_common_pat_inv, dtype: int64\n",
      "1369833\n"
     ]
    }
   ],
   "source": [
    "# Load new files and get common inventors\n",
    "files = [\"naics_name_common_inv_0726.parq\", \"primclass_common_inv_0726.parq\"]\n",
    "# files = [\"naics_name_common_inv_0726.parq\"]\n",
    "pathdir = \"DataStore/2018-07-P2/Reg0726/\"\n",
    "\n",
    "for f in files:\n",
    "    mdc = fastparquet.ParquetFile(pathdir+f).to_pandas()\n",
    "    print(f)\n",
    "    print(len(mdc))\n",
    "    %time num_common_inv = [len(set(inv[tp]).intersection(inv[op])) if (tp in inv.keys()) & (op in inv.keys())\\\n",
    "                      else np.nan for tp, op in zip(mdc[\"tp\"], mdc[\"op\"])]\n",
    "    mdc[\"num_common_pat_inv\"] = num_common_inv\n",
    "    del(num_common_inv)\n",
    "    mdc[\"common_pat_inv\"] = np.nan\n",
    "    mdc.loc[mdc[\"num_common_pat_inv\"] >= 1, \"common_pat_inv\"] = True\n",
    "    mdc.loc[mdc[\"num_common_pat_inv\"] == 0, \"common_pat_inv\"] = False\n",
    "    print(mdc[\"num_common_pat_inv\"].value_counts())\n",
    "    print(len(mdc))\n",
    "    fastparquet.write(pathdir+f, mdc, compression=\"GZIP\")\n",
    "    del(mdc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add lawyers indicator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/homedir/eco/sfeng/bigdata/python/miniconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2785: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "ldf = pd.read_table(\"RawData/PatentView/patent_lawyer.tsv\")\n",
    "\n",
    "def get_numeric(p):\n",
    "    try:\n",
    "        return int(p)\n",
    "    except Exception:\n",
    "        return np.nan\n",
    "    \n",
    "ldf[\"patent\"] = ldf[\"patent_id\"].apply(get_numeric)\n",
    "ldf = ldf.loc[ldf[\"patent\"].notnull(), [\"patent\", \"lawyer_id\"]]\n",
    "ldf.to_csv(\"RawData/Cleaned/patent_lawyer.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load new files and get common inventors\n",
    "files = [\"naics_name_common_inv_0726.parq\", \"primclass_common_inv_0726.parq\"]\n",
    "# files = [\"naics_name_common_inv_0726.parq\"]\n",
    "pathdir = \"DataStore/2018-07-P2/Reg0726/\"\n",
    "ldf = pd.read_csv(\"RawData/Cleaned/patent_lawyer.csv\")\n",
    "%time ldf = {n:g[\"lawyer_id\"].tolist() for n,g in ldf[[\"patent\", \"lawyer_id\"]].groupby(\"patent\")}\n",
    "\n",
    "for f in files:\n",
    "    %time mdc = fastparquet.ParquetFile(pathdir+f).to_pandas()\n",
    "    print(f)\n",
    "    print(len(mdc))\n",
    "    \n",
    "    %time l_match = (set(ldf.get(tp, [])).intersection(set(ldf.get(op, []))) for tp, op in zip(mdc[\"tp\"], mdc[\"op\"]))\n",
    "    %time mdc[\"lawyer_match\"] = [len(i) for i in l_match]\n",
    "    %time mdc[\"lawyer_match\"] = mdc[\"lawyer_match\"].apply(lambda x: True if x >= 1 else False)\n",
    "    print(mdc[\"lawyer_match\"].value_counts())\n",
    "    print(len(mdc))\n",
    "    fastparquet.write(pathdir+f, mdc, compression=\"GZIP\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add direct citation indicator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.8 s, sys: 336 ms, total: 3.13 s\n",
      "Wall time: 3.07 s\n",
      "primclass_common_inv_0726.parq\n",
      "1369833\n",
      "CPU times: user 1min 6s, sys: 10.1 s, total: 1min 16s\n",
      "Wall time: 28 s\n",
      "CPU times: user 2min 44s, sys: 4.22 s, total: 2min 48s\n",
      "Wall time: 2min 53s\n",
      "CPU times: user 40.6 ms, sys: 26.1 ms, total: 66.7 ms\n",
      "Wall time: 73.2 ms\n",
      "CPU times: user 5.7 s, sys: 0 ns, total: 5.7 s\n",
      "Wall time: 6.27 s\n",
      "0     1351856\n",
      "1       11156\n",
      "2        2681\n",
      "3        1207\n",
      "4         644\n",
      "5         413\n",
      "6         286\n",
      "7         220\n",
      "8         160\n",
      "9         125\n",
      "11         96\n",
      "10         86\n",
      "12         63\n",
      "13         44\n",
      "15         43\n",
      "14         42\n",
      "17         39\n",
      "19         36\n",
      "18         35\n",
      "20         30\n",
      "Name: num_common_cites, dtype: int64\n",
      "False    1351856\n",
      "True       17977\n",
      "Name: common_cites_match, dtype: int64\n",
      "1369833\n",
      "Index(['tp', 'op', 'tp_gyear', 'tp_inv_msa', 'op_inv_msa', 'op_gyear',\n",
      "       'tp_assignee_id', 'tp_msaname', 'op_assignee_id', 'op_msaname',\n",
      "       'num_common_est_inv', 'common_est_inv', 'num_common_pat_inv',\n",
      "       'common_pat_inv', 'lawyer_match', 'direct_cite', 'num_common_cites',\n",
      "       'common_cites_match'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "cit = dd.read_parquet(\"RawData/Cleaned/cit_0628.parq\")\n",
    "\n",
    "# Load new files and get common inventors\n",
    "# files = [\"naics_name_common_inv_0726.parq\", \"primclass_common_inv_0726.parq\"]\n",
    "files = [\"primclass_common_inv_0726.parq\"]\n",
    "pathdir = \"DataStore/2018-07-P2/Reg0726/\"\n",
    "\n",
    "for f in files:\n",
    "    %time mdc = fastparquet.ParquetFile(pathdir+f).to_pandas()\n",
    "    print(f)\n",
    "    print(len(mdc))\n",
    "    \n",
    "#     # Direct citations\n",
    "#     # Create all False\n",
    "#     mdc[\"direct_cite\"] = False\n",
    "#     # Create zipped pairs\n",
    "#     mdc[\"tp_op\"] = list(zip(mdc[\"tp\"], mdc[\"op\"]))\n",
    "#     # Citations\n",
    "#     c2 = cit[cit[\"cited\"].isin(mdc[\"tp\"])].compute()\n",
    "#     mdc.loc[mdc[\"tp_op\"].isin(list(zip(c2[\"cited\"], c2[\"citing\"]))), \"direct_cite\"] = True\n",
    "#     del(c2)\n",
    "#     print(mdc[\"direct_cite\"].value_counts())\n",
    "#     # Drop pairs\n",
    "#     mdc = mdc.drop(\"tp_op\",1)\n",
    "    \n",
    "    # Number of common citations\n",
    "    # Citations\n",
    "    %time c2 = cit[cit[\"citing\"].isin(mdc[\"tp\"]) | cit[\"citing\"].isin(mdc[\"op\"])].compute()\n",
    "    # Dictionary of citing: cited patents\n",
    "    %time c2 = {n:g[\"cited\"].tolist() for n,g in c2.groupby(\"citing\")}\n",
    "    # Get number of overlapping\n",
    "    %time num_common_cites = (set(c2.get(tp, [])).intersection(set(c2.get(op, []))) for tp, op in zip(mdc[\"tp\"], mdc[\"op\"]))\n",
    "    %time mdc[\"num_common_cites\"] = [len(i) for i in num_common_cites]\n",
    "    # At least one number of common cites\n",
    "    mdc[\"common_cites_match\"] = False\n",
    "    mdc.loc[(mdc[\"num_common_cites\"] >= 1), \"common_cites_match\"] = True\n",
    "    print(mdc[\"num_common_cites\"].value_counts()[:20])\n",
    "    print(mdc[\"common_cites_match\"].value_counts())\n",
    "    print(len(mdc))\n",
    "    print(mdc.columns)\n",
    "    fastparquet.write(pathdir+f, mdc, compression=\"GZIP\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_______________\n",
    "\n",
    "Finish here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Add indicator term\n",
    "\n",
    "# Load new files and get common inventors\n",
    "files = [\"naics_name_common_inv_0726.parq\", \"primclass_common_inv_0726.parq\"]\n",
    "# files = [\"naics_name_common_inv_0726.parq\"]\n",
    "pathdir = \"DataStore/2018-07-P2/Reg0726/\"\n",
    "\n",
    "for f in files:\n",
    "    mdc = fastparquet.ParquetFile(pathdir+f).to_pandas()\n",
    "    mdc[\"common_est_inv\"] = np.nan\n",
    "    mdc.loc[mdc[\"num_common_est_inv\"] >= 1, \"common_est_inv\"] = True\n",
    "    mdc.loc[mdc[\"num_common_est_inv\"] == 0, \"common_est_inv\"] = False\n",
    "    \n",
    "    mdc[\"common_pat_inv\"] = np.nan\n",
    "    mdc.loc[mdc[\"num_common_pat_inv\"] >= 1, \"common_pat_inv\"] = True\n",
    "    mdc.loc[mdc[\"num_common_pat_inv\"] == 0, \"common_pat_inv\"] = False\n",
    "    fastparquet.write(pathdir+f, mdc, compression=\"GZIP\")\n",
    "    del(mdc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load new files and get common inventors\n",
    "# files = [\"naics_name_common_inv_0726.parq\", \"primclass_common_inv_0726.parq\"]\n",
    "files = [\"naics_name_common_inv_0726.parq\"]\n",
    "files = [\"primclass_common_inv_0726.parq\"]\n",
    "pathdir = \"DataStore/2018-07-P2/Reg0726/\"\n",
    "\n",
    "for f in files:\n",
    "    mdc = fastparquet.ParquetFile(pathdir+f).to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    656592\n",
       "1.0    158028\n",
       "Name: common_est_inv, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdc[\"common_est_inv\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    1496604\n",
       "True        1580\n",
       "Name: common_pat_inv, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdc[\"common_pat_inv\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
