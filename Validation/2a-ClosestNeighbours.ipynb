{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/homedir/eco/sfeng/bigdata/python/miniconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "/homedir/eco/sfeng/bigdata/python/miniconda3/lib/python3.6/site-packages/statsmodels/compat/pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.\n",
      "  from pandas.core import datetools\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "import timeit\n",
    "import datetime\n",
    "import time\n",
    "import pprint\n",
    "import itertools\n",
    "import pickle\n",
    "import sklearn\n",
    "import dask\n",
    "import os\n",
    "os.chdir('/mnt/t48/bighomes-active/sfeng/patentdiffusion/')\n",
    "import fastparquet\n",
    "seed = 3\n",
    "import seaborn as sns\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "import collections\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "import statsmodels.iolib.summary2 as summary2\n",
    "import dask\n",
    "import dask.dataframe as dd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Do citations overstate localization?\n",
    "### 1.1 Compare localization rates for lawyers who operate in 1 city vs 1+ cities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = pd.read_pickle(\"DataStore/2018-07-P2/targ_samp_0717.pkl\")\n",
    "# Drop duplicates\n",
    "dup_pats = pd.read_pickle(\"RawData/Cleaned/duplicate_pattext_0712.pkl\").tolist()\n",
    "# Get relevant US Patents\n",
    "ts = ts.loc[~ts[\"tp\"].isin(dup_pats)]\n",
    "\n",
    "ts = ts[[\"tp\", \"tp_primclass\", \"tp_gyear\", \"tp_inv_msa\", \"tp_match_5\", \"tp_match_10\", \"cp_match_5\", \"cp_match_10\"]]\n",
    "\n",
    "# ts = ts[['tp', 'tp_primclass', 'tp_gyear', 'tp_inv_msa', 'tp_match_5',\n",
    "#        'tp_match_10', 'year_group', 'tp_lawyer']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tp</th>\n",
       "      <th>tp_primclass</th>\n",
       "      <th>tp_gyear</th>\n",
       "      <th>tp_inv_msa</th>\n",
       "      <th>tp_match_5</th>\n",
       "      <th>tp_match_10</th>\n",
       "      <th>cp_match_5</th>\n",
       "      <th>cp_match_10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5241648</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1993</td>\n",
       "      <td>San Jose-Sunnyvale-Santa Clara, CA</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.064516</td>\n",
       "      <td>0.151261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6665662</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2003</td>\n",
       "      <td>San Francisco-Oakland-Fremont, CA</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.145833</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5797117</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1998</td>\n",
       "      <td>Los Angeles-Long Beach-Santa Ana, CA</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.025641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>7502777</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2009</td>\n",
       "      <td>San Jose-Sunnyvale-Santa Clara, CA</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>7599939</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2009</td>\n",
       "      <td>San Jose-Sunnyvale-Santa Clara, CA</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>0.103448</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         tp  tp_primclass  tp_gyear                            tp_inv_msa  \\\n",
       "3   5241648           1.0      1993    San Jose-Sunnyvale-Santa Clara, CA   \n",
       "5   6665662           1.0      2003     San Francisco-Oakland-Fremont, CA   \n",
       "9   5797117           1.0      1998  Los Angeles-Long Beach-Santa Ana, CA   \n",
       "11  7502777           1.0      2009    San Jose-Sunnyvale-Santa Clara, CA   \n",
       "15  7599939           1.0      2009    San Jose-Sunnyvale-Santa Clara, CA   \n",
       "\n",
       "    tp_match_5  tp_match_10  cp_match_5  cp_match_10  \n",
       "3     0.200000     0.285714    0.064516     0.151261  \n",
       "5     0.000000     0.145833    0.500000     0.600000  \n",
       "9     0.000000     0.000000    0.000000     0.025641  \n",
       "11    0.000000     0.000000    0.000000     0.000000  \n",
       "15    0.166667     0.250000    0.150000     0.103448  "
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7.08 s, sys: 335 ms, total: 7.42 s\n",
      "Wall time: 6.56 s\n",
      "CPU times: user 2.89 s, sys: 121 ms, total: 3.01 s\n",
      "Wall time: 2.64 s\n",
      "CPU times: user 857 ms, sys: 70.1 ms, total: 927 ms\n",
      "Wall time: 922 ms\n"
     ]
    }
   ],
   "source": [
    "# Limit to lawyers of patents within the sample\n",
    "%time ldf = pd.read_csv(\"RawData/Cleaned/patent_lawyer.csv\")\n",
    "samp_lawyers = ldf.loc[ldf[\"patent\"].isin(ts[\"tp\"]), \"lawyer_id\"].unique()\n",
    "ldf = ldf.loc[ldf[\"lawyer_id\"].isin(samp_lawyers)]\n",
    "\n",
    "# Lawyer for each patent\n",
    "%time l2 = ldf.drop_duplicates(\"patent\")\n",
    "%time l2 = dict(zip(l2[\"patent\"], l2[\"lawyer_id\"]))\n",
    "\n",
    "# Add to patents\n",
    "ts[\"tp_lawyer\"] = ts[\"tp\"].map(l2)\n",
    "del(l2)\n",
    "\n",
    "# Location of each patent\n",
    "pdf = fastparquet.ParquetFile(\"RawData/Cleaned/patent_loc_unique_us_0628.parq\")\\\n",
    ".to_pandas([\"patent\", \"inv_msa\"])\n",
    "\n",
    "# Location of each lawyer's patent\n",
    "ldf[\"inv_msa\"] = ldf[\"patent\"].map(dict(zip(pdf[\"patent\"], pdf[\"inv_msa\"])))\n",
    "\n",
    "# Drop missing locations\n",
    "ldf = ldf.dropna(subset=[\"inv_msa\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 12.7 s, sys: 54.4 ms, total: 12.8 s\n",
      "Wall time: 12.7 s\n",
      "CPU times: user 20.9 ms, sys: 0 ns, total: 20.9 ms\n",
      "Wall time: 20.7 ms\n"
     ]
    }
   ],
   "source": [
    "# Unique locations by lawyer\n",
    "%time lawyer_loc = ldf.groupby('lawyer_id', as_index=False).agg({'inv_msa': 'unique'})\n",
    "# Number of unique cities\n",
    "%time num_lawyer_loc = dict(zip(lawyer_loc[\"lawyer_id\"], [len(i) for i in lawyer_loc[\"inv_msa\"].tolist()]))\n",
    "# Location\n",
    "lawyer_loc = dict(zip(lawyer_loc[\"lawyer_id\"], lawyer_loc[\"inv_msa\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts[\"tp_lawyer_loc\"] = ts[\"tp_lawyer\"].map(lawyer_loc)\n",
    "ts[\"num_tp_lawyer_loc\"] = ts[\"tp_lawyer\"].map(num_lawyer_loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tp_match_10</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_tp_lawyer_loc</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>0.120746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.0</th>\n",
       "      <td>0.119691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.0</th>\n",
       "      <td>0.125865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.0</th>\n",
       "      <td>0.116938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5.0</th>\n",
       "      <td>0.120910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6.0</th>\n",
       "      <td>0.113576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7.0</th>\n",
       "      <td>0.116480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8.0</th>\n",
       "      <td>0.123766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9.0</th>\n",
       "      <td>0.122442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10.0</th>\n",
       "      <td>0.114709</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   tp_match_10\n",
       "num_tp_lawyer_loc             \n",
       "1.0                   0.120746\n",
       "2.0                   0.119691\n",
       "3.0                   0.125865\n",
       "4.0                   0.116938\n",
       "5.0                   0.120910\n",
       "6.0                   0.113576\n",
       "7.0                   0.116480\n",
       "8.0                   0.123766\n",
       "9.0                   0.122442\n",
       "10.0                  0.114709"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts[[\"num_tp_lawyer_loc\", \"tp_match_10\"]].groupby(\"num_tp_lawyer_loc\").mean()[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Doesn't appear that lawyers operating in multiple cities have a huge effect on rates of local citation; i.e. all lawyers cite locally a lot. It's more to do with the control of selecting on the *same* lawyer.\n",
    "\n",
    "#### 1.1.2 How well does citations overlap with lawyer's locations?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 17.4 s, sys: 3.92 s, total: 21.4 s\n",
      "Wall time: 19.3 s\n",
      "CPU times: user 24.2 s, sys: 1.73 s, total: 25.9 s\n",
      "Wall time: 25.9 s\n",
      "CPU times: user 541 ms, sys: 247 ms, total: 788 ms\n",
      "Wall time: 783 ms\n",
      "CPU times: user 31.7 s, sys: 72.5 ms, total: 31.7 s\n",
      "Wall time: 31.7 s\n",
      "CPU times: user 31.2 s, sys: 62.6 ms, total: 31.3 s\n",
      "Wall time: 31.3 s\n"
     ]
    }
   ],
   "source": [
    "all_p = ts[\"tp\"].tolist()\n",
    "\n",
    "%time cit = fastparquet.ParquetFile(\"RawData/Cleaned/cit_0628.parq\").to_pandas()\n",
    "c2 = cit.loc[cit[\"cited\"].isin(all_p)]\n",
    "del(cit)\n",
    "\n",
    "%time asgs = pickle.load(open(\"RawData/Cleaned/patent_assignee_dict_0628.pkl\", \"rb\"))\n",
    "# Remove self-citations\n",
    "%time asg_match = (set(asgs.get(cited, [])).intersection(asgs.get(citing, [])) for cited, citing \\\n",
    "                       in zip(c2[\"cited\"], c2[\"citing\"]))\n",
    "%time asg_match = [len(i) for i in asg_match]\n",
    "del(asgs)\n",
    "\n",
    "c2[\"asg_match\"] = asg_match\n",
    "c2 = c2.loc[c2[\"asg_match\"] == 0]\n",
    "c2 = c2[[\"citing\", \"cited\"]]\n",
    "\n",
    "# Patent locations\n",
    "pdf = fastparquet.ParquetFile(\"RawData/Cleaned/patent_loc_unique_us_0628.parq\")\\\n",
    ".to_pandas([\"patent\", \"inv_msa\"])\n",
    "\n",
    "# Location of each lawyer's patent\n",
    "c2[\"citing_inv_msa\"] = c2[\"citing\"].map(dict(zip(pdf[\"patent\"], pdf[\"inv_msa\"])))\n",
    "c3 = c2.dropna(subset=[\"citing_inv_msa\"])\n",
    "%time c3 = c3.groupby(\"cited\")[\"citing_inv_msa\"].apply(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7.47 s, sys: 203 ms, total: 7.68 s\n",
      "Wall time: 6.82 s\n",
      "CPU times: user 2.98 s, sys: 117 ms, total: 3.1 s\n",
      "Wall time: 2.73 s\n",
      "CPU times: user 873 ms, sys: 50.2 ms, total: 923 ms\n",
      "Wall time: 919 ms\n",
      "CPU times: user 32.4 s, sys: 50.7 ms, total: 32.5 s\n",
      "Wall time: 32.4 s\n"
     ]
    }
   ],
   "source": [
    "# Lawyer for each citing patent\n",
    "# Limit to lawyers of patents within the sample\n",
    "%time ldf = pd.read_csv(\"RawData/Cleaned/patent_lawyer.csv\")\n",
    "samp_lawyers = ldf.loc[ldf[\"patent\"].isin(c2[\"citing\"]), \"lawyer_id\"].unique()\n",
    "ldf = ldf.loc[ldf[\"lawyer_id\"].isin(samp_lawyers)]\n",
    "\n",
    "# Lawyer for each patent\n",
    "%time l2 = ldf.drop_duplicates(\"patent\")\n",
    "%time l2 = dict(zip(l2[\"patent\"], l2[\"lawyer_id\"]))\n",
    "\n",
    "# Add to patents\n",
    "c2[\"citing_lawyer\"] = c2[\"citing\"].map(l2)\n",
    "c4 = c2.dropna(subset=[\"citing_inv_msa\"])\n",
    "%time c4 = c4.groupby(\"cited\")[\"citing_lawyer\"].apply(list)\n",
    "del(ldf, l2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 16s, sys: 29.5 ms, total: 1min 16s\n",
      "Wall time: 1min 16s\n",
      "CPU times: user 979 ms, sys: 922 Âµs, total: 980 ms\n",
      "Wall time: 979 ms\n"
     ]
    }
   ],
   "source": [
    "# Get citation locations\n",
    "ts[\"tp_cit_loc\"] = ts[\"tp\"].map(c3)\n",
    "\n",
    "# Get citing lawyer\n",
    "ts[\"tp_cit_lawyer\"] = ts[\"tp\"].map(c4)\n",
    "del(c3, c4)\n",
    "\n",
    "ts = ts.dropna(subset=[\"tp_cit_loc\", \"tp_lawyer\", \"tp_cit_lawyer\"])\n",
    "\n",
    "def tokenize(l, filter_list):\n",
    "    for item in l:\n",
    "        if item in filter_list:\n",
    "            yield item\n",
    "            \n",
    "# Get lawyer locations\n",
    "%time cit_in_lawyer = [len(list(tokenize(tp_c, l_l))) for tp_c, l_l\\\n",
    "                       in zip(ts[\"tp_cit_loc\"].tolist(), ts[\"tp_lawyer_loc\"].tolist())]\n",
    "ts[\"cit_in_lawyer_loc\"] = cit_in_lawyer\n",
    "ts[\"pct_cit_in_lawyer_loc\"] = ts[\"cit_in_lawyer_loc\"]/ts[\"tp_cit_loc\"].apply(len)\n",
    "\n",
    "# Get lawyer match\n",
    "%time lawyer_match = [len([i for i in j if i == tp_l])/len(j) for j, tp_l in zip(ts[\"tp_cit_lawyer\"].tolist(), ts[\"tp_lawyer\"].tolist())]\n",
    "ts[\"pct_cit_lawyer_match\"] = lawyer_match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pct_cit_in_lawyer_loc</th>\n",
       "      <th>pct_cit_lawyer_match</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>255236.000000</td>\n",
       "      <td>255236.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.475913</td>\n",
       "      <td>0.016455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.387421</td>\n",
       "      <td>0.099520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.045455</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.475000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.886957</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       pct_cit_in_lawyer_loc  pct_cit_lawyer_match\n",
       "count          255236.000000         255236.000000\n",
       "mean                0.475913              0.016455\n",
       "std                 0.387421              0.099520\n",
       "min                 0.000000              0.000000\n",
       "25%                 0.045455              0.000000\n",
       "50%                 0.475000              0.000000\n",
       "75%                 0.886957              0.000000\n",
       "max                 1.000000              1.000000"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts[[\"pct_cit_in_lawyer_loc\", \"pct_cit_lawyer_match\"]].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts.to_pickle(\"DataStore/2018-11/jth_rep_lawyer_loc_1209.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Why localization in citations does not imply localization in innovation\n",
    "\n",
    "### 2.1 Plenty of similar inventions in different cities\n",
    "\n",
    "I found lists of 50 closest neighbours here: https://sfengc7.stern.nyu.edu:8888/notebooks/patentdiffusion/201811/Previous/1-ControlWithSim.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7.41 s, sys: 150 ms, total: 7.56 s\n",
      "Wall time: 7.54 s\n"
     ]
    }
   ],
   "source": [
    "# ts_sp = pd.read_pickle(\"DataStore/2018-11/closest_nbrs_1105.pkl\")\n",
    "\n",
    "# Convert closest pat to integer\n",
    "%time ts_sp[\"closest_pat\"] = ts_sp[\"closest_pat\"].apply(lambda x: x.astype(int))\n",
    "\n",
    "print(len(ts_sp))\n",
    "# Get rid of values with missing closest neighbours\n",
    "ts_sp = ts_sp.loc[ts_sp[\"closest_pat_sim\"].apply(lambda x: x[0].isnull() == False)]\n",
    "ts_sp = ts_sp.reset_index(drop=True)\n",
    "print(len(ts_sp))\n",
    "\n",
    "# Check number of neighbours\n",
    "print(len(ts_sp.loc[3, \"closest_pat\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Only use patents from different assignees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Patents from different assignee\n",
    "asgs = pickle.load(open(\"RawData/Cleaned/patent_assignee_dict_0628.pkl\", \"rb\"))\n",
    "%time tp_asgs = [set(asgs.get(p, [])) for p in ts_sp[\"tp\"]]\n",
    "%time cp_asgs = [np.array([len(set(asgs.get(cp, [])).intersection(tasg)) for cp in j]) for j, tasg in zip(ts_sp[\"closest_pat\"], tp_asgs)]\n",
    "%time cp_asgs_ind = [np.where(j == 0) for j in cp_asgs]\n",
    "del(asgs)\n",
    "\n",
    "cp_cited2 = [x[i] for x,i in zip(ts_sp[\"closest_pat\"], cp_asgs_ind)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_sp[\"closest_pat_df\"] = cp_cited2\n",
    "ts_sp[\"closest_pat_diff\"] = ts_sp[\"closest_pat\"].apply(len) - ts_sp[\"closest_pat_df\"].apply(len)\n",
    "ts_sp[\"closest_pat_diff\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/homedir/eco/sfeng/bigdata/python/miniconda3/lib/python3.6/site-packages/ipykernel_launcher.py:1: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.81 s, sys: 11.8 ms, total: 2.83 s\n",
      "Wall time: 2.82 s\n"
     ]
    }
   ],
   "source": [
    "# Get their locations\n",
    "pdf = fastparquet.ParquetFile(\"RawData/Cleaned/patent_loc_unique_us_0628.parq\").to_pandas([\"patent\", \"inv_msa\"])\n",
    "pdf = dict(zip(pdf[\"patent\"], pdf[\"inv_msa\"]))\n",
    "%time tp_msa = [pdf.get(p, np.nan) for p in ts_sp[\"tp\"]]\n",
    "%time cp_msa = [np.array([pdf.get(cp, np.nan) for cp in j]) for j in ts_sp[\"closest_pat_df\"]]\n",
    "%time cp_msa_match = [len(np.where(j == t)[0]) for j,t in zip(cp_msa, tp_msa)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_sp[\"num_cp_df_msa_match\"] = cp_msa_match\n",
    "ts_sp[\"num_cp_df\"] = ts_sp[\"closest_pat_df\"].apply(lambda x: len(x))\n",
    "ts_sp[\"cp_df_msa_match\"] = ts_sp[\"num_cp_df_msa_match\"]/ts_sp[\"num_cp_df\"]\n",
    "\n",
    "print(len(ts_sp))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_sp.to_pickle(\"DataStore/2018-11/tp_closest_nbrs_1209.pkl\")\n",
    "ts_sp.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.1 Average proportion of nearest neighbours from different firms in the same location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.03854070707450035"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.nanmean(ts_sp[\"cp_df_msa_match\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.2 Random occurence of patents from the same city"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.023703718966184697\n"
     ]
    }
   ],
   "source": [
    "# What's the random occurrence of patents from the same city?\n",
    "# p2 = fastparquet.ParquetFile(\"RawData/Cleaned/patent_loc_unique_us_0628.parq\").to_pandas([\"patent\", \"inv_msa\"])\n",
    "p2[\"inv_msa_2\"] = p2[\"inv_msa\"].sample(frac=1).tolist()\n",
    "p2[\"msa_match\"] = (p2[\"inv_msa\"] == p2[\"inv_msa_2\"])\n",
    "print(np.mean(p2[\"msa_match\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.3 Overlap in citations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.06 s, sys: 1.51 s, total: 3.57 s\n",
      "Wall time: 3.56 s\n",
      "CPU times: user 1min 42s, sys: 173 ms, total: 1min 42s\n",
      "Wall time: 1min 43s\n"
     ]
    }
   ],
   "source": [
    "all_p = [item for sublist in ts_sp[\"closest_pat_df\"].tolist() for item in sublist]\n",
    "all_p = all_p+ts_sp[\"tp\"].tolist()\n",
    "\n",
    "cit = fastparquet.ParquetFile(\"RawData/Cleaned/cit_0628.parq\").to_pandas()\n",
    "c2 = cit.loc[cit[\"citing\"].isin(all_p)]\n",
    "del(cit)\n",
    "\n",
    "asgs = pickle.load(open(\"RawData/Cleaned/patent_assignee_dict_0628.pkl\", \"rb\"))\n",
    "# Remove self-citations\n",
    "%time asg_match = (set(asgs.get(cited, [])).intersection(asgs.get(citing, [])) for cited, citing \\\n",
    "                       in zip(c2[\"cited\"], c2[\"citing\"]))\n",
    "%time asg_match = [len(i) for i in asg_match]\n",
    "del(asgs)\n",
    "\n",
    "c2[\"asg_match\"] = asg_match\n",
    "c2 = c2.loc[c2[\"asg_match\"] == 0]\n",
    "c2 = c2[[\"citing\", \"cited\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/homedir/eco/sfeng/bigdata/python/miniconda3/lib/python3.6/site-packages/numpy/core/fromnumeric.py:2920: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/homedir/eco/sfeng/bigdata/python/miniconda3/lib/python3.6/site-packages/numpy/core/_methods.py:85: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.09 s, sys: 9.55 ms, total: 5.1 s\n",
      "Wall time: 5.2 s\n"
     ]
    }
   ],
   "source": [
    "# Citing patent to cited dictionary\n",
    "# %time c2 = {n:g[\"cited\"].tolist() for n,g in c2.groupby(\"citing\")}\n",
    "\n",
    "# Get pct of common citations\n",
    "# %time tp_cite = [c2.get(tp, []) for tp in ts_sp[\"tp\"]]\n",
    "# %time pct_cite = [[len(set(c2.get(cp, [])).intersection(set(tp_c)))/len(tp_c) if len(tp_c)>0 else np.nan \\\n",
    "#                    for cp in j] for j, tp_c in zip(ts_sp[\"closest_pat_df\"], tp_cite)]\n",
    "del(c2)\n",
    "%time pct_cite = [np.mean(l) for l in pct_cite]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.005023767850486143\n"
     ]
    }
   ],
   "source": [
    "# ts_sp[\"tp_pct_common_cited\"] = pct_cite\n",
    "print(np.nanmean(ts_sp[\"tp_pct_common_cited\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ts_sp.to_pickle(\"DataStore/2018-11/tp_closest_nbrs_1209.pkl\")\n",
    "# ts_sp.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_______\n",
    "## Results tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf = fastparquet.ParquetFile(\"RawData/Cleaned/patent_loc_unique_us_0628.parq\").to_pandas([\"patent\", \"gyear\"])\n",
    "pdf = dict(zip(pdf[\"patent\"], pdf[\"gyear\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = pd.read_pickle(\"DataStore/2018-11/jth_rep_lawyer_loc_1209.pkl\")\n",
    "ts_sp = pd.read_pickle(\"DataStore/2018-11/tp_closest_nbrs_1209.pkl\")\n",
    "ts2 = pd.read_pickle(\"DataStore/2018-07-P2/targ_samp_0717.pkl\")[[\"tp\", \"tp_match_10\"]]\n",
    "ts_sp[\"tp_gyear\"] = ts_sp[\"tp\"].map(pdf)\n",
    "ts_sp[\"tp_match_10\"] = ts_sp[\"tp\"].map(dict(zip(ts2[\"tp\"], ts2[\"tp_match_10\"])))\n",
    "del(ts2)\n",
    "\n",
    "def get_year_group_10(x):\n",
    "    if x in range(1975,1985):\n",
    "        yg = \"1975-85\"\n",
    "    elif x in range(1985,1995):\n",
    "        yg = \"1985-95\"\n",
    "    elif x in range(1995, 2005):\n",
    "        yg = \"1995-05\"\n",
    "    elif x in range(2005,2015):\n",
    "        yg = \"2005-15\"\n",
    "    else:\n",
    "        yg = np.nan\n",
    "    return yg\n",
    "\n",
    "ts_sp[\"year_group\"] = ts_sp[\"tp_gyear\"].apply(get_year_group_10)\n",
    "ts[\"year_group\"] = ts[\"tp_gyear\"].apply(get_year_group_10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ts_sp.to_pickle(\"DataStore/2018-11/tp_closest_nbrs_1209.pkl\")\n",
    "# ts.to_pickle(\"DataStore/2018-11/jth_rep_lawyer_loc_1209.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = pd.read_pickle(\"DataStore/2018-11/jth_rep_lawyer_loc_1209.pkl\")\n",
    "ts_sp = pd.read_pickle(\"DataStore/2018-11/tp_closest_nbrs_1209.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Pct citations in lawyer's cities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = ts[[\"pct_cit_in_lawyer_loc\", \"year_group\"]].groupby(\"year_group\").mean()\\\n",
    ".rename(columns={\"pct_cit_in_lawyer_loc\": \"Pct Cites in Lawyer's MSAs\"})\n",
    "s = ts[[\"pct_cit_in_lawyer_loc\", \"year_group\"]].groupby(\"year_group\").std()\\\n",
    ".rename(columns={\"pct_cit_in_lawyer_loc\": \"S.D.\"})\n",
    "c = ts[[\"pct_cit_in_lawyer_loc\", \"year_group\"]].groupby(\"year_group\").count()\\\n",
    ".rename(columns={\"pct_cit_in_lawyer_loc\": \"$N$\"})\n",
    "m[\"S.D.\"] = s[\"S.D.\"]\n",
    "m = m*100\n",
    "m[\"$N$\"] = c[\"$N$\"]\n",
    "m = np.round(m.T,2)\n",
    "m.loc[\"$N$\"] = m.loc[\"$N$\"].astype(int).astype(str)\n",
    "m = m.drop(\"2005-15\",1)\n",
    "m.columns.name = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lccc}\n",
      "\\toprule\n",
      "{} & 1975-85 & 1985-95 & 1995-05 \\\\\n",
      "\\midrule\n",
      "Pct Cites in Lawyer's MSAs &   32.55 &   39.84 &   47.03 \\\\\n",
      "S.D.                       &   31.93 &   33.52 &    37.4 \\\\\n",
      "$N$                        &   31546 &   54754 &   90243 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(m.to_latex(escape=False, index=True, column_format=\"lccc\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = ts_sp[[\"cp_df_msa_match\", \"year_group\"]].groupby(\"year_group\").mean()\\\n",
    ".rename(columns={\"cp_df_msa_match\": \"Pct Most Similar Pats in Same MSA\"})\n",
    "s = ts_sp[[\"cp_df_msa_match\", \"year_group\"]].groupby(\"year_group\").std()\\\n",
    ".rename(columns={\"cp_df_msa_match\": \"S.D.\"})\n",
    "m1 = ts_sp[[\"tp_match_10\", \"year_group\"]].groupby(\"year_group\").mean()\\\n",
    ".rename(columns={\"tp_match_10\": \"Pct Cites in Same MSA\"})\n",
    "s1 = ts_sp[[\"tp_match_10\", \"year_group\"]].groupby(\"year_group\").std()\\\n",
    ".rename(columns={\"tp_match_10\": \"S.D.\"})\n",
    "\n",
    "c = ts_sp[[\"cp_df_msa_match\", \"year_group\"]].groupby(\"year_group\").count()\\\n",
    ".rename(columns={\"cp_df_msa_match\": \"$N$\"})\n",
    "\n",
    "m = pd.concat([m,s,m1,s1,c], axis=1)\n",
    "m = np.round(m*100,2)\n",
    "m[\"$N$\"] = m[\"$N$\"]/100\n",
    "m[\"$N$\"] = m[\"$N$\"].astype(int).astype(str)\n",
    "m = m.T\n",
    "m.columns.name = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lcccc}\n",
      "\\toprule\n",
      "{} & 1975-85 & 1985-95 & 1995-05 & 2005-15 \\\\\n",
      "\\midrule\n",
      "Pct Most Similar Pats in Same MSA &       3 &    3.22 &    4.02 &    4.41 \\\\\n",
      "S.D.                              &    5.09 &    5.29 &    6.39 &    6.48 \\\\\n",
      "Pct Cites in Same MSA             &    9.16 &    9.72 &   10.96 &   12.99 \\\\\n",
      "S.D.                              &   23.62 &   22.93 &   23.34 &   27.92 \\\\\n",
      "$N$                               &   24124 &   41341 &   69699 &   61273 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(m.to_latex(escape=False, index=True, column_format=\"lcccc\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "m1 = ts_sp[[\"tp_pct_common_cited\", \"year_group\"]].groupby(\"year_group\").mean()\\\n",
    ".rename(columns={\"tp_pct_common_cited\": \"Pct Common Cited\"})\n",
    "s1 = ts_sp[[\"tp_pct_common_cited\", \"year_group\"]].groupby(\"year_group\").std()\\\n",
    ".rename(columns={\"tp_pct_common_cited\": \"S.D.\"})\n",
    "\n",
    "c = ts_sp[[\"tp_pct_common_cited\", \"year_group\"]].groupby(\"year_group\").count()\\\n",
    ".rename(columns={\"tp_pct_common_cited\": \"$N$\"})\n",
    "\n",
    "m = pd.concat([m1,s1,c], axis=1)\n",
    "m = np.round(m*100,2)\n",
    "m[\"$N$\"] = m[\"$N$\"]/100\n",
    "m[\"$N$\"] = m[\"$N$\"].astype(int).astype(str)\n",
    "m = m.T\n",
    "m.columns.name = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lcccc}\n",
      "\\toprule\n",
      "{} & 1975-85 & 1985-95 & 1995-05 & 2005-15 \\\\\n",
      "\\midrule\n",
      "Pct Common Cited &    0.35 &    0.44 &    0.56 &    0.55 \\\\\n",
      "S.D.             &    0.83 &    1.08 &    1.96 &    2.36 \\\\\n",
      "$N$              &   23439 &   40294 &   58529 &   59154 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(m.to_latex(escape=False, index=True, column_format=\"lcccc\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Examples\n",
    "\n",
    "#### 2.1 Examples of control patents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf = fastparquet.ParquetFile(\"RawData/Cleaned/patent_loc_unique_us_0628.parq\").to_pandas([\"patent\", \"title\"])\n",
    "pdf = dict(zip(pdf[\"patent\"], pdf[\"title\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = pd.read_pickle(\"DataStore/2018-07-P2/targ_samp_0717.pkl\")[[\"tp\", \"tp_primclass\", \"tp_gyear\", \"tp_inv_msa\", \n",
    "                                                                \"tp_match_10\", \"cp\", \"cp_match_10\"]]\n",
    "ts1 = pd.read_pickle(\"DataStore/2018-11/closest_nbr_control_1108.pkl\")[[\"tp\", \"closest_pat\",\\\n",
    "                        \"closest_pat_sim\", \"closest_pat_match\"]].rename(columns={\"closest_pat_match\": \"closest_pat_match_10\"})\n",
    "ts2 = pd.read_pickle(\"DataStore/2018-11/jth_rep_lawyers_control_1109.pkl\")[[\"tp\", \"lawyer_cp\", \"lawyer_cp_match_10\"]]\n",
    "ts = ts.merge(ts1, how=\"left\", on=\"tp\")\n",
    "ts = ts.merge(ts2, how=\"left\", on=\"tp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts[\"tp_title\"] = ts[\"tp\"].map(pdf)\n",
    "ts[\"cp_title\"] = ts[\"cp\"].map(pdf)\n",
    "ts[\"closest_pat_title\"] = ts[\"closest_pat\"].map(pdf)\n",
    "ts[\"lawyer_cp_title\"] = ts[\"lawyer_cp\"].map(pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts.to_pickle(\"DataStore/2018-11/jth_rep_all_controls_1209.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tp_title</th>\n",
       "      <th>cp_title</th>\n",
       "      <th>closest_pat_title</th>\n",
       "      <th>lawyer_cp_title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>140952</th>\n",
       "      <td>Reuse of an idle paging slot of a frame in a m...</td>\n",
       "      <td>Enabling AD-HOC data communication over establ...</td>\n",
       "      <td>Platform for serving online content</td>\n",
       "      <td>Combining mobile VPN and internet protocol</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98502</th>\n",
       "      <td>Card reading terminal having protective shield...</td>\n",
       "      <td>Operator work station</td>\n",
       "      <td>Uniport interface for a bar code reading instr...</td>\n",
       "      <td>Method of merchandising cutter bits and displa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76934</th>\n",
       "      <td>System for supporting and adjusting refrigerat...</td>\n",
       "      <td>Table base construction</td>\n",
       "      <td>Horizontal refrigerator</td>\n",
       "      <td>Automatic conduit anchorage device</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64304</th>\n",
       "      <td>Self-cleaning water filtration system and method</td>\n",
       "      <td>Mobile phase gradient generation microfluidic ...</td>\n",
       "      <td>System for processing polluted water</td>\n",
       "      <td>Nanostructured separation and analysis devices...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28122</th>\n",
       "      <td>Saw table with compound movement of saw</td>\n",
       "      <td>Bakery product slicing machine</td>\n",
       "      <td>Apparatus for cutting interlocking joints</td>\n",
       "      <td>Rotary cutting dies</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155957</th>\n",
       "      <td>Efficient implementation of block-based transf...</td>\n",
       "      <td>Run length coding and decoding</td>\n",
       "      <td>Apparatus and method for selective attribute d...</td>\n",
       "      <td>Nosologic system of diagnosis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268099</th>\n",
       "      <td>Apparatus and method for selectively accessing...</td>\n",
       "      <td>Limiting concurrent modification and execution...</td>\n",
       "      <td>Cache-line reuse-buffer</td>\n",
       "      <td>Pipelined microprocessor, apparatus, and metho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189072</th>\n",
       "      <td>Purification of polymorphic components of comp...</td>\n",
       "      <td>Liquid single reagent for air enzyme complemen...</td>\n",
       "      <td>Method of preparing and applying single strand...</td>\n",
       "      <td>Flow cytometry apparatus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134126</th>\n",
       "      <td>Vehicle inverter assembly with cooling channels</td>\n",
       "      <td>CFP mechanical platform</td>\n",
       "      <td>Motor drive architecture for high frequency AC...</td>\n",
       "      <td>Methods and apparatus for an improved PCB asse...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203795</th>\n",
       "      <td>Voice quality on a communication link based on...</td>\n",
       "      <td>Provisioning of wireless private access subscr...</td>\n",
       "      <td>Method and apparatus for providing and obtaini...</td>\n",
       "      <td>Communications handoff using an adaptive antenna</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158951</th>\n",
       "      <td>Opto-electronic multi-chip modules using imagi...</td>\n",
       "      <td>Focused ion-beam fabrication of fiber probes f...</td>\n",
       "      <td>Dopant diffusion blocking for optoelectronic d...</td>\n",
       "      <td>Use of sol-gel as inorganic adhesive for high ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8420</th>\n",
       "      <td>Method for modifying electrical performance ch...</td>\n",
       "      <td>Method of forming flexible metal leads on inte...</td>\n",
       "      <td>Board edge connector</td>\n",
       "      <td>Generator rotor slot wedge assembly and disass...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61434</th>\n",
       "      <td>Horizontal FCC feed injection process</td>\n",
       "      <td>Asphalt compositions containing solvent deasph...</td>\n",
       "      <td>Theft prevention device</td>\n",
       "      <td>Reforming of hydrocarbons utilizing a trimetal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77984</th>\n",
       "      <td>Method for measuring film thickness on wood pa...</td>\n",
       "      <td>Dark field infrared telescope</td>\n",
       "      <td>Electrical resistance coating for steel</td>\n",
       "      <td>Apparatus for infrared imaging inspections</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102464</th>\n",
       "      <td>Multiprobe eddy current flaw detection device ...</td>\n",
       "      <td>Closed loop for automatic substitution of a si...</td>\n",
       "      <td>Bi-axial probe</td>\n",
       "      <td>Inductive coupling position sensor method and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183745</th>\n",
       "      <td>Multiple step fuel cell seal</td>\n",
       "      <td>Methods and reagents for enhancing the cycling...</td>\n",
       "      <td>Electrically conductive seal for fuel cell ele...</td>\n",
       "      <td>Stable high conductivity functionally gradient...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205930</th>\n",
       "      <td>Method and apparatus for network controller se...</td>\n",
       "      <td>Interworking gateway for mobile nodes</td>\n",
       "      <td>Method and system for providing network services</td>\n",
       "      <td>Method and system for device positioning utili...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85088</th>\n",
       "      <td>Layered chip package with heat sink</td>\n",
       "      <td>Compliant spring interposer for wafer level th...</td>\n",
       "      <td>Chip assembly with chip-scale packaging</td>\n",
       "      <td>Substrates having increased thermal conductivi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42316</th>\n",
       "      <td>Water tank and gated dump valve for fire trucks</td>\n",
       "      <td>Modular valve service box</td>\n",
       "      <td>Mobile storage tank</td>\n",
       "      <td>Water wheel for pumping chemical treatment int...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172350</th>\n",
       "      <td>Methods for treating non-suturable wounds by u...</td>\n",
       "      <td>Therapy of cancer by insect cells containing r...</td>\n",
       "      <td>Integrin receptor antagonists</td>\n",
       "      <td>Compositions for use in embolizing blood vessels</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 tp_title  \\\n",
       "140952  Reuse of an idle paging slot of a frame in a m...   \n",
       "98502   Card reading terminal having protective shield...   \n",
       "76934   System for supporting and adjusting refrigerat...   \n",
       "64304    Self-cleaning water filtration system and method   \n",
       "28122             Saw table with compound movement of saw   \n",
       "155957  Efficient implementation of block-based transf...   \n",
       "268099  Apparatus and method for selectively accessing...   \n",
       "189072  Purification of polymorphic components of comp...   \n",
       "134126    Vehicle inverter assembly with cooling channels   \n",
       "203795  Voice quality on a communication link based on...   \n",
       "158951  Opto-electronic multi-chip modules using imagi...   \n",
       "8420    Method for modifying electrical performance ch...   \n",
       "61434               Horizontal FCC feed injection process   \n",
       "77984   Method for measuring film thickness on wood pa...   \n",
       "102464  Multiprobe eddy current flaw detection device ...   \n",
       "183745                       Multiple step fuel cell seal   \n",
       "205930  Method and apparatus for network controller se...   \n",
       "85088                 Layered chip package with heat sink   \n",
       "42316     Water tank and gated dump valve for fire trucks   \n",
       "172350  Methods for treating non-suturable wounds by u...   \n",
       "\n",
       "                                                 cp_title  \\\n",
       "140952  Enabling AD-HOC data communication over establ...   \n",
       "98502                               Operator work station   \n",
       "76934                             Table base construction   \n",
       "64304   Mobile phase gradient generation microfluidic ...   \n",
       "28122                      Bakery product slicing machine   \n",
       "155957                     Run length coding and decoding   \n",
       "268099  Limiting concurrent modification and execution...   \n",
       "189072  Liquid single reagent for air enzyme complemen...   \n",
       "134126                            CFP mechanical platform   \n",
       "203795  Provisioning of wireless private access subscr...   \n",
       "158951  Focused ion-beam fabrication of fiber probes f...   \n",
       "8420    Method of forming flexible metal leads on inte...   \n",
       "61434   Asphalt compositions containing solvent deasph...   \n",
       "77984                       Dark field infrared telescope   \n",
       "102464  Closed loop for automatic substitution of a si...   \n",
       "183745  Methods and reagents for enhancing the cycling...   \n",
       "205930              Interworking gateway for mobile nodes   \n",
       "85088   Compliant spring interposer for wafer level th...   \n",
       "42316                           Modular valve service box   \n",
       "172350  Therapy of cancer by insect cells containing r...   \n",
       "\n",
       "                                        closest_pat_title  \\\n",
       "140952                Platform for serving online content   \n",
       "98502   Uniport interface for a bar code reading instr...   \n",
       "76934                             Horizontal refrigerator   \n",
       "64304                System for processing polluted water   \n",
       "28122           Apparatus for cutting interlocking joints   \n",
       "155957  Apparatus and method for selective attribute d...   \n",
       "268099                            Cache-line reuse-buffer   \n",
       "189072  Method of preparing and applying single strand...   \n",
       "134126  Motor drive architecture for high frequency AC...   \n",
       "203795  Method and apparatus for providing and obtaini...   \n",
       "158951  Dopant diffusion blocking for optoelectronic d...   \n",
       "8420                                 Board edge connector   \n",
       "61434                             Theft prevention device   \n",
       "77984             Electrical resistance coating for steel   \n",
       "102464                                     Bi-axial probe   \n",
       "183745  Electrically conductive seal for fuel cell ele...   \n",
       "205930   Method and system for providing network services   \n",
       "85088             Chip assembly with chip-scale packaging   \n",
       "42316                                 Mobile storage tank   \n",
       "172350                      Integrin receptor antagonists   \n",
       "\n",
       "                                          lawyer_cp_title  \n",
       "140952         Combining mobile VPN and internet protocol  \n",
       "98502   Method of merchandising cutter bits and displa...  \n",
       "76934                  Automatic conduit anchorage device  \n",
       "64304   Nanostructured separation and analysis devices...  \n",
       "28122                                 Rotary cutting dies  \n",
       "155957                      Nosologic system of diagnosis  \n",
       "268099  Pipelined microprocessor, apparatus, and metho...  \n",
       "189072                           Flow cytometry apparatus  \n",
       "134126  Methods and apparatus for an improved PCB asse...  \n",
       "203795   Communications handoff using an adaptive antenna  \n",
       "158951  Use of sol-gel as inorganic adhesive for high ...  \n",
       "8420    Generator rotor slot wedge assembly and disass...  \n",
       "61434   Reforming of hydrocarbons utilizing a trimetal...  \n",
       "77984          Apparatus for infrared imaging inspections  \n",
       "102464  Inductive coupling position sensor method and ...  \n",
       "183745  Stable high conductivity functionally gradient...  \n",
       "205930  Method and system for device positioning utili...  \n",
       "85088   Substrates having increased thermal conductivi...  \n",
       "42316   Water wheel for pumping chemical treatment int...  \n",
       "172350   Compositions for use in embolizing blood vessels  "
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts2 = ts.dropna(subset=[\"tp_title\",\"cp_title\", \"closest_pat_title\", \"lawyer_cp_title\"])[[\"tp_title\",\"cp_title\", \"closest_pat_title\", \"lawyer_cp_title\"]]\n",
    "ts2.sample(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(5265951,\n",
       "  'Card reading terminal having protective shield for input port thereof'),\n",
       " (5265952, 'Operator work station'),\n",
       " (5233169.0, 'Uniport interface for a bar code reading instrument'),\n",
       " (5443310.0, 'Method of merchandising cutter bits and display case therefor')]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tp              5265951\n",
      "tp_primclass        312\n",
      "Name: 98502, dtype: object\n"
     ]
    }
   ],
   "source": [
    "i = 98502\n",
    "display(list(zip(ts.loc[i, [\"tp\", \"cp\", \"closest_pat\", \"lawyer_cp\"]].tolist(), ts2.loc[i].tolist())))\n",
    "print(ts.loc[i, [\"tp\", \"tp_primclass\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 Examples of citations in lawyer's MSAs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts2 = pd.read_pickle(\"DataStore/2018-11/jth_rep_lawyer_loc_1209.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tp</th>\n",
       "      <th>tp_primclass</th>\n",
       "      <th>tp_gyear</th>\n",
       "      <th>tp_inv_msa</th>\n",
       "      <th>tp_match_5</th>\n",
       "      <th>tp_match_10</th>\n",
       "      <th>cp_match_5</th>\n",
       "      <th>cp_match_10</th>\n",
       "      <th>tp_lawyer</th>\n",
       "      <th>num_tp_lawyer_loc</th>\n",
       "      <th>tp_lawyer_loc</th>\n",
       "      <th>tp_cit_loc</th>\n",
       "      <th>cit_in_lawyer_loc</th>\n",
       "      <th>pct_cit_in_lawyer_loc</th>\n",
       "      <th>tp_cit_lawyer</th>\n",
       "      <th>pct_cit_lawyer_match</th>\n",
       "      <th>year_group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1109778</th>\n",
       "      <td>4656580</td>\n",
       "      <td>703.0</td>\n",
       "      <td>1987</td>\n",
       "      <td>Kingston, NY</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>223416f11e9a916c06f8cf089d87047c</td>\n",
       "      <td>70.0</td>\n",
       "      <td>[Norfolk, NE, Jena, LA, Miles City, MT, Hartfo...</td>\n",
       "      <td>[San Jose-Sunnyvale-Santa Clara, CA, San Jose-...</td>\n",
       "      <td>57</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>[nan, f83afa9c8dc187c3513e6ccca52b8c03, ef844d...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1985-95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97509</th>\n",
       "      <td>4955204</td>\n",
       "      <td>62.0</td>\n",
       "      <td>1990</td>\n",
       "      <td>San Francisco-Oakland-Fremont, CA</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5049a9bcae438751676d30baf8dade89</td>\n",
       "      <td>207.0</td>\n",
       "      <td>[San Jose-Sunnyvale-Santa Clara, CA, Carmel-by...</td>\n",
       "      <td>[Seattle-Tacoma-Bellevue, WA, Seattle-Tacoma-B...</td>\n",
       "      <td>17</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>[5e2531ea3c81405026098b8ea02583cb, 5e2531ea3c8...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1985-95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26571</th>\n",
       "      <td>4367565</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1983</td>\n",
       "      <td>Reno-Sparks, NV</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7332d3b5c7f04bd7a5e903839fc5b5a1</td>\n",
       "      <td>179.0</td>\n",
       "      <td>[Missoula, MT, Denver-Aurora-Broomfield, CO, S...</td>\n",
       "      <td>[Akron, OH, Grand Rapids-Wyoming, MI, Reno-Spa...</td>\n",
       "      <td>10</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>[nan, b0aef50cbb791f78831d1a68abaa4ed3, 7332d3...</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>1975-85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>651141</th>\n",
       "      <td>5623492</td>\n",
       "      <td>370.0</td>\n",
       "      <td>1997</td>\n",
       "      <td>Boulder, CO</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>5dd57b5aa65ebeedd3178a30b2213489</td>\n",
       "      <td>119.0</td>\n",
       "      <td>[Toledo, OH, Woodville, OH, Detroit-Warren-Liv...</td>\n",
       "      <td>[San Jose-Sunnyvale-Santa Clara, CA, Minneapol...</td>\n",
       "      <td>112</td>\n",
       "      <td>0.903226</td>\n",
       "      <td>[015d4a8c5fe3f874cd569d3845d40070, 613e63765b4...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1995-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1174800</th>\n",
       "      <td>6230266</td>\n",
       "      <td>713.0</td>\n",
       "      <td>2001</td>\n",
       "      <td>Boston-Cambridge-Quincy, MA-NH</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.013158</td>\n",
       "      <td>31e4ab159dc0d2e08c0189ecda77af16</td>\n",
       "      <td>117.0</td>\n",
       "      <td>[Barnstable Town, MA, Boston-Cambridge-Quincy,...</td>\n",
       "      <td>[Riverside-San Bernardino-Ontario, CA, San Die...</td>\n",
       "      <td>62</td>\n",
       "      <td>0.953846</td>\n",
       "      <td>[038e71433ed6a2952d8325db21106917, 038e71433ed...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1995-05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              tp  tp_primclass  tp_gyear                         tp_inv_msa  \\\n",
       "1109778  4656580         703.0      1987                       Kingston, NY   \n",
       "97509    4955204          62.0      1990  San Francisco-Oakland-Fremont, CA   \n",
       "26571    4367565          15.0      1983                    Reno-Sparks, NV   \n",
       "651141   5623492         370.0      1997                        Boulder, CO   \n",
       "1174800  6230266         713.0      2001     Boston-Cambridge-Quincy, MA-NH   \n",
       "\n",
       "         tp_match_5  tp_match_10  cp_match_5  cp_match_10  \\\n",
       "1109778         0.0          0.0         0.0     0.000000   \n",
       "97509           0.0          0.0         NaN     0.000000   \n",
       "26571           NaN          0.0         0.0     0.000000   \n",
       "651141          0.0          0.0         0.0     0.125000   \n",
       "1174800         0.0          0.0         0.0     0.013158   \n",
       "\n",
       "                                tp_lawyer  num_tp_lawyer_loc  \\\n",
       "1109778  223416f11e9a916c06f8cf089d87047c               70.0   \n",
       "97509    5049a9bcae438751676d30baf8dade89              207.0   \n",
       "26571    7332d3b5c7f04bd7a5e903839fc5b5a1              179.0   \n",
       "651141   5dd57b5aa65ebeedd3178a30b2213489              119.0   \n",
       "1174800  31e4ab159dc0d2e08c0189ecda77af16              117.0   \n",
       "\n",
       "                                             tp_lawyer_loc  \\\n",
       "1109778  [Norfolk, NE, Jena, LA, Miles City, MT, Hartfo...   \n",
       "97509    [San Jose-Sunnyvale-Santa Clara, CA, Carmel-by...   \n",
       "26571    [Missoula, MT, Denver-Aurora-Broomfield, CO, S...   \n",
       "651141   [Toledo, OH, Woodville, OH, Detroit-Warren-Liv...   \n",
       "1174800  [Barnstable Town, MA, Boston-Cambridge-Quincy,...   \n",
       "\n",
       "                                                tp_cit_loc  cit_in_lawyer_loc  \\\n",
       "1109778  [San Jose-Sunnyvale-Santa Clara, CA, San Jose-...                 57   \n",
       "97509    [Seattle-Tacoma-Bellevue, WA, Seattle-Tacoma-B...                 17   \n",
       "26571    [Akron, OH, Grand Rapids-Wyoming, MI, Reno-Spa...                 10   \n",
       "651141   [San Jose-Sunnyvale-Santa Clara, CA, Minneapol...                112   \n",
       "1174800  [Riverside-San Bernardino-Ontario, CA, San Die...                 62   \n",
       "\n",
       "         pct_cit_in_lawyer_loc  \\\n",
       "1109778               0.863636   \n",
       "97509                 0.944444   \n",
       "26571                 0.833333   \n",
       "651141                0.903226   \n",
       "1174800               0.953846   \n",
       "\n",
       "                                             tp_cit_lawyer  \\\n",
       "1109778  [nan, f83afa9c8dc187c3513e6ccca52b8c03, ef844d...   \n",
       "97509    [5e2531ea3c81405026098b8ea02583cb, 5e2531ea3c8...   \n",
       "26571    [nan, b0aef50cbb791f78831d1a68abaa4ed3, 7332d3...   \n",
       "651141   [015d4a8c5fe3f874cd569d3845d40070, 613e63765b4...   \n",
       "1174800  [038e71433ed6a2952d8325db21106917, 038e71433ed...   \n",
       "\n",
       "         pct_cit_lawyer_match year_group  \n",
       "1109778              0.000000    1985-95  \n",
       "97509                0.000000    1985-95  \n",
       "26571                0.083333    1975-85  \n",
       "651141               0.000000    1995-05  \n",
       "1174800              0.000000    1995-05  "
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts2.loc[ts2[\"pct_cit_in_lawyer_loc\"] >= 0.7].sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array(['Barnstable Town, MA', 'Boston-Cambridge-Quincy, MA-NH',\n",
       "        'Jacksonville, FL', 'Worcester, MA',\n",
       "        'Portland-South Portland-Biddeford, ME', 'Provo-Orem, UT',\n",
       "        'Tucson, AZ', 'Contoocook, NH',\n",
       "        'San Jose-Sunnyvale-Santa Clara, CA', 'West Barnstable, MA',\n",
       "        'New York-Northern New Jersey-Long Island, NY-NJ-PA',\n",
       "        'San Francisco-Oakland-Fremont, CA',\n",
       "        'Providence-New Bedford-Fall River, RI-MA', 'Royalston, MA',\n",
       "        'Revere, MA', 'New London, NH', 'Alum Bank, PA',\n",
       "        'Davenport-Moline-Rock Island, IA-IL', 'Golden Beach, FL',\n",
       "        'Manchester-Nashua, NH', 'Orlando-Kissimmee-Sanford, FL',\n",
       "        'Parkersburg-Marietta-Vienna, WV-OH', 'Raleigh-Cary, NC',\n",
       "        'Blue Hill, ME', 'Riverside-San Bernardino-Ontario, CA',\n",
       "        'Pittsburgh, PA', 'Los Angeles-Long Beach-Santa Ana, CA',\n",
       "        'Las Cruces, NM', 'Seattle-Tacoma-Bellevue, WA',\n",
       "        'East Hampstead, NH', 'Phoenix-Mesa-Glendale, AZ',\n",
       "        'Chicago-Joliet-Naperville, IL-IN-WI',\n",
       "        'Dallas-Fort Worth-Arlington, TX', 'Salt Lake City, UT',\n",
       "        'Bedford, PA', 'Minneapolis-St. Paul-Bloomington, MN-WI',\n",
       "        'Oakham, MA', 'Durham-Chapel Hill, NC',\n",
       "        'Austin-Round Rock-San Marcos, TX', 'Mont Vernon, NH',\n",
       "        'Baltimore-Towson, MD', 'Cumberland Foreside, ME',\n",
       "        'Sacramento--Arden-Arcade--Roseville, CA',\n",
       "        'Oxnard-Thousand Oaks-Ventura, CA', 'Vienna, WV',\n",
       "        'Peaks Island, ME', 'Poughkeepsie-Newburgh-Middletown, NY',\n",
       "        'St. Louis, MO-IL', 'Albany-Schenectady-Troy, NY',\n",
       "        'Cincinnati-Middletown, OH-KY-IN', 'Old Orchard Beach, ME',\n",
       "        'Stryker, OH', 'Cape Elizabeth, ME', 'Binghamton, NY',\n",
       "        'San Diego-Carlsbad-San Marcos, CA', 'North Yarmouth, ME',\n",
       "        'Springfield, MA', 'Cumberland Center, ME',\n",
       "        'Cleveland-Elyria-Mentor, OH', 'Penn Valley, CA',\n",
       "        'Harrisville, NH', 'Lyman, ME', 'Ann Arbor, MI',\n",
       "        'Santa Cruz-Watsonville, CA', 'Falmouth Foreside, ME',\n",
       "        'Boulder, CO', 'Greeley, CO', 'Brownfield, ME',\n",
       "        'Colorado Springs, CO', 'Madison, WI', 'Las Vegas-Paradise, NV',\n",
       "        'Fort Collins-Loveland, CO', 'Ira, VT', 'Dunstable, MA',\n",
       "        'Freeland, WA', 'Lewiston-Auburn, ME',\n",
       "        'Atlanta-Sandy Springs-Marietta, GA',\n",
       "        'New Orleans-Metairie-Kenner, LA', 'Rochester, VT',\n",
       "        'Belleville, MO', 'Blacksburg-Christiansburg-Radford, VA',\n",
       "        'Watertown, CT', 'Bridgeport-Stamford-Norwalk, CT', 'Monument, CO',\n",
       "        'Honolulu, HI', 'Detroit-Warren-Livonia, MI',\n",
       "        'Philadelphia-Camden-Wilmington, PA-NJ-DE-MD', 'Bridgewater, NH',\n",
       "        'Louisville/Jefferson County, KY-IN', 'Boise City-Nampa, ID',\n",
       "        'Oakville, CT', 'Bethlehem, CT',\n",
       "        'Hartford-West Hartford-East Hartford, CT', 'Freedom, PA',\n",
       "        'Elma, WA', 'Harford, NY', 'Palm Bay-Melbourne-Titusville, FL',\n",
       "        'Lyndeborough, NH', 'Huntsville, AL', 'Groveland, CA',\n",
       "        'Indianapolis-Carmel, IN', 'Ithaca, NY',\n",
       "        'North Port-Bradenton-Sarasota, FL', 'Southwest Harbor, ME',\n",
       "        'Columbus, OH', 'Houston-Sugar Land-Baytown, TX',\n",
       "        'East Sandwich, MA', 'Cummaquid, MA', 'Ocean City, NJ',\n",
       "        'Richboro, PA', 'Lexington-Fayette, KY', 'Richford, NY',\n",
       "        'Glenmoore, PA', 'Miami-Fort Lauderdale-Pompano Beach, FL',\n",
       "        'Charlottesville, VA',\n",
       "        'Washington-Arlington-Alexandria, DC-VA-MD-WV', 'Richmond, VA'],\n",
       "       dtype=object),\n",
       " ['Riverside-San Bernardino-Ontario, CA',\n",
       "  'San Diego-Carlsbad-San Marcos, CA',\n",
       "  'San Diego-Carlsbad-San Marcos, CA',\n",
       "  'San Diego-Carlsbad-San Marcos, CA',\n",
       "  'San Diego-Carlsbad-San Marcos, CA',\n",
       "  'San Diego-Carlsbad-San Marcos, CA',\n",
       "  'San Diego-Carlsbad-San Marcos, CA',\n",
       "  'San Diego-Carlsbad-San Marcos, CA',\n",
       "  'San Diego-Carlsbad-San Marcos, CA',\n",
       "  'San Diego-Carlsbad-San Marcos, CA',\n",
       "  'New York-Northern New Jersey-Long Island, NY-NJ-PA',\n",
       "  'San Diego-Carlsbad-San Marcos, CA',\n",
       "  'Seattle-Tacoma-Bellevue, WA',\n",
       "  'San Diego-Carlsbad-San Marcos, CA',\n",
       "  'Austin-Round Rock-San Marcos, TX',\n",
       "  'San Diego-Carlsbad-San Marcos, CA',\n",
       "  'Los Angeles-Long Beach-Santa Ana, CA',\n",
       "  'New York-Northern New Jersey-Long Island, NY-NJ-PA',\n",
       "  'Washington-Arlington-Alexandria, DC-VA-MD-WV',\n",
       "  'San Diego-Carlsbad-San Marcos, CA',\n",
       "  'San Diego-Carlsbad-San Marcos, CA',\n",
       "  'Riverside-San Bernardino-Ontario, CA',\n",
       "  'San Diego-Carlsbad-San Marcos, CA',\n",
       "  'San Diego-Carlsbad-San Marcos, CA',\n",
       "  'San Diego-Carlsbad-San Marcos, CA',\n",
       "  'San Diego-Carlsbad-San Marcos, CA',\n",
       "  'San Diego-Carlsbad-San Marcos, CA',\n",
       "  'Seattle-Tacoma-Bellevue, WA',\n",
       "  'San Diego-Carlsbad-San Marcos, CA',\n",
       "  'San Diego-Carlsbad-San Marcos, CA',\n",
       "  'San Diego-Carlsbad-San Marcos, CA',\n",
       "  'Seattle-Tacoma-Bellevue, WA',\n",
       "  'Boston-Cambridge-Quincy, MA-NH',\n",
       "  'San Diego-Carlsbad-San Marcos, CA',\n",
       "  'New Orleans-Metairie-Kenner, LA',\n",
       "  'San Diego-Carlsbad-San Marcos, CA',\n",
       "  'San Diego-Carlsbad-San Marcos, CA',\n",
       "  'San Diego-Carlsbad-San Marcos, CA',\n",
       "  'San Diego-Carlsbad-San Marcos, CA',\n",
       "  'San Diego-Carlsbad-San Marcos, CA',\n",
       "  'Seattle-Tacoma-Bellevue, WA',\n",
       "  'San Diego-Carlsbad-San Marcos, CA',\n",
       "  'San Diego-Carlsbad-San Marcos, CA',\n",
       "  'Bremerton-Silverdale, WA',\n",
       "  'Seattle-Tacoma-Bellevue, WA',\n",
       "  'Washington-Arlington-Alexandria, DC-VA-MD-WV',\n",
       "  'San Diego-Carlsbad-San Marcos, CA',\n",
       "  'San Diego-Carlsbad-San Marcos, CA',\n",
       "  'Danville, PA',\n",
       "  'San Diego-Carlsbad-San Marcos, CA',\n",
       "  'Lansing-East Lansing, MI',\n",
       "  'San Diego-Carlsbad-San Marcos, CA',\n",
       "  'San Diego-Carlsbad-San Marcos, CA',\n",
       "  'San Diego-Carlsbad-San Marcos, CA',\n",
       "  'Boston-Cambridge-Quincy, MA-NH',\n",
       "  'San Diego-Carlsbad-San Marcos, CA',\n",
       "  'San Diego-Carlsbad-San Marcos, CA',\n",
       "  'San Diego-Carlsbad-San Marcos, CA',\n",
       "  'Seattle-Tacoma-Bellevue, WA',\n",
       "  'Riverside-San Bernardino-Ontario, CA',\n",
       "  'San Diego-Carlsbad-San Marcos, CA',\n",
       "  'San Diego-Carlsbad-San Marcos, CA',\n",
       "  'San Diego-Carlsbad-San Marcos, CA',\n",
       "  'San Diego-Carlsbad-San Marcos, CA',\n",
       "  'San Diego-Carlsbad-San Marcos, CA']]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(ts2.loc[1174800, [\"tp_lawyer_loc\", \"tp_cit_loc\"]].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
