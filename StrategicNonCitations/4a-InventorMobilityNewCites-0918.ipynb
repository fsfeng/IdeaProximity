{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "import timeit\n",
    "import datetime\n",
    "import time\n",
    "import pprint\n",
    "import itertools\n",
    "import pickle\n",
    "import sklearn\n",
    "import dask\n",
    "import os\n",
    "os.chdir('/mnt/t48/bighomes-active/sfeng/patentdiffusion/')\n",
    "import fastparquet\n",
    "seed = 3\n",
    "import seaborn as sns\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "import dask\n",
    "import dask.dataframe as dd\n",
    "import dask.array as da\n",
    "# Percentiles\n",
    "from scipy.stats import percentileofscore\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For sample generation, see: https://sfengc7.stern.nyu.edu:8888/notebooks/patentdiffusion/201808Results/StrategicNonCitations/Previous/1d-InventorMobilityNewCitations-0911.ipynb\n",
    "\n",
    "### Alternatively: Find control patent for each post-move citation\n",
    "- Find new firms that cite prior patent post-move\n",
    "- For each post-move citation at second MSA to inventor's prior move patent, find patent in same primary class that does not cite the patent granted prior to year of  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "yv = \"appyear\"\n",
    "c2 = pd.read_pickle(\"DataStore/2018-08/inv_move_cites_0912.pkl\")\n",
    "ip = pd.read_pickle(\"DataStore/2018-08/inv_move_pats_0912.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/homedir/eco/sfeng/bigdata/python/miniconda3/lib/python3.6/site-packages/ipykernel_launcher.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "# Use unique assignees\n",
    "c2 = c2.drop([\"cited_asg\", \"citing_asg\"],1)\n",
    "asgs = fastparquet.ParquetFile(\"RawData/Cleaned/patent_assignees_unique_0628.parq\").to_pandas([\"patent\", \"assignee_id\"])\n",
    "pdf = fastparquet.ParquetFile(\"RawData/Cleaned/patent_loc_unique_us_0628.parq\")\\\n",
    ".to_pandas([\"patent\", \"primclass\", \"appyear\"])\n",
    "pdf = pdf.merge(asgs, how = \"left\", on = \"patent\")\n",
    "\n",
    "c2 = c2.merge(asgs, how=\"left\", left_on=\"citing\", right_on=\"patent\").rename(columns={\"assignee_id\": \"citing_asg\"}).drop(\"patent\",1)\n",
    "c2 = c2.merge(asgs, how=\"left\", left_on=\"cited\", right_on=\"patent\").rename(columns={\"assignee_id\": \"cited_asg\"}).drop(\"patent\",1)\n",
    "del(asgs)\n",
    "\n",
    "# New firms that cite prior patent post move\n",
    "a1 = c2.loc[(c2[\"citing_appyear\"] < c2[\"sec_fyear\"]), \"citing_asg\"].tolist()\n",
    "a2 = c2.loc[(c2[\"citing_appyear\"] >= c2[\"sec_fyear\"]), \"citing_asg\"].tolist()\n",
    "new_cite_asgs = list(set(a2).difference(set(a1)))\n",
    "\n",
    "# New cites\n",
    "c3 = c2.loc[(c2[\"citing_appyear\"] >= c2[\"sec_fyear\"]) & c2[\"citing_asg\"].isin(new_cite_asgs)]\n",
    "\n",
    "# Merge new citing patents with pdf\n",
    "c3[\"citing_primclass\"] = c3[\"citing\"].map(dict(zip(pdf[\"patent\"], pdf[\"primclass\"])))\n",
    "del(c2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1975\n",
      "2018-09-18 18:12:51.280341\n",
      "1976\n",
      "2018-09-18 18:12:51.760796\n",
      "1977\n",
      "2018-09-18 18:12:52.432847\n",
      "1978\n",
      "2018-09-18 18:12:53.267608\n",
      "1979\n",
      "2018-09-18 18:12:54.342849\n",
      "1980\n",
      "2018-09-18 18:12:55.835915\n",
      "1981\n",
      "2018-09-18 18:12:57.041474\n",
      "1982\n",
      "2018-09-18 18:12:58.306479\n",
      "1983\n",
      "2018-09-18 18:12:59.740788\n",
      "1984\n",
      "2018-09-18 18:13:01.185551\n",
      "1985\n",
      "2018-09-18 18:13:02.689110\n",
      "1986\n",
      "2018-09-18 18:13:04.221915\n",
      "1987\n",
      "2018-09-18 18:13:05.832788\n",
      "1988\n",
      "2018-09-18 18:13:07.542305\n",
      "1989\n",
      "2018-09-18 18:13:09.801002\n",
      "1990\n",
      "2018-09-18 18:13:13.006353\n",
      "1991\n",
      "2018-09-18 18:13:15.333865\n",
      "1992\n",
      "2018-09-18 18:13:17.824082\n",
      "1993\n",
      "2018-09-18 18:13:20.480050\n",
      "1994\n",
      "2018-09-18 18:13:23.056017\n",
      "1995\n",
      "2018-09-18 18:13:26.051266\n",
      "1996\n",
      "2018-09-18 18:13:29.206569\n",
      "1997\n",
      "2018-09-18 18:13:32.651648\n",
      "1998\n",
      "2018-09-18 18:13:36.695311\n",
      "1999\n",
      "2018-09-18 18:13:41.250473\n",
      "2000\n",
      "2018-09-18 18:13:46.536752\n",
      "2001\n",
      "2018-09-18 18:13:52.642300\n",
      "2002\n",
      "2018-09-18 18:13:58.755443\n",
      "2003\n",
      "2018-09-18 18:14:05.308897\n",
      "2004\n",
      "2018-09-18 18:14:12.161804\n",
      "2005\n",
      "2018-09-18 18:14:19.666181\n",
      "2006\n",
      "2018-09-18 18:14:27.579427\n",
      "2007\n",
      "2018-09-18 18:14:35.040201\n",
      "2008\n",
      "2018-09-18 18:14:41.663176\n",
      "2009\n",
      "2018-09-18 18:14:47.614352\n",
      "2010\n",
      "2018-09-18 18:14:52.210539\n",
      "2011\n",
      "2018-09-18 18:14:56.441979\n",
      "2012\n",
      "2018-09-18 18:14:59.370628\n",
      "2013\n",
      "2018-09-18 18:15:00.919314\n",
      "2014\n",
      "2018-09-18 18:15:01.683283\n",
      "2015\n",
      "2018-09-18 18:15:01.898331\n"
     ]
    }
   ],
   "source": [
    "# Patents by newly citing assignees\n",
    "pdf = pdf.loc[pdf[\"assignee_id\"].isin(new_cite_asgs)]\n",
    "len(pdf)\n",
    "\n",
    "# Sort by assignee, primclass, app year\n",
    "pdf = pdf.sort_values([\"assignee_id\", \"primclass\", yv], ascending = [1,1,0])\n",
    "\n",
    "# Groupby assignee, primclass, app year\n",
    "p2 = pdf.groupby([\"assignee_id\", \"primclass\"])\n",
    "\n",
    "# Control patent by assignee, primclass\n",
    "cdict = {}\n",
    "for yr in range(1975, 2016):\n",
    "    print(yr)\n",
    "    print(datetime.datetime.now())\n",
    "    # Control patent by assignee, primclass\n",
    "    p2 = pdf.loc[(pdf[\"appyear\"].isin(range(yr-5,yr+1))), \\\n",
    "        [\"appyear\", \"assignee_id\", \"primclass\", \"patent\"]].groupby([\"assignee_id\", \"primclass\"])\n",
    "    p2 = {n+(yr,): (g[\"patent\"].tolist() if len(g[\"patent\"].tolist()) >= 1 else None) for n,g in p2}\n",
    "    cdict.update(p2)\n",
    "    del(p2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get all of cited patent's citations\n",
    "c2 = pd.read_pickle(\"DataStore/2018-08/inv_move_cites_0912.pkl\")\n",
    "c2 = {n:g[\"citing\"].tolist() for n,g in c2[[\"cited\", \"citing\"]].groupby(\"cited\")}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 128 ms, sys: 2.05 ms, total: 130 ms\n",
      "Wall time: 125 ms\n",
      "CPU times: user 729 ms, sys: 0 ns, total: 729 ms\n",
      "Wall time: 733 ms\n"
     ]
    }
   ],
   "source": [
    "# Get list of potential control candidates\n",
    "%time c = [cdict.get((asg, pc, fyr), []) for asg,pc,fyr in zip(c3[\"citing_asg\"], c3[\"citing_primclass\"],\\\n",
    "                                                     c3[\"citing_appyear\"])]\n",
    "# Remove patents that cite the cited patent\n",
    "%time c_2 = [list(set(i)-set(c2.get(j, []))) for i,j in zip(c, c3[\"cited\"])]\n",
    "\n",
    "# Control: since earlier patents have smaller numbers, the control will be one granted closer in date with highest patent number\n",
    "c_3 = [max(i) if len(i) >= 1 else np.nan for i in c_2]\n",
    "\n",
    "c3[\"citing_control_asg_pc\"] = c_3\n",
    "del(c, c_2, c_3, c2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "c3.to_pickle(\"DataStore/2018-08/inv_mob_cite_pc_control_0918.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting row values\n",
      "2018-09-27 13:16:09.192614\n",
      "('ldavecs', 'started')\n",
      "Loading matrix and dict\n",
      "2018-09-27 13:16:11.902623\n",
      "7846\n",
      "Getting chunks\n",
      "2018-09-27 13:16:23.123945\n",
      "Getting patent pair cosine similarity\n",
      "2018-09-27 13:16:23.178828\n",
      "27817\n",
      "finished\n",
      "2018-09-27 13:16:24.592446\n",
      "('docvecs', 'started')\n",
      "Loading matrix and dict\n",
      "2018-09-27 13:16:24.602495\n",
      "7846\n",
      "Getting chunks\n",
      "2018-09-27 13:16:48.076133\n",
      "Getting patent pair cosine similarity\n",
      "2018-09-27 13:16:48.173546\n",
      "27817\n",
      "finished\n",
      "2018-09-27 13:16:49.830461\n"
     ]
    }
   ],
   "source": [
    "def grouper(n, iterable):\n",
    "    \"\"\"\n",
    "    >>> list(grouper(3, 'ABCDEFG'))\n",
    "    [['A', 'B', 'C'], ['D', 'E', 'F'], ['G']]\n",
    "    \"\"\"\n",
    "    iterable = iter(iterable)\n",
    "    return iter(lambda: list(itertools.islice(iterable, n)), [])\n",
    "\n",
    "\n",
    "import scipy.spatial.distance as distance\n",
    "dms = [\"ldavecs\", \"docvecs\"]\n",
    "\n",
    "print(\"Getting row values\")\n",
    "print(datetime.datetime.now())\n",
    "pat_dict = fastparquet.ParquetFile(\"RawData/Cleaned/patabs7615_us_no_dup.parq\").to_pandas([\"patent\"])[\"patent\"].tolist()\n",
    "pat_dict = dict(zip(pat_dict, range(len(pat_dict))))\n",
    "\n",
    "\n",
    "l2 = c3.copy()\n",
    "\n",
    "for dm in dms:\n",
    "    print((dm,\"started\"))\n",
    "    print(\"Loading matrix and dict\")\n",
    "    print(datetime.datetime.now())\n",
    "    \n",
    "    if dm == \"ldavecs\":\n",
    "        ncols = 60\n",
    "    else:\n",
    "        ncols = 100\n",
    "\n",
    "    pm = fastparquet.ParquetFile(\"DataStore/2018-07-P2/ML/{0}_pats_0712.parq\".format(dm))\\\n",
    "    .to_pandas().values\n",
    "    \n",
    "    for col in [\"citing_control_asg_pc\"]:\n",
    "        l3 = pd.DataFrame({\"tp\": c3[\"cited\"], \"op\": c3[col]})\n",
    "        l3 = l3.dropna(how=\"any\").drop_duplicates()\n",
    "        # Store copy as array\n",
    "        l3 = l3.loc[l3[\"tp\"].isin(pat_dict.keys()) & l3[\"op\"].isin(pat_dict.keys())]\n",
    "        print(len(l3))\n",
    "\n",
    "        # Convert to chunks\n",
    "        print(\"Getting chunks\")\n",
    "        print(datetime.datetime.now())\n",
    "        # Split into chunks\n",
    "        n_rows = 3000\n",
    "        n_chunks = int(np.round(len(l3)/n_rows))\n",
    "        tp_chunks = grouper(n_rows, pm[[pat_dict[p[1]] for p in l3[\"tp\"].iteritems()]])\n",
    "        op_chunks = grouper(n_rows, pm[[pat_dict[p[1]] for p in l3[\"op\"].iteritems()]])\n",
    "        \n",
    "        chunks = itertools.zip_longest(tp_chunks, op_chunks)\n",
    "\n",
    "        print(\"Getting patent pair cosine similarity\")\n",
    "        print(datetime.datetime.now())\n",
    "        # Cosine\n",
    "\n",
    "        cos_dis = np.empty(len(l3))\n",
    "\n",
    "        for r, c in enumerate(chunks):\n",
    "            cos_dis[r*n_rows:r*n_rows+n_rows] = np.diag(distance.cdist(c[0],c[1], metric = \"cosine\"))\n",
    "\n",
    "        l3[\"sim_{0}_{1}\".format(dm,col)] = 1-cos_dis\n",
    "\n",
    "        # Rename columns\n",
    "        l3 = l3.rename(columns={\"tp\": \"cited\", \"op\": col})\n",
    "        l2 = l2.merge(l3, how = \"left\", on = [\"cited\", col])\n",
    "        print(len(l2))\n",
    "        del(l3)\n",
    "        print(\"finished\")\n",
    "        print(datetime.datetime.now())\n",
    "    del(pm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>citing</th>\n",
       "      <th>cited</th>\n",
       "      <th>sim_ldavecs</th>\n",
       "      <th>sim_docvecs</th>\n",
       "      <th>cited_inv_msa</th>\n",
       "      <th>citing_inv_msa</th>\n",
       "      <th>cited_appyear</th>\n",
       "      <th>citing_appyear</th>\n",
       "      <th>sec_inv_msa</th>\n",
       "      <th>sec_fyear</th>\n",
       "      <th>sec_inv_msa_match</th>\n",
       "      <th>citing_asg</th>\n",
       "      <th>cited_asg</th>\n",
       "      <th>citing_primclass</th>\n",
       "      <th>citing_control_asg_pc</th>\n",
       "      <th>sim_ldavecs_citing_control_asg_pc</th>\n",
       "      <th>sim_docvecs_citing_control_asg_pc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7837428</td>\n",
       "      <td>5765986</td>\n",
       "      <td>0.517405</td>\n",
       "      <td>0.346076</td>\n",
       "      <td>Reyes Place, CA</td>\n",
       "      <td>Los Angeles-Long Beach-Santa Ana, CA</td>\n",
       "      <td>1995.0</td>\n",
       "      <td>2007.0</td>\n",
       "      <td>San Francisco-Oakland-Fremont, CA</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>False</td>\n",
       "      <td>ed4a5c14c182669b71d3c3a7dd3fb40d</td>\n",
       "      <td>65e7638ba8d787b699cb8a35381c47cb</td>\n",
       "      <td>414.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6131756</td>\n",
       "      <td>4673112</td>\n",
       "      <td>0.308394</td>\n",
       "      <td>0.026374</td>\n",
       "      <td>North Conway, NH</td>\n",
       "      <td>Buffalo-Niagara Falls, NY</td>\n",
       "      <td>1985.0</td>\n",
       "      <td>1997.0</td>\n",
       "      <td>Buffalo-Niagara Falls, NY</td>\n",
       "      <td>1984.0</td>\n",
       "      <td>True</td>\n",
       "      <td>b9e57d6c92ba464bcc64bb7582f2475d</td>\n",
       "      <td>ea0f2ad6019e13b612e3b84b6c97d08b</td>\n",
       "      <td>220.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7300433</td>\n",
       "      <td>5971979</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>San Francisco-Oakland-Fremont, CA</td>\n",
       "      <td>Boston-Cambridge-Quincy, MA-NH</td>\n",
       "      <td>1997.0</td>\n",
       "      <td>2003.0</td>\n",
       "      <td>San Jose-Sunnyvale-Santa Clara, CA</td>\n",
       "      <td>1999.0</td>\n",
       "      <td>False</td>\n",
       "      <td>57118d075226aaaa1e8cd261c28e24f5</td>\n",
       "      <td>f3f87efb03e97170334721471a935585</td>\n",
       "      <td>606.0</td>\n",
       "      <td>7097641.0</td>\n",
       "      <td>0.403679</td>\n",
       "      <td>0.463220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7246244</td>\n",
       "      <td>5802199</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>San Francisco-Oakland-Fremont, CA</td>\n",
       "      <td>New York-Northern New Jersey-Long Island, NY-N...</td>\n",
       "      <td>1997.0</td>\n",
       "      <td>2005.0</td>\n",
       "      <td>Santa Rosa-Petaluma, CA</td>\n",
       "      <td>1996.0</td>\n",
       "      <td>False</td>\n",
       "      <td>2267041f3263c6a765376db6932e65ac</td>\n",
       "      <td>d62b58104e0f118c0b087f21f3df259c</td>\n",
       "      <td>713.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6358993</td>\n",
       "      <td>5011834</td>\n",
       "      <td>0.768476</td>\n",
       "      <td>0.791573</td>\n",
       "      <td>Eugene-Springfield, OR</td>\n",
       "      <td>Boston-Cambridge-Quincy, MA-NH</td>\n",
       "      <td>1989.0</td>\n",
       "      <td>1999.0</td>\n",
       "      <td>Los Angeles-Long Beach-Santa Ana, CA</td>\n",
       "      <td>1993.0</td>\n",
       "      <td>False</td>\n",
       "      <td>c9980fda27658ca1dab82b9473d3bffc</td>\n",
       "      <td>e76e5d396a6c43e5a43e4fcf44a1c84f</td>\n",
       "      <td>514.0</td>\n",
       "      <td>6482839.0</td>\n",
       "      <td>0.703835</td>\n",
       "      <td>0.455489</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    citing    cited  sim_ldavecs  sim_docvecs  \\\n",
       "0  7837428  5765986     0.517405     0.346076   \n",
       "1  6131756  4673112     0.308394     0.026374   \n",
       "2  7300433  5971979          NaN          NaN   \n",
       "3  7246244  5802199          NaN          NaN   \n",
       "4  6358993  5011834     0.768476     0.791573   \n",
       "\n",
       "                       cited_inv_msa  \\\n",
       "0                    Reyes Place, CA   \n",
       "1                   North Conway, NH   \n",
       "2  San Francisco-Oakland-Fremont, CA   \n",
       "3  San Francisco-Oakland-Fremont, CA   \n",
       "4             Eugene-Springfield, OR   \n",
       "\n",
       "                                      citing_inv_msa  cited_appyear  \\\n",
       "0               Los Angeles-Long Beach-Santa Ana, CA         1995.0   \n",
       "1                          Buffalo-Niagara Falls, NY         1985.0   \n",
       "2                     Boston-Cambridge-Quincy, MA-NH         1997.0   \n",
       "3  New York-Northern New Jersey-Long Island, NY-N...         1997.0   \n",
       "4                     Boston-Cambridge-Quincy, MA-NH         1989.0   \n",
       "\n",
       "   citing_appyear                           sec_inv_msa  sec_fyear  \\\n",
       "0          2007.0     San Francisco-Oakland-Fremont, CA     2000.0   \n",
       "1          1997.0             Buffalo-Niagara Falls, NY     1984.0   \n",
       "2          2003.0    San Jose-Sunnyvale-Santa Clara, CA     1999.0   \n",
       "3          2005.0               Santa Rosa-Petaluma, CA     1996.0   \n",
       "4          1999.0  Los Angeles-Long Beach-Santa Ana, CA     1993.0   \n",
       "\n",
       "   sec_inv_msa_match                        citing_asg  \\\n",
       "0              False  ed4a5c14c182669b71d3c3a7dd3fb40d   \n",
       "1               True  b9e57d6c92ba464bcc64bb7582f2475d   \n",
       "2              False  57118d075226aaaa1e8cd261c28e24f5   \n",
       "3              False  2267041f3263c6a765376db6932e65ac   \n",
       "4              False  c9980fda27658ca1dab82b9473d3bffc   \n",
       "\n",
       "                          cited_asg  citing_primclass  citing_control_asg_pc  \\\n",
       "0  65e7638ba8d787b699cb8a35381c47cb             414.0                    NaN   \n",
       "1  ea0f2ad6019e13b612e3b84b6c97d08b             220.0                    NaN   \n",
       "2  f3f87efb03e97170334721471a935585             606.0              7097641.0   \n",
       "3  d62b58104e0f118c0b087f21f3df259c             713.0                    NaN   \n",
       "4  e76e5d396a6c43e5a43e4fcf44a1c84f             514.0              6482839.0   \n",
       "\n",
       "   sim_ldavecs_citing_control_asg_pc  sim_docvecs_citing_control_asg_pc  \n",
       "0                                NaN                                NaN  \n",
       "1                                NaN                                NaN  \n",
       "2                           0.403679                           0.463220  \n",
       "3                                NaN                                NaN  \n",
       "4                           0.703835                           0.455489  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "c3.to_pickle(\"DataStore/2018-08/inv_mob_cite_pc_control_0918.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sim_docvecs                          0.278359\n",
       "sim_docvecs_citing_control_asg_pc    0.233973\n",
       "dtype: float64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l2.dropna(subset=[\"sim_docvecs\", \"sim_docvecs_citing_control_asg_pc\"], how=\"any\")\\\n",
    "[[\"sim_docvecs\", \"sim_docvecs_citing_control_asg_pc\"]].mean()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
