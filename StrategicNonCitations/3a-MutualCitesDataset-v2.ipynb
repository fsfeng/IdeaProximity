{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/homedir/eco/sfeng/bigdata/python/miniconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "import timeit\n",
    "import datetime\n",
    "import time\n",
    "import pprint\n",
    "import itertools\n",
    "import pickle\n",
    "import sklearn\n",
    "import dask\n",
    "import os\n",
    "os.chdir('/mnt/t48/bighomes-active/sfeng/patentdiffusion/')\n",
    "import fastparquet\n",
    "seed = 3\n",
    "import seaborn as sns\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "# Distances\n",
    "import scipy.spatial.distance as distance\n",
    "# KL\n",
    "from scipy.stats import entropy\n",
    "# Normalize\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "# Pairwise distances\n",
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "import h5py\n",
    "import dask\n",
    "import dask.dataframe as dd\n",
    "import dask.array as da"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "*17.05.18*\n",
    "## Mutual citing patents\n",
    "1. Get random patents (50,000)\n",
    "2. Get list of all patents *cited by* 1\n",
    "3. Get patents also citing 2, but granted *before* 1, so that 1 could potentially have also cited 3\n",
    "4. **Key**: Sample from 3. Repeat. Otherwise my results may be too driven by initial sample.\n",
    "\n",
    "Sampling taken from `201709KnowledgeSpilloversRep/1A-MutualCitingSample.ipynb`.\n",
    "\n",
    "See `1a-MutualCitesDataset-v1` for full version of this code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "patent_df = fastparquet.ParquetFile(\"RawData/Cleaned/patent_loc_unique_us_0628.parq\").to_pandas()\n",
    "# Use only citations not from same assignee, granted within 10 years\n",
    "citation_df = fastparquet.ParquetFile(\"DataStore/2018-07-P2/citation_pairs_samp_0716.parq\").to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Updated script from `201804KnowledgeSpilloversRep/2018-03-P1/get_citations.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_citations(pats_col, targ_pats_df, max_year_diff = 100, targ_pats_cited = True,\n",
    "                  citation_cols_to_merge = ['patent', 'gyear'], \n",
    "                 targ_cols_to_merge = ['patent', 'gyear']):\n",
    "\n",
    "    # 1. Limit dataframe to the ones relevant to target dataframe\n",
    "    if targ_pats_cited is True:\n",
    "        # Find patents who cited the target_pat\n",
    "        c1 = citation_df.loc[citation_df[\"cited\"].isin(targ_pats_df[pats_col])]\n",
    "        # Get their patent info\n",
    "        c2 = c1.merge(patent_df[citation_cols_to_merge].add_prefix(\"citing_\"), how = \"left\", left_on = [\"citing\"], right_on = \"citing_patent\")\n",
    "        c2 = c2.drop(\"citing_patent\", 1)\n",
    "        # Merge with targ_pats_df columns\n",
    "        c2 = c2.merge(patent_df[targ_cols_to_merge], how = \"left\", left_on = [\"cited\"], right_on = [\"patent\"])\n",
    "        # Drop patent column\n",
    "        c2 = c2.drop(\"patent\", 1)\n",
    "        # Get the year difference\n",
    "        c2[\"year_diff\"] = c2[\"citing_gyear\"] - c2[\"gyear\"]\n",
    "        # Cull the years greater than the max_year_diff\n",
    "        c2 = c2.loc[abs(c2[\"year_diff\"]) <= max_year_diff]\n",
    "        # Rename the cited column the pats column\n",
    "        c2 = c2.rename(columns={\"cited\": pats_col})\n",
    "        \n",
    "    else:\n",
    "        # Find patents the target_pats cite\n",
    "        c1 = citation_df.loc[citation_df[\"citing\"].isin(targ_pats_df[pats_col])]\n",
    "        c2 = c1.merge(patent_df[citation_cols_to_merge].add_prefix(\"cited_\"), left_on = [\"cited\"], right_on = \"cited_patent\")\n",
    "        c2 = c2.drop(\"cited_patent\", 1)\n",
    "        # Merge with targ_pats_df columns\n",
    "        c2 = c2.merge(patent_df[targ_cols_to_merge], how = \"left\", left_on = [\"citing\"], right_on = [\"patent\"])\n",
    "        # Drop patent column\n",
    "        c2 = c2.drop(\"patent\", 1)\n",
    "        # Get the year difference; cited_gyear < gyear\n",
    "        c2[\"year_diff\"] = c2[\"cited_gyear\"] - c2[\"gyear\"]\n",
    "        # Cull the years greater than the max_year_diff\n",
    "        c2 = c2.loc[abs(c2[\"year_diff\"]) <= max_year_diff]\n",
    "        # Rename the cited column the pats column\n",
    "        c2 = c2.rename(columns={\"citing\": pats_col})\n",
    "           \n",
    "    return c2.drop([\"year_diff\"],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "2018-07-16 16:58:10.225926\n",
      "CPU times: user 2.7 s, sys: 183 ms, total: 2.89 s\n",
      "Wall time: 3.18 s\n",
      "2018-07-16 16:58:13.495161\n",
      "163476\n",
      "CPU times: user 3.46 s, sys: 342 ms, total: 3.8 s\n",
      "Wall time: 4.18 s\n",
      "2018-07-16 16:58:17.673923\n",
      "CPU times: user 374 ms, sys: 89.4 ms, total: 464 ms\n",
      "Wall time: 509 ms\n",
      "4113585\n",
      "1090078\n",
      "272520\n",
      "1\n",
      "2018-07-16 16:58:19.662897\n",
      "CPU times: user 2.59 s, sys: 183 ms, total: 2.77 s\n",
      "Wall time: 3.04 s\n",
      "2018-07-16 16:58:22.812381\n",
      "163674\n",
      "CPU times: user 3.44 s, sys: 332 ms, total: 3.78 s\n",
      "Wall time: 4.15 s\n",
      "2018-07-16 16:58:26.965375\n",
      "CPU times: user 361 ms, sys: 66.4 ms, total: 427 ms\n",
      "Wall time: 469 ms\n",
      "4210564\n",
      "1095308\n",
      "546347\n",
      "2\n",
      "2018-07-16 16:58:28.789901\n",
      "CPU times: user 2.65 s, sys: 169 ms, total: 2.82 s\n",
      "Wall time: 3.1 s\n",
      "2018-07-16 16:58:31.991730\n",
      "159261\n",
      "CPU times: user 3.45 s, sys: 305 ms, total: 3.75 s\n",
      "Wall time: 4.13 s\n",
      "2018-07-16 16:58:36.121275\n",
      "CPU times: user 367 ms, sys: 43.6 ms, total: 411 ms\n",
      "Wall time: 451 ms\n",
      "4064372\n",
      "1069225\n",
      "813653\n",
      "3\n",
      "2018-07-16 16:58:37.832815\n",
      "CPU times: user 2.61 s, sys: 172 ms, total: 2.78 s\n",
      "Wall time: 2.7 s\n",
      "2018-07-16 16:58:40.628494\n",
      "157096\n",
      "CPU times: user 3.85 s, sys: 319 ms, total: 4.17 s\n",
      "Wall time: 3.96 s\n",
      "2018-07-16 16:58:44.591202\n",
      "CPU times: user 347 ms, sys: 49.1 ms, total: 396 ms\n",
      "Wall time: 375 ms\n",
      "3914005\n",
      "1044853\n",
      "1074866\n",
      "4\n",
      "2018-07-16 16:58:46.084823\n",
      "CPU times: user 2.56 s, sys: 188 ms, total: 2.75 s\n",
      "Wall time: 2.97 s\n",
      "2018-07-16 16:58:49.134765\n",
      "159419\n",
      "CPU times: user 3.43 s, sys: 365 ms, total: 3.8 s\n",
      "Wall time: 4.17 s\n",
      "2018-07-16 16:58:53.310467\n",
      "CPU times: user 365 ms, sys: 84.7 ms, total: 450 ms\n",
      "Wall time: 494 ms\n",
      "4143379\n",
      "1048948\n",
      "1337103\n",
      "5\n",
      "2018-07-16 16:58:55.154448\n",
      "CPU times: user 2.8 s, sys: 136 ms, total: 2.94 s\n",
      "Wall time: 3.23 s\n",
      "2018-07-16 16:58:58.479290\n",
      "153714\n",
      "CPU times: user 3.42 s, sys: 208 ms, total: 3.63 s\n",
      "Wall time: 3.99 s\n",
      "2018-07-16 16:59:02.475187\n",
      "CPU times: user 346 ms, sys: 64.3 ms, total: 410 ms\n",
      "Wall time: 450 ms\n",
      "3938138\n",
      "1042090\n",
      "1597625\n",
      "6\n",
      "2018-07-16 16:59:04.250303\n",
      "CPU times: user 2.63 s, sys: 137 ms, total: 2.77 s\n",
      "Wall time: 3.05 s\n",
      "2018-07-16 16:59:07.386554\n",
      "152184\n",
      "CPU times: user 3.3 s, sys: 312 ms, total: 3.61 s\n",
      "Wall time: 3.97 s\n",
      "2018-07-16 16:59:11.354309\n",
      "CPU times: user 352 ms, sys: 40.2 ms, total: 392 ms\n",
      "Wall time: 430 ms\n",
      "3856007\n",
      "994399\n",
      "1846225\n",
      "7\n",
      "2018-07-16 16:59:13.116797\n",
      "CPU times: user 2.53 s, sys: 181 ms, total: 2.71 s\n",
      "Wall time: 2.98 s\n",
      "2018-07-16 16:59:16.195237\n",
      "152475\n",
      "CPU times: user 3.33 s, sys: 314 ms, total: 3.64 s\n",
      "Wall time: 4.01 s\n",
      "2018-07-16 16:59:20.201804\n",
      "CPU times: user 335 ms, sys: 56.9 ms, total: 391 ms\n",
      "Wall time: 430 ms\n",
      "3817982\n",
      "995650\n",
      "2095137\n",
      "8\n",
      "2018-07-16 16:59:21.939423\n",
      "CPU times: user 2.76 s, sys: 123 ms, total: 2.88 s\n",
      "Wall time: 3.17 s\n",
      "2018-07-16 16:59:25.201926\n",
      "150552\n",
      "CPU times: user 3.38 s, sys: 282 ms, total: 3.67 s\n",
      "Wall time: 4.03 s\n",
      "2018-07-16 16:59:29.233842\n",
      "CPU times: user 325 ms, sys: 44.9 ms, total: 370 ms\n",
      "Wall time: 406 ms\n",
      "3646614\n",
      "981515\n",
      "2340516\n",
      "9\n",
      "2018-07-16 16:59:30.991668\n",
      "CPU times: user 2.56 s, sys: 163 ms, total: 2.72 s\n",
      "Wall time: 2.99 s\n",
      "2018-07-16 16:59:34.076062\n",
      "145518\n",
      "CPU times: user 3.38 s, sys: 297 ms, total: 3.67 s\n",
      "Wall time: 4.04 s\n",
      "2018-07-16 16:59:38.116242\n",
      "CPU times: user 354 ms, sys: 24 ms, total: 379 ms\n",
      "Wall time: 384 ms\n",
      "3573251\n",
      "943284\n",
      "2576337\n",
      "10\n",
      "2018-07-16 16:59:39.670526\n",
      "CPU times: user 2.6 s, sys: 208 ms, total: 2.81 s\n",
      "Wall time: 2.57 s\n",
      "2018-07-16 16:59:42.319123\n",
      "146180\n",
      "CPU times: user 3.5 s, sys: 275 ms, total: 3.78 s\n",
      "Wall time: 3.45 s\n",
      "2018-07-16 16:59:45.774111\n",
      "CPU times: user 348 ms, sys: 28.8 ms, total: 377 ms\n",
      "Wall time: 343 ms\n",
      "3557675\n",
      "935390\n",
      "2810185\n"
     ]
    }
   ],
   "source": [
    "# 1. Create initial run\n",
    "mdc = pd.DataFrame()\n",
    "i = 0\n",
    "p2 = patent_df.loc[(patent_df[\"gyear\"] >= 1980) & (patent_df[\"gyear\"] <= 2015)].copy()\n",
    "\n",
    "while i < 11:\n",
    "    print(i)\n",
    "    print(datetime.datetime.now())\n",
    "    # 2. Initial sample\n",
    "    tp = p2.sample(50000, random_state = seed)\n",
    "    # tp[\"gyear\"].value_counts()\n",
    "\n",
    "    # 3. All patents cited by tp\n",
    "    %time tpc = get_citations(pats_col = \"patent\", targ_pats_df = tp, \\\n",
    "                              targ_pats_cited = False, max_year_diff = 100)\n",
    "    print(datetime.datetime.now())\n",
    "    print(len(tpc))\n",
    "    # 4. All patents citing cited\n",
    "    %time tpc2 = get_citations(pats_col = \"cited\", targ_pats_df = tpc, \\\n",
    "                              targ_pats_cited = True, max_year_diff = 100)\n",
    "    print(datetime.datetime.now())\n",
    "    # 5. Merge with tpc\n",
    "    # First drop gyear column on tpc2\n",
    "    %time tpc = tpc.merge(tpc2.drop([\"gyear\"],1), how = \"left\", on = \"cited\")\n",
    "    print(len(tpc))\n",
    "    del(tpc2)\n",
    "    # 6. Drop those with gyear after tp, as we want tp to be potentially citable by op\n",
    "    tpc = tpc.loc[(tpc[\"gyear\"] < tpc[\"citing_gyear\"])]\n",
    "    # Groupby patent, citing and get number of mutual patents\n",
    "    tpc = tpc.groupby([\"patent\", \"citing\"]).size().reset_index()\n",
    "    tpc = tpc.rename(columns={\"patent\":\"tp\", \"citing\": \"op\", 0: \"num_common_cited\"})\n",
    "    print(len(tpc))\n",
    "\n",
    "    # 7. Sample only % of resulting dataset\n",
    "    mdc = mdc.append(tpc.sample(frac=0.25), ignore_index = True)\n",
    "    print(len(mdc))\n",
    "    \n",
    "    # Update sampling set\n",
    "    p2 = p2.loc[~(patent_df[\"patent\"].isin(mdc[\"tp\"]))]\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2810185\n",
      "2810185\n"
     ]
    }
   ],
   "source": [
    "# Drop any duplicates\n",
    "print(len(mdc))\n",
    "mdc = mdc.drop_duplicates(subset=[\"tp\", \"op\"])\n",
    "print(len(mdc))\n",
    "fastparquet.write(\"DataStore/2018-07-P2/mutual_cited_samp_0716.parq\", mdc, compression=\"GZIP\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add other variables\n",
    "- *tp*: original patent\n",
    "- *op*: patent that also cited a patent that *tp* does, but is granted after *tp*\n",
    "\n",
    "#### Check if *tp* is cited by *op*\n",
    "\n",
    "Get all patents cited by *op*, see if *tp* in the list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.39 s, sys: 464 ms, total: 5.85 s\n",
      "Wall time: 5.85 s\n",
      "CPU times: user 1min 29s, sys: 981 ms, total: 1min 30s\n",
      "Wall time: 1min 28s\n",
      "2810185\n"
     ]
    }
   ],
   "source": [
    "%time tpc3 = get_citations(pats_col = \"op\", targ_pats_df = mdc, \\\n",
    "                          targ_pats_cited = False, max_year_diff = 100)\n",
    "%time op_cited = {n:g[\"cited\"].tolist() for n,g in tpc3[[\"op\", \"cited\"]].groupby(\"op\")}\n",
    "del(tpc3)\n",
    "mdc[\"op_cites_tp\"] = [tp in op_cited[op] if op in op_cited.keys() else np.nan for tp,op \\\n",
    "                      in zip(mdc[\"tp\"], mdc[\"op\"])] \n",
    "print(len(mdc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    2754414\n",
       "True       55771\n",
       "Name: op_cites_tp, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "mdc[\"op_cites_tp\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "fastparquet.write(\"DataStore/2018-07-P2/mutual_cited_samp_0716.parq\", mdc, compression=\"GZIP\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add similarity\n",
    "### 2.1 Measuring similarity across data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:good day to you madam fiona\n",
      "INFO:root:started\n",
      "INFO:root:2018-07-16 17:03:21.326738\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger.addHandler(logging.FileHandler('Logs/mutual_cite_sim_{0}.log'.format(datetime.datetime.now().\\\n",
    "                                                            strftime(\"%Y-%m-%d\"), 'a')))\n",
    "print = logging.info\n",
    "print('good day to you madam fiona')\n",
    "print('started')\n",
    "print(datetime.datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Loading matrix and dict\n",
      "INFO:root:2018-07-16 17:03:21.345195\n",
      "INFO:root:2810185\n",
      "INFO:root:2445169\n",
      "INFO:root:2445169\n",
      "INFO:root:2445169\n",
      "INFO:root:Getting patent pair similarity\n",
      "INFO:root:cosine\n",
      "INFO:root:2018-07-16 17:03:40.075070\n",
      "INFO:root:finished\n",
      "INFO:root:2018-07-16 17:12:53.408940\n"
     ]
    }
   ],
   "source": [
    "import scipy.spatial.distance as distance\n",
    "import dask.array as da\n",
    "dms = [\"ldavecs\", \"docvecs\"]\n",
    "res = {}\n",
    "for dm in dms:\n",
    "    print(\"Loading matrix and dict\")\n",
    "    print(datetime.datetime.now())\n",
    "    \n",
    "    pat_dict = fastparquet.ParquetFile(\"RawData/Cleaned/patabs7615_us_no_dup.parq\").to_pandas([\"patent\"])[\"patent\"].tolist()\n",
    "    pat_dict = dict(zip(pat_dict, range(len(pat_dict))))\n",
    "    # Store as dask array\n",
    "    if dm == \"ldavecs\":\n",
    "        ncols = 60\n",
    "    else:\n",
    "        ncols = 100\n",
    "    pm = dd.read_parquet(\"DataStore/2018-07-P2/ML/{0}_pats_0712.parq\".format(dm)).values.compute()\n",
    "    pm = da.from_array(pm, chunks=(10000,ncols))\n",
    "\n",
    "    l3 = fastparquet.ParquetFile(\"DataStore/2018-07-P2/mutual_cited_samp_0716.parq\").to_pandas()\\\n",
    "    .rename(columns={\"cited\":\"tp\", \"citing\":\"op\"})\n",
    "\n",
    "    # Remove missing values\n",
    "    print(len(l3))\n",
    "    l3 = l3.loc[l3[\"tp\"].isin(pat_dict.keys()) & l3[\"op\"].isin(pat_dict.keys())]\n",
    "    print(len(l3))\n",
    "    if dm == \"ldavecs\":\n",
    "        ncols = 60\n",
    "    else:\n",
    "        ncols = 100\n",
    "        \n",
    "    print(len(l3))\n",
    "\n",
    "    tp_chunks = pm[[pat_dict[p] for p in l3[\"tp\"].tolist()]].compute()\n",
    "    op_chunks = pm[[pat_dict[p] for p in l3[\"op\"].tolist()]].compute()\n",
    "    print(len(l3))\n",
    "\n",
    "    # Split into chunks\n",
    "    n_chunks = np.round(len(l3)/3000)\n",
    "    tp_chunks = np.array_split(tp_chunks, n_chunks)\n",
    "    op_chunks = np.array_split(op_chunks, n_chunks)\n",
    "\n",
    "    print(\"Getting patent pair similarity\")\n",
    "    print(\"cosine\")\n",
    "    print(datetime.datetime.now())\n",
    "    # Recursively lengthen the array of cosine distances\n",
    "    cos_dis = np.array([])\n",
    "    for i,j in zip(tp_chunks, op_chunks):\n",
    "        cos_dis = np.hstack((cos_dis, np.hstack([np.diag(distance.cdist(i,j, metric = \"cosine\"))])))\n",
    "        \n",
    "    l3[\"sim_{0}\".format(dm)] = 1-cos_dis\n",
    "    res[dm] = l3\n",
    "    print(\"finished\")\n",
    "    print(datetime.datetime.now())\n",
    "    del(l3)    \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdc = res[\"ldavecs\"].merge(res[\"docvecs\"][[\"tp\", \"op\", \"sim_docvecs\"]],\n",
    "                          how = \"left\", on = [\"tp\", \"op\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tp</th>\n",
       "      <th>op</th>\n",
       "      <th>num_common_cited</th>\n",
       "      <th>op_cites_tp</th>\n",
       "      <th>sim_ldavecs</th>\n",
       "      <th>sim_docvecs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8312465</td>\n",
       "      <td>9104645</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>0.201732</td>\n",
       "      <td>0.142462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6546553</td>\n",
       "      <td>6823508</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>0.686707</td>\n",
       "      <td>0.220453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7310179</td>\n",
       "      <td>7916103</td>\n",
       "      <td>33</td>\n",
       "      <td>False</td>\n",
       "      <td>0.160098</td>\n",
       "      <td>0.092198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8250031</td>\n",
       "      <td>8595191</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>0.396526</td>\n",
       "      <td>0.347709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7085553</td>\n",
       "      <td>7379733</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>0.578231</td>\n",
       "      <td>0.016689</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        tp       op  num_common_cited  op_cites_tp  sim_ldavecs  sim_docvecs\n",
       "0  8312465  9104645                 1        False     0.201732     0.142462\n",
       "1  6546553  6823508                 1        False     0.686707     0.220453\n",
       "2  7310179  7916103                33        False     0.160098     0.092198\n",
       "3  8250031  8595191                 1        False     0.396526     0.347709\n",
       "4  7085553  7379733                 1        False     0.578231     0.016689"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "fastparquet.write(\"DataStore/2018-07-P2/mutual_cited_sim_0716.parq\", mdc, compression=\"GZIP\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge with original dataset for other variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2445169\n",
      "2445169\n"
     ]
    }
   ],
   "source": [
    "pdf = fastparquet.ParquetFile(\"RawData/Cleaned/patent_loc_unique_us_0628.parq\").to_pandas().drop_duplicates([\"patent\"])\n",
    "mdc = fastparquet.ParquetFile(\"DataStore/2018-07-P2/mutual_cited_sim_0716.parq\").to_pandas()\n",
    "print(len(mdc))\n",
    "# Drop missing\n",
    "mdc = mdc.loc[(mdc[\"tp\"].notnull()) & (mdc[\"op\"].notnull())]\n",
    "print(len(mdc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2445169\n",
      "2445169\n"
     ]
    }
   ],
   "source": [
    "mdc = mdc.merge(pdf[[\"patent\", \"gyear\", \"inv_msa\", \"naics_name\", \"primclass\"]]\n",
    "               .add_prefix(\"tp_\"), how = \"left\", left_on = \"tp\", right_on = \"tp_patent\").\\\n",
    "drop(\"tp_patent\",1)\n",
    "# Drop missing\n",
    "mdc = mdc.loc[(mdc[\"tp\"].notnull()) & (mdc[\"op\"].notnull())]\n",
    "print(len(mdc))\n",
    "mdc = mdc.merge(pdf[[\"patent\", \"gyear\", \"inv_msa\", \"naics_name\", \"primclass\"]]\n",
    "               .add_prefix(\"op_\"), how = \"right\", left_on = \"op\", right_on = \"op_patent\").\\\n",
    "drop(\"op_patent\",1)\n",
    "# Drop missing\n",
    "mdc = mdc.loc[(mdc[\"tp\"].notnull()) & (mdc[\"op\"].notnull())]\n",
    "print(len(mdc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add year group\n",
    "def get_year_group(x):\n",
    "    if x in range(1975,1985):\n",
    "        yg = \"1975-85\"\n",
    "    elif x in range(1985,1995):\n",
    "        yg = \"1985-95\"\n",
    "    elif x in range(1995, 2005):\n",
    "        yg = \"1995-05\"\n",
    "    elif x in range(2005,2015):\n",
    "        yg = \"2005-15\"\n",
    "    else:\n",
    "        yg = np.nan\n",
    "    return yg\n",
    "mdc[\"year_group\"] = mdc[\"tp_gyear\"].apply(get_year_group)\n",
    "\n",
    "# Don't scale\n",
    "# eps = 0.01\n",
    "# dv_min = 0.7\n",
    "# def scale_docvecs(x):\n",
    "#     scaled = ((x+dv_min)/(1+dv_min))*(1-eps)+eps\n",
    "#     return scaled\n",
    "# def scale_ldavecs(x):\n",
    "#     scaled = x*(1-eps)+eps\n",
    "#     return scaled\n",
    "# mdc[\"sim_ldavecs\"] = mdc[\"sim_ldavecs\"].apply(scale_ldavecs)\n",
    "# mdc[\"sim_docvecs\"] = mdc[\"sim_docvecs\"].apply(scale_docvecs)\n",
    "# print(len(mdc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fastparquet.write(\"DataStore/2018-07-P2/mutual_cited_0716.parq\", mdc, compression=\"GZIP\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sim_ldavecs</th>\n",
       "      <th>sim_docvecs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2445169.000</td>\n",
       "      <td>2445169.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.458</td>\n",
       "      <td>0.548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.252</td>\n",
       "      <td>0.084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.011</td>\n",
       "      <td>0.037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.252</td>\n",
       "      <td>0.491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.455</td>\n",
       "      <td>0.545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.660</td>\n",
       "      <td>0.601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.968</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       sim_ldavecs  sim_docvecs\n",
       "count  2445169.000  2445169.000\n",
       "mean         0.458        0.548\n",
       "std          0.252        0.084\n",
       "min          0.011        0.037\n",
       "25%          0.252        0.491\n",
       "50%          0.455        0.545\n",
       "75%          0.660        0.601\n",
       "max          1.000        0.968"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(mdc[[\"sim_ldavecs\", \"sim_docvecs\"]].describe(),3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
